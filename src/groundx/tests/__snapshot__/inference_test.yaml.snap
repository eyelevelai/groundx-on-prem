'aws: inference':
  1: |
    apiVersion: apps/v1
    kind: Deployment
    metadata:
      labels:
        app: layout-inference
        appVersion: 0.1.0
        chart: groundx-0.1.0
        heritage: Helm
        version: 0.1.0
      name: layout-inference
      namespace: eyelevel
    spec:
      replicas: 1
      selector:
        matchLabels:
          app: layout-inference
      template:
        metadata:
          annotations:
            config-hash: 7ceb284dc3b869a93078dc13391866ce9c9dfbcef7aa4a5b0d8a7edf2626c888
            config-models-hash: 529542d6881ddf622683f3bc8516205a5707660e0a921243b32fd51fd3573f4f
            ldconfig-symlink-hash: 9958a113394211878ece8f9030f4c08a1860e77aa75b5852bfa0691fc3faf32f
            supervisord-hash: 389d025411e33663295cbafcb9d7241d27e1d8736153cd1d14fa9c1b056107fe
          labels:
            app: layout-inference
        spec:
          containers:
            - command:
                - /bin/sh
                - -c
                - |
                  export PYTHONPATH=/app:$PYTHONPATH && python /app/init-layout.py && supervisord -c /app/supervisord.conf
              env:
                - name: POD_NAME
                  valueFrom:
                    fieldRef:
                      fieldPath: metadata.name
              image: public.ecr.aws/c9r4x6y5/eyelevel/layout-inference:0.1.0
              imagePullPolicy: IfNotPresent
              livenessProbe:
                failureThreshold: 8
                httpGet:
                  path: /alive
                  port: 8080
                initialDelaySeconds: 30
                periodSeconds: 15
              name: layout-inference
              ports:
                - containerPort: 8080
                  protocol: TCP
              readinessProbe:
                failureThreshold: 30
                httpGet:
                  path: /health
                  port: 8080
                initialDelaySeconds: 30
                periodSeconds: 15
              resources:
                limits:
                  nvidia.com/gpu: 1
                requests:
                  cpu: 500m
                  memory: 2Gi
                  nvidia.com/gpu: 1
              securityContext:
                allowPrivilegeEscalation: false
                capabilities:
                  drop:
                    - ALL
                runAsGroup: 1001
                runAsNonRoot: true
                runAsUser: 1001
                seccompProfile:
                  type: RuntimeDefault
              volumeMounts:
                - mountPath: /app/config_models.py
                  name: config-models
                  subPath: config_models.py
                - mountPath: /app/config.py
                  name: config-volume
                  subPath: config.py
                - mountPath: /app/supervisord.conf
                  name: supervisord-volume
                  subPath: supervisord.conf
              workingDir: /app
          initContainers:
            - command:
                - sh
                - -c
                - until nc -z X.X.X.use2.cache.amazonaws.com 6379; do echo waiting for cache; sleep 2; done
              image: public.ecr.aws/c9r4x6y5/eyelevel/busybox:1.0.0
              imagePullPolicy: IfNotPresent
              name: wait-for-cache
            - command:
                - sh
                - -c
                - until nc -z X.s3.us-west-2.amazonaws.com 443; do echo waiting for file storage; sleep 2; done
              image: public.ecr.aws/c9r4x6y5/eyelevel/busybox:1.0.0
              imagePullPolicy: IfNotPresent
              name: wait-for-file-storage
            - args:
                - echo 'Running ldconfig_symlink.sh on this node'; /scripts/ldconfig_symlink.sh
              command:
                - /bin/sh
                - -c
                - --
              image: public.ecr.aws/c9r4x6y5/eyelevel/busybox:1.0.0
              imagePullPolicy: IfNotPresent
              name: create-symlink
              resources:
                requests:
                  cpu: 10m
                  memory: 50Mi
              securityContext:
                privileged: true
              volumeMounts:
                - mountPath: /scripts/ldconfig_symlink.sh
                  name: layout-inference
                  subPath: ldconfig_symlink.sh
                - mountPath: /host-sbin
                  name: host-sbin
                - mountPath: /host-usr-sbin
                  name: host-usr-sbin
                - mountPath: /host-bin
                  name: host-bin
                - mountPath: /host-usr-bin
                  name: host-usr-bin
          nodeSelector:
            node: eyelevel-gpu-layout
          securityContext:
            fsGroup: 1001
            fsGroupChangePolicy: OnRootMismatch
            runAsGroup: 1001
            runAsNonRoot: true
            runAsUser: 1001
            seccompProfile:
              type: RuntimeDefault
          tolerations:
            - effect: NoSchedule
              key: node
              value: eyelevel-gpu-layout
          volumes:
            - configMap:
                name: config-models-map
              name: config-models
            - configMap:
                name: layout-config-py-map
              name: config-volume
            - configMap:
                name: layout-inference-supervisord-conf-map
              name: supervisord-volume
            - configMap:
                defaultMode: 365
                name: ldconfig-symlink-map
              name: layout-inference
            - hostPath:
                path: /sbin
                type: Directory
              name: host-sbin
            - hostPath:
                path: /usr/sbin
                type: Directory
              name: host-usr-sbin
            - hostPath:
                path: /bin
                type: Directory
              name: host-bin
            - hostPath:
                path: /usr/bin
                type: Directory
              name: host-usr-bin
  2: |
    apiVersion: apps/v1
    kind: Deployment
    metadata:
      labels:
        app: summary-inference
        appVersion: 0.1.0
        chart: groundx-0.1.0
        heritage: Helm
        version: 0.1.0
      name: summary-inference
      namespace: eyelevel
    spec:
      replicas: 2
      selector:
        matchLabels:
          app: summary-inference
      template:
        metadata:
          annotations:
            config-hash: 2e9432e7927d2f5c53c8cdb87fa2a9a545c618f950c4ea653afe64e36ae0aa39
            config-models-hash: 529542d6881ddf622683f3bc8516205a5707660e0a921243b32fd51fd3573f4f
            ldconfig-symlink-hash: 9958a113394211878ece8f9030f4c08a1860e77aa75b5852bfa0691fc3faf32f
            supervisord-hash: a48af0c98c4a6d0aafa9d919d204e9d8b1c51e416a36f766644a6c8d11e48a90
          labels:
            app: summary-inference
        spec:
          containers:
            - command:
                - /bin/sh
                - -c
                - |
                  export PYTHONPATH=/workspace:$PYTHONPATH &&  supervisord -c /workspace/supervisord.conf
              env:
                - name: POD_NAME
                  valueFrom:
                    fieldRef:
                      fieldPath: metadata.name
              image: public.ecr.aws/c9r4x6y5/eyelevel/summary-inference:0.1.0
              imagePullPolicy: IfNotPresent
              livenessProbe:
                failureThreshold: 8
                httpGet:
                  path: /alive
                  port: 8080
                initialDelaySeconds: 30
                periodSeconds: 15
              name: summary-inference
              ports:
                - containerPort: 8080
                  protocol: TCP
              readinessProbe:
                failureThreshold: 30
                httpGet:
                  path: /health
                  port: 8080
                initialDelaySeconds: 30
                periodSeconds: 15
              resources:
                requests:
                  cpu: 500m
                  memory: 1Gi
              securityContext:
                allowPrivilegeEscalation: false
                capabilities:
                  drop:
                    - ALL
                runAsGroup: 1001
                runAsNonRoot: true
                runAsUser: 1001
                seccompProfile:
                  type: RuntimeDefault
              volumeMounts:
                - mountPath: /workspace/config_models.py
                  name: config-models
                  subPath: config_models.py
                - mountPath: /workspace/config.py
                  name: config-volume
                  subPath: config.py
                - mountPath: /workspace/supervisord.conf
                  name: supervisord-volume
                  subPath: supervisord.conf
                - mountPath: /workspace/hf_models_cache
                  name: model-volume
              workingDir: /workspace
          initContainers:
            - command:
                - sh
                - -c
                - until nc -z X.X.X.use2.cache.amazonaws.com 6379; do echo waiting for cache; sleep 2; done
              image: public.ecr.aws/c9r4x6y5/eyelevel/busybox:1.0.0
              imagePullPolicy: IfNotPresent
              name: wait-for-cache
            - args:
                - echo 'Running ldconfig_symlink.sh on this node'; /scripts/ldconfig_symlink.sh
              command:
                - /bin/sh
                - -c
                - --
              image: public.ecr.aws/c9r4x6y5/eyelevel/busybox:1.0.0
              imagePullPolicy: IfNotPresent
              name: create-symlink
              resources:
                requests:
                  cpu: 10m
                  memory: 50Mi
              securityContext:
                privileged: true
              volumeMounts:
                - mountPath: /scripts/ldconfig_symlink.sh
                  name: summary-inference
                  subPath: ldconfig_symlink.sh
                - mountPath: /host-sbin
                  name: host-sbin
                - mountPath: /host-usr-sbin
                  name: host-usr-sbin
                - mountPath: /host-bin
                  name: host-bin
                - mountPath: /host-usr-bin
                  name: host-usr-bin
            - command:
                - /bin/sh
                - -c
                - |
                  download_and_extract_model() {
                    echo "Model downloading started..."

                    touch /workspace/hf_models_cache/downloading

                    echo "00 01 02 03 04" | tr ' ' '\n' | xargs -n 1 -P 5 -I {} sh -c \
                      'MAX_RETRIES=3; RETRIES=0; SUCCESS=0; PART={}; URL=https://upload.groundx.ai/summary/model/current/g34b.tar.gz.part.$PART; \
                      while [ $RETRIES -lt $MAX_RETRIES ]; do \
                        echo "Download [attempt $RETRIES] summary.tar.gz.part.$PART"; \
                        wget -q -O /workspace/hf_models_cache/summary.tar.gz.part.$PART $URL && { echo "Downloaded summary.tar.gz.part.$PART successfully."; SUCCESS=1; break; }; \
                        echo "Failed to download $URL. Retrying..."; RETRIES=$((RETRIES + 1)); sleep 3; \
                      done; \
                      [ $SUCCESS -eq 0 ] && { echo "Failed to download $URL after $MAX_RETRIES attempts. Exiting."; rm /workspace/hf_models_cache/downloading; exit 1; }; \
                      echo "Unzipping summary.tar.gz.part.$PART..."; tar -xzf /workspace/hf_models_cache/summary.tar.gz.part.$PART -C /workspace/hf_models_cache/; echo "Unzipping summary.tar.gz.part.$PART complete...";'

                    rm /workspace/hf_models_cache/summary.tar.*
                    rm /workspace/hf_models_cache/downloading
                    touch /workspace/hf_models_cache/complete.g34b
                  }
                  if [ ! -f /workspace/hf_models_cache/complete.g34b ]; then
                    if [ ! -f /workspace/hf_models_cache/downloading ]; then
                      download_and_extract_model
                    else
                      echo "Download in progress by another pod. Waiting..."
                      while [ -f /workspace/hf_models_cache/downloading ] || [ ! -f /workspace/hf_models_cache/complete.g34b ]; do
                        sleep $((3 + RANDOM % 2))
                      done

                      if [ ! -f /workspace/hf_models_cache/complete.g34b ]; then
                        download_and_extract_model
                      else
                        echo "Model cache ready."
                      fi
                    fi
                  else
                    echo "Model cache already exists. Skipping download."
                  fi

                  echo "Model load done."
              image: public.ecr.aws/c9r4x6y5/eyelevel/busybox:1.0.0
              imagePullPolicy: IfNotPresent
              name: download-model
              securityContext:
                allowPrivilegeEscalation: false
                capabilities:
                  drop:
                    - ALL
                runAsGroup: 1001
                runAsNonRoot: true
                runAsUser: 1001
                seccompProfile:
                  type: RuntimeDefault
              volumeMounts:
                - mountPath: /workspace/hf_models_cache
                  name: model-volume
          nodeSelector:
            node: eyelevel-gpu-summary
          securityContext:
            fsGroup: 1001
            fsGroupChangePolicy: OnRootMismatch
            runAsGroup: 1001
            runAsNonRoot: true
            runAsUser: 1001
            seccompProfile:
              type: RuntimeDefault
          tolerations:
            - effect: NoSchedule
              key: node
              value: eyelevel-gpu-summary
          volumes:
            - configMap:
                name: config-models-map
              name: config-models
            - configMap:
                name: summary-config-py-map
              name: config-volume
            - configMap:
                name: summary-inference-supervisord-conf-map
              name: supervisord-volume
            - configMap:
                defaultMode: 365
                name: ldconfig-symlink-map
              name: summary-inference
            - hostPath:
                path: /sbin
                type: Directory
              name: host-sbin
            - hostPath:
                path: /usr/sbin
                type: Directory
              name: host-usr-sbin
            - hostPath:
                path: /bin
                type: Directory
              name: host-bin
            - hostPath:
                path: /usr/bin
                type: Directory
              name: host-usr-bin
            - name: model-volume
              persistentVolumeClaim:
                claimName: summary-model
  3: |
    apiVersion: v1
    kind: PersistentVolumeClaim
    metadata:
      labels:
        app: summary-inference
      name: summary-model
      namespace: eyelevel
    spec:
      accessModes:
        - ReadWriteOnce
      resources:
        requests:
          storage: 20Gi
      storageClassName: eyelevel-pv
'cloud: inference':
  1: |
    apiVersion: apps/v1
    kind: Deployment
    metadata:
      labels:
        app: layout-inference
        appVersion: 0.1.0
        chart: groundx-0.1.0
        heritage: Helm
        version: 0.1.0
      name: layout-inference
      namespace: eyelevel
    spec:
      replicas: 1
      selector:
        matchLabels:
          app: layout-inference
      template:
        metadata:
          annotations:
            config-hash: 2ee257a6597d2d64b9b3fb9f6d4e1e1490b4b0524207506f61ea45765d2eaa15
            config-models-hash: 529542d6881ddf622683f3bc8516205a5707660e0a921243b32fd51fd3573f4f
            ldconfig-symlink-hash: 9958a113394211878ece8f9030f4c08a1860e77aa75b5852bfa0691fc3faf32f
            supervisord-hash: 389d025411e33663295cbafcb9d7241d27e1d8736153cd1d14fa9c1b056107fe
          labels:
            app: layout-inference
        spec:
          containers:
            - command:
                - /bin/sh
                - -c
                - |
                  export PYTHONPATH=/app:$PYTHONPATH && python /app/init-layout.py && supervisord -c /app/supervisord.conf
              env:
                - name: POD_NAME
                  valueFrom:
                    fieldRef:
                      fieldPath: metadata.name
              image: public.ecr.aws/c9r4x6y5/eyelevel/layout-inference:0.1.0
              imagePullPolicy: IfNotPresent
              livenessProbe:
                failureThreshold: 8
                httpGet:
                  path: /alive
                  port: 8080
                initialDelaySeconds: 30
                periodSeconds: 15
              name: layout-inference
              ports:
                - containerPort: 8080
                  protocol: TCP
              readinessProbe:
                failureThreshold: 30
                httpGet:
                  path: /health
                  port: 8080
                initialDelaySeconds: 30
                periodSeconds: 15
              resources:
                limits:
                  nvidia.com/gpu: 1
                requests:
                  cpu: 500m
                  memory: 2Gi
                  nvidia.com/gpu: 1
              securityContext:
                allowPrivilegeEscalation: false
                capabilities:
                  drop:
                    - ALL
                runAsGroup: 1001
                runAsNonRoot: true
                runAsUser: 1001
                seccompProfile:
                  type: RuntimeDefault
              volumeMounts:
                - mountPath: /app/config_models.py
                  name: config-models
                  subPath: config_models.py
                - mountPath: /app/config.py
                  name: config-volume
                  subPath: config.py
                - mountPath: /app/supervisord.conf
                  name: supervisord-volume
                  subPath: supervisord.conf
              workingDir: /app
          initContainers:
            - command:
                - sh
                - -c
                - until nc -z cache.eyelevel.svc.cluster.local 6379; do echo waiting for cache; sleep 2; done
              image: public.ecr.aws/c9r4x6y5/eyelevel/busybox:1.0.0
              imagePullPolicy: IfNotPresent
              name: wait-for-cache
            - command:
                - sh
                - -c
                - until nc -z X.s3.us-west-2.amazonaws.com 443; do echo waiting for file storage; sleep 2; done
              image: public.ecr.aws/c9r4x6y5/eyelevel/busybox:1.0.0
              imagePullPolicy: IfNotPresent
              name: wait-for-file-storage
            - args:
                - echo 'Running ldconfig_symlink.sh on this node'; /scripts/ldconfig_symlink.sh
              command:
                - /bin/sh
                - -c
                - --
              image: public.ecr.aws/c9r4x6y5/eyelevel/busybox:1.0.0
              imagePullPolicy: IfNotPresent
              name: create-symlink
              resources:
                requests:
                  cpu: 10m
                  memory: 50Mi
              securityContext:
                privileged: true
              volumeMounts:
                - mountPath: /scripts/ldconfig_symlink.sh
                  name: layout-inference
                  subPath: ldconfig_symlink.sh
                - mountPath: /host-sbin
                  name: host-sbin
                - mountPath: /host-usr-sbin
                  name: host-usr-sbin
                - mountPath: /host-bin
                  name: host-bin
                - mountPath: /host-usr-bin
                  name: host-usr-bin
          nodeSelector:
            node: eyelevel-gpu-layout
          securityContext:
            fsGroup: 1001
            fsGroupChangePolicy: OnRootMismatch
            runAsGroup: 1001
            runAsNonRoot: true
            runAsUser: 1001
            seccompProfile:
              type: RuntimeDefault
          tolerations:
            - effect: NoSchedule
              key: node
              value: eyelevel-gpu-layout
          volumes:
            - configMap:
                name: config-models-map
              name: config-models
            - configMap:
                name: layout-config-py-map
              name: config-volume
            - configMap:
                name: layout-inference-supervisord-conf-map
              name: supervisord-volume
            - configMap:
                defaultMode: 365
                name: ldconfig-symlink-map
              name: layout-inference
            - hostPath:
                path: /sbin
                type: Directory
              name: host-sbin
            - hostPath:
                path: /usr/sbin
                type: Directory
              name: host-usr-sbin
            - hostPath:
                path: /bin
                type: Directory
              name: host-bin
            - hostPath:
                path: /usr/bin
                type: Directory
              name: host-usr-bin
  2: |
    apiVersion: apps/v1
    kind: Deployment
    metadata:
      labels:
        app: ranker-inference
        appVersion: 0.1.0
        chart: groundx-0.1.0
        heritage: Helm
        version: 0.1.0
      name: ranker-inference
      namespace: eyelevel
    spec:
      replicas: 1
      selector:
        matchLabels:
          app: ranker-inference
      template:
        metadata:
          annotations:
            config-hash: 8de2baea042228f54db256891d5da302316aab7828362929c3145cbfcfa75146
            config-models-hash: 529542d6881ddf622683f3bc8516205a5707660e0a921243b32fd51fd3573f4f
            ldconfig-symlink-hash: 9958a113394211878ece8f9030f4c08a1860e77aa75b5852bfa0691fc3faf32f
            supervisord-hash: c3de8d835a18146d0f59120a18513f20056efbb1cda896213ca789277d88a71b
          labels:
            app: ranker-inference
        spec:
          containers:
            - command:
                - /bin/sh
                - -c
                - |
                  export PYTHONPATH=/workspace:$PYTHONPATH &&  supervisord -c /workspace/supervisord.conf
              env:
                - name: POD_NAME
                  valueFrom:
                    fieldRef:
                      fieldPath: metadata.name
              image: public.ecr.aws/c9r4x6y5/eyelevel/ranker-inference:0.1.0
              imagePullPolicy: IfNotPresent
              livenessProbe:
                exec:
                  command:
                    - /bin/sh
                    - -c
                    - ps aux | grep 'ranker.celery.appSearch' | grep -v grep || exit 1
                failureThreshold: 10
                initialDelaySeconds: 60
                periodSeconds: 30
              name: ranker-inference
              readinessProbe:
                exec:
                  command:
                    - /bin/sh
                    - -c
                    - ps aux | grep 'ranker.celery.appSearch' | grep -v grep || exit 1
                initialDelaySeconds: 60
                periodSeconds: 30
              resources:
                limits:
                  nvidia.com/gpu: 1
                requests:
                  cpu: 1.5
                  memory: 1Gi
                  nvidia.com/gpu: 1
              securityContext:
                allowPrivilegeEscalation: false
                capabilities:
                  drop:
                    - ALL
                runAsGroup: 1001
                runAsNonRoot: true
                runAsUser: 1001
                seccompProfile:
                  type: RuntimeDefault
              volumeMounts:
                - mountPath: /workspace/config_models.py
                  name: config-models
                  subPath: config_models.py
                - mountPath: /workspace/config.py
                  name: config-volume
                  subPath: config.py
                - mountPath: /workspace/supervisord.conf
                  name: supervisord-volume
                  subPath: supervisord.conf
                - mountPath: /workspace/hf_models_cache
                  name: model-volume
              workingDir: /workspace
          initContainers:
            - command:
                - sh
                - -c
                - until nc -z cache.eyelevel.svc.cluster.local 6379; do echo waiting for cache; sleep 2; done
              image: public.ecr.aws/c9r4x6y5/eyelevel/busybox:1.0.0
              imagePullPolicy: IfNotPresent
              name: wait-for-cache
            - args:
                - echo 'Running ldconfig_symlink.sh on this node'; /scripts/ldconfig_symlink.sh
              command:
                - /bin/sh
                - -c
                - --
              image: public.ecr.aws/c9r4x6y5/eyelevel/busybox:1.0.0
              imagePullPolicy: IfNotPresent
              name: create-symlink
              resources:
                requests:
                  cpu: 10m
                  memory: 50Mi
              securityContext:
                privileged: true
              volumeMounts:
                - mountPath: /scripts/ldconfig_symlink.sh
                  name: ranker-inference
                  subPath: ldconfig_symlink.sh
                - mountPath: /host-sbin
                  name: host-sbin
                - mountPath: /host-usr-sbin
                  name: host-usr-sbin
                - mountPath: /host-bin
                  name: host-bin
                - mountPath: /host-usr-bin
                  name: host-usr-bin
            - command:
                - /bin/sh
                - -c
                - |
                  download_and_extract_model() {
                    echo "Model downloading started..."

                    touch /workspace/hf_models_cache/downloading

                    echo "00 01 02" | tr ' ' '\n' | xargs -n 1 -P 5 -I {} sh -c \
                      'MAX_RETRIES=3; RETRIES=0; SUCCESS=0; PART={}; URL=https://upload.groundx.ai/ranker/model/current/model.tar.gz.part.$PART; \
                      while [ $RETRIES -lt $MAX_RETRIES ]; do \
                        echo "Download [attempt $RETRIES] ranker.tar.gz.part.$PART"; \
                        wget -q -O /workspace/hf_models_cache/ranker.tar.gz.part.$PART $URL && { echo "Downloaded ranker.tar.gz.part.$PART successfully."; SUCCESS=1; break; }; \
                        echo "Failed to download $URL. Retrying..."; RETRIES=$((RETRIES + 1)); sleep 3; \
                      done; \
                      [ $SUCCESS -eq 0 ] && { echo "Failed to download $URL after $MAX_RETRIES attempts. Exiting."; rm /workspace/hf_models_cache/downloading; exit 1; }; \
                      echo "Unzipping ranker.tar.gz.part.$PART..."; tar -xzf /workspace/hf_models_cache/ranker.tar.gz.part.$PART -C /workspace/hf_models_cache/; echo "Unzipping ranker.tar.gz.part.$PART complete...";'

                    rm /workspace/hf_models_cache/ranker.tar.*
                    rm /workspace/hf_models_cache/downloading
                    touch /workspace/hf_models_cache/complete.model
                  }
                  if [ ! -f /workspace/hf_models_cache/complete.model ]; then
                    if [ ! -f /workspace/hf_models_cache/downloading ]; then
                      download_and_extract_model
                    else
                      echo "Download in progress by another pod. Waiting..."
                      while [ -f /workspace/hf_models_cache/downloading ] || [ ! -f /workspace/hf_models_cache/complete.model ]; do
                        sleep $((3 + RANDOM % 2))
                      done

                      if [ ! -f /workspace/hf_models_cache/complete.model ]; then
                        download_and_extract_model
                      else
                        echo "Model cache ready."
                      fi
                    fi
                  else
                    echo "Model cache already exists. Skipping download."
                  fi

                  echo "Model load done."
              image: public.ecr.aws/c9r4x6y5/eyelevel/busybox:1.0.0
              imagePullPolicy: IfNotPresent
              name: download-model
              securityContext:
                allowPrivilegeEscalation: false
                capabilities:
                  drop:
                    - ALL
                runAsGroup: 1001
                runAsNonRoot: true
                runAsUser: 1001
                seccompProfile:
                  type: RuntimeDefault
              volumeMounts:
                - mountPath: /workspace/hf_models_cache
                  name: model-volume
          nodeSelector:
            node: eyelevel-gpu-ranker
          securityContext:
            fsGroup: 1001
            fsGroupChangePolicy: OnRootMismatch
            runAsGroup: 1001
            runAsNonRoot: true
            runAsUser: 1001
            seccompProfile:
              type: RuntimeDefault
          tolerations:
            - effect: NoSchedule
              key: node
              value: eyelevel-gpu-ranker
          volumes:
            - configMap:
                name: config-models-map
              name: config-models
            - configMap:
                name: ranker-config-py-map
              name: config-volume
            - configMap:
                name: ranker-inference-supervisord-conf-map
              name: supervisord-volume
            - configMap:
                defaultMode: 365
                name: ldconfig-symlink-map
              name: ranker-inference
            - hostPath:
                path: /sbin
                type: Directory
              name: host-sbin
            - hostPath:
                path: /usr/sbin
                type: Directory
              name: host-usr-sbin
            - hostPath:
                path: /bin
                type: Directory
              name: host-bin
            - hostPath:
                path: /usr/bin
                type: Directory
              name: host-usr-bin
            - name: model-volume
              persistentVolumeClaim:
                claimName: ranker-model
  3: |
    apiVersion: v1
    kind: PersistentVolumeClaim
    metadata:
      labels:
        app: ranker-inference
      name: ranker-model
      namespace: eyelevel
    spec:
      accessModes:
        - ReadWriteOnce
      resources:
        requests:
          storage: 10Gi
      storageClassName: eyelevel-pv
  4: |
    apiVersion: apps/v1
    kind: Deployment
    metadata:
      labels:
        app: summary-inference
        appVersion: 0.1.0
        chart: groundx-0.1.0
        heritage: Helm
        version: 0.1.0
      name: summary-inference
      namespace: eyelevel
    spec:
      replicas: 2
      selector:
        matchLabels:
          app: summary-inference
      template:
        metadata:
          annotations:
            config-hash: 51b3f74b62e64c36d06ea7360481e2bce39d6048899f71f252e65339efe9ee25
            config-models-hash: 529542d6881ddf622683f3bc8516205a5707660e0a921243b32fd51fd3573f4f
            ldconfig-symlink-hash: 9958a113394211878ece8f9030f4c08a1860e77aa75b5852bfa0691fc3faf32f
            supervisord-hash: a48af0c98c4a6d0aafa9d919d204e9d8b1c51e416a36f766644a6c8d11e48a90
          labels:
            app: summary-inference
        spec:
          containers:
            - command:
                - /bin/sh
                - -c
                - |
                  export PYTHONPATH=/workspace:$PYTHONPATH &&  supervisord -c /workspace/supervisord.conf
              env:
                - name: POD_NAME
                  valueFrom:
                    fieldRef:
                      fieldPath: metadata.name
              image: public.ecr.aws/c9r4x6y5/eyelevel/summary-inference:0.1.0
              imagePullPolicy: IfNotPresent
              livenessProbe:
                failureThreshold: 8
                httpGet:
                  path: /alive
                  port: 8080
                initialDelaySeconds: 30
                periodSeconds: 15
              name: summary-inference
              ports:
                - containerPort: 8080
                  protocol: TCP
              readinessProbe:
                failureThreshold: 30
                httpGet:
                  path: /health
                  port: 8080
                initialDelaySeconds: 30
                periodSeconds: 15
              resources:
                requests:
                  cpu: 500m
                  memory: 1Gi
              securityContext:
                allowPrivilegeEscalation: false
                capabilities:
                  drop:
                    - ALL
                runAsGroup: 1001
                runAsNonRoot: true
                runAsUser: 1001
                seccompProfile:
                  type: RuntimeDefault
              volumeMounts:
                - mountPath: /workspace/config_models.py
                  name: config-models
                  subPath: config_models.py
                - mountPath: /workspace/config.py
                  name: config-volume
                  subPath: config.py
                - mountPath: /workspace/supervisord.conf
                  name: supervisord-volume
                  subPath: supervisord.conf
                - mountPath: /workspace/hf_models_cache
                  name: model-volume
              workingDir: /workspace
          initContainers:
            - command:
                - sh
                - -c
                - until nc -z cache.eyelevel.svc.cluster.local 6379; do echo waiting for cache; sleep 2; done
              image: public.ecr.aws/c9r4x6y5/eyelevel/busybox:1.0.0
              imagePullPolicy: IfNotPresent
              name: wait-for-cache
            - args:
                - echo 'Running ldconfig_symlink.sh on this node'; /scripts/ldconfig_symlink.sh
              command:
                - /bin/sh
                - -c
                - --
              image: public.ecr.aws/c9r4x6y5/eyelevel/busybox:1.0.0
              imagePullPolicy: IfNotPresent
              name: create-symlink
              resources:
                requests:
                  cpu: 10m
                  memory: 50Mi
              securityContext:
                privileged: true
              volumeMounts:
                - mountPath: /scripts/ldconfig_symlink.sh
                  name: summary-inference
                  subPath: ldconfig_symlink.sh
                - mountPath: /host-sbin
                  name: host-sbin
                - mountPath: /host-usr-sbin
                  name: host-usr-sbin
                - mountPath: /host-bin
                  name: host-bin
                - mountPath: /host-usr-bin
                  name: host-usr-bin
            - command:
                - /bin/sh
                - -c
                - |
                  download_and_extract_model() {
                    echo "Model downloading started..."

                    touch /workspace/hf_models_cache/downloading

                    echo "00 01 02 03 04" | tr ' ' '\n' | xargs -n 1 -P 5 -I {} sh -c \
                      'MAX_RETRIES=3; RETRIES=0; SUCCESS=0; PART={}; URL=https://upload.groundx.ai/summary/model/current/g34b.tar.gz.part.$PART; \
                      while [ $RETRIES -lt $MAX_RETRIES ]; do \
                        echo "Download [attempt $RETRIES] summary.tar.gz.part.$PART"; \
                        wget -q -O /workspace/hf_models_cache/summary.tar.gz.part.$PART $URL && { echo "Downloaded summary.tar.gz.part.$PART successfully."; SUCCESS=1; break; }; \
                        echo "Failed to download $URL. Retrying..."; RETRIES=$((RETRIES + 1)); sleep 3; \
                      done; \
                      [ $SUCCESS -eq 0 ] && { echo "Failed to download $URL after $MAX_RETRIES attempts. Exiting."; rm /workspace/hf_models_cache/downloading; exit 1; }; \
                      echo "Unzipping summary.tar.gz.part.$PART..."; tar -xzf /workspace/hf_models_cache/summary.tar.gz.part.$PART -C /workspace/hf_models_cache/; echo "Unzipping summary.tar.gz.part.$PART complete...";'

                    rm /workspace/hf_models_cache/summary.tar.*
                    rm /workspace/hf_models_cache/downloading
                    touch /workspace/hf_models_cache/complete.g34b
                  }
                  if [ ! -f /workspace/hf_models_cache/complete.g34b ]; then
                    if [ ! -f /workspace/hf_models_cache/downloading ]; then
                      download_and_extract_model
                    else
                      echo "Download in progress by another pod. Waiting..."
                      while [ -f /workspace/hf_models_cache/downloading ] || [ ! -f /workspace/hf_models_cache/complete.g34b ]; do
                        sleep $((3 + RANDOM % 2))
                      done

                      if [ ! -f /workspace/hf_models_cache/complete.g34b ]; then
                        download_and_extract_model
                      else
                        echo "Model cache ready."
                      fi
                    fi
                  else
                    echo "Model cache already exists. Skipping download."
                  fi

                  echo "Model load done."
              image: public.ecr.aws/c9r4x6y5/eyelevel/busybox:1.0.0
              imagePullPolicy: IfNotPresent
              name: download-model
              securityContext:
                allowPrivilegeEscalation: false
                capabilities:
                  drop:
                    - ALL
                runAsGroup: 1001
                runAsNonRoot: true
                runAsUser: 1001
                seccompProfile:
                  type: RuntimeDefault
              volumeMounts:
                - mountPath: /workspace/hf_models_cache
                  name: model-volume
          nodeSelector:
            node: eyelevel-gpu-summary
          securityContext:
            fsGroup: 1001
            fsGroupChangePolicy: OnRootMismatch
            runAsGroup: 1001
            runAsNonRoot: true
            runAsUser: 1001
            seccompProfile:
              type: RuntimeDefault
          tolerations:
            - effect: NoSchedule
              key: node
              value: eyelevel-gpu-summary
          volumes:
            - configMap:
                name: config-models-map
              name: config-models
            - configMap:
                name: summary-config-py-map
              name: config-volume
            - configMap:
                name: summary-inference-supervisord-conf-map
              name: supervisord-volume
            - configMap:
                defaultMode: 365
                name: ldconfig-symlink-map
              name: summary-inference
            - hostPath:
                path: /sbin
                type: Directory
              name: host-sbin
            - hostPath:
                path: /usr/sbin
                type: Directory
              name: host-usr-sbin
            - hostPath:
                path: /bin
                type: Directory
              name: host-bin
            - hostPath:
                path: /usr/bin
                type: Directory
              name: host-usr-bin
            - name: model-volume
              persistentVolumeClaim:
                claimName: summary-model
  5: |
    apiVersion: v1
    kind: PersistentVolumeClaim
    metadata:
      labels:
        app: summary-inference
      name: summary-model
      namespace: eyelevel
    spec:
      accessModes:
        - ReadWriteOnce
      resources:
        requests:
          storage: 20Gi
      storageClassName: eyelevel-pv
'default: inference':
  1: |
    apiVersion: apps/v1
    kind: Deployment
    metadata:
      labels:
        app: layout-inference
        appVersion: 0.1.0
        chart: groundx-0.1.0
        heritage: Helm
        version: 0.1.0
      name: layout-inference
      namespace: eyelevel
    spec:
      replicas: 1
      selector:
        matchLabels:
          app: layout-inference
      template:
        metadata:
          annotations:
            config-hash: ac70a23921bbd948745293be79d474cb3687af3882748951e056c20a584278a5
            config-models-hash: 529542d6881ddf622683f3bc8516205a5707660e0a921243b32fd51fd3573f4f
            ldconfig-symlink-hash: 9958a113394211878ece8f9030f4c08a1860e77aa75b5852bfa0691fc3faf32f
            supervisord-hash: 389d025411e33663295cbafcb9d7241d27e1d8736153cd1d14fa9c1b056107fe
          labels:
            app: layout-inference
        spec:
          containers:
            - command:
                - /bin/sh
                - -c
                - |
                  export PYTHONPATH=/app:$PYTHONPATH && python /app/init-layout.py && supervisord -c /app/supervisord.conf
              env:
                - name: POD_NAME
                  valueFrom:
                    fieldRef:
                      fieldPath: metadata.name
              image: public.ecr.aws/c9r4x6y5/eyelevel/layout-inference:0.1.0
              imagePullPolicy: IfNotPresent
              livenessProbe:
                failureThreshold: 8
                httpGet:
                  path: /alive
                  port: 8080
                initialDelaySeconds: 30
                periodSeconds: 15
              name: layout-inference
              ports:
                - containerPort: 8080
                  protocol: TCP
              readinessProbe:
                failureThreshold: 30
                httpGet:
                  path: /health
                  port: 8080
                initialDelaySeconds: 30
                periodSeconds: 15
              resources:
                limits:
                  nvidia.com/gpu: 1
                requests:
                  cpu: 500m
                  memory: 2Gi
                  nvidia.com/gpu: 1
              securityContext:
                allowPrivilegeEscalation: false
                capabilities:
                  drop:
                    - ALL
                runAsGroup: 1001
                runAsNonRoot: true
                runAsUser: 1001
                seccompProfile:
                  type: RuntimeDefault
              volumeMounts:
                - mountPath: /app/config_models.py
                  name: config-models
                  subPath: config_models.py
                - mountPath: /app/config.py
                  name: config-volume
                  subPath: config.py
                - mountPath: /app/supervisord.conf
                  name: supervisord-volume
                  subPath: supervisord.conf
              workingDir: /app
          initContainers:
            - command:
                - sh
                - -c
                - until nc -z cache.eyelevel.svc.cluster.local 6379; do echo waiting for cache; sleep 2; done
              image: public.ecr.aws/c9r4x6y5/eyelevel/busybox:1.0.0
              imagePullPolicy: IfNotPresent
              name: wait-for-cache
            - command:
                - sh
                - -c
                - until nc -z minio-tenant-hl.eyelevel.svc.cluster.local 9000; do echo waiting for file storage; sleep 2; done
              image: public.ecr.aws/c9r4x6y5/eyelevel/busybox:1.0.0
              imagePullPolicy: IfNotPresent
              name: wait-for-file-storage
            - args:
                - echo 'Running ldconfig_symlink.sh on this node'; /scripts/ldconfig_symlink.sh
              command:
                - /bin/sh
                - -c
                - --
              image: public.ecr.aws/c9r4x6y5/eyelevel/busybox:1.0.0
              imagePullPolicy: IfNotPresent
              name: create-symlink
              resources:
                requests:
                  cpu: 10m
                  memory: 50Mi
              securityContext:
                privileged: true
              volumeMounts:
                - mountPath: /scripts/ldconfig_symlink.sh
                  name: layout-inference
                  subPath: ldconfig_symlink.sh
                - mountPath: /host-sbin
                  name: host-sbin
                - mountPath: /host-usr-sbin
                  name: host-usr-sbin
                - mountPath: /host-bin
                  name: host-bin
                - mountPath: /host-usr-bin
                  name: host-usr-bin
          nodeSelector:
            node: eyelevel-gpu-layout
          securityContext:
            fsGroup: 1001
            fsGroupChangePolicy: OnRootMismatch
            runAsGroup: 1001
            runAsNonRoot: true
            runAsUser: 1001
            seccompProfile:
              type: RuntimeDefault
          tolerations:
            - effect: NoSchedule
              key: node
              value: eyelevel-gpu-layout
          volumes:
            - configMap:
                name: config-models-map
              name: config-models
            - configMap:
                name: layout-config-py-map
              name: config-volume
            - configMap:
                name: layout-inference-supervisord-conf-map
              name: supervisord-volume
            - configMap:
                defaultMode: 365
                name: ldconfig-symlink-map
              name: layout-inference
            - hostPath:
                path: /sbin
                type: Directory
              name: host-sbin
            - hostPath:
                path: /usr/sbin
                type: Directory
              name: host-usr-sbin
            - hostPath:
                path: /bin
                type: Directory
              name: host-bin
            - hostPath:
                path: /usr/bin
                type: Directory
              name: host-usr-bin
  2: |
    apiVersion: apps/v1
    kind: Deployment
    metadata:
      labels:
        app: ranker-inference
        appVersion: 0.1.0
        chart: groundx-0.1.0
        heritage: Helm
        version: 0.1.0
      name: ranker-inference
      namespace: eyelevel
    spec:
      replicas: 1
      selector:
        matchLabels:
          app: ranker-inference
      template:
        metadata:
          annotations:
            config-hash: 8de2baea042228f54db256891d5da302316aab7828362929c3145cbfcfa75146
            config-models-hash: 529542d6881ddf622683f3bc8516205a5707660e0a921243b32fd51fd3573f4f
            ldconfig-symlink-hash: 9958a113394211878ece8f9030f4c08a1860e77aa75b5852bfa0691fc3faf32f
            supervisord-hash: c3de8d835a18146d0f59120a18513f20056efbb1cda896213ca789277d88a71b
          labels:
            app: ranker-inference
        spec:
          containers:
            - command:
                - /bin/sh
                - -c
                - |
                  export PYTHONPATH=/workspace:$PYTHONPATH &&  supervisord -c /workspace/supervisord.conf
              env:
                - name: POD_NAME
                  valueFrom:
                    fieldRef:
                      fieldPath: metadata.name
              image: public.ecr.aws/c9r4x6y5/eyelevel/ranker-inference:0.1.0
              imagePullPolicy: IfNotPresent
              livenessProbe:
                exec:
                  command:
                    - /bin/sh
                    - -c
                    - ps aux | grep 'ranker.celery.appSearch' | grep -v grep || exit 1
                failureThreshold: 10
                initialDelaySeconds: 60
                periodSeconds: 30
              name: ranker-inference
              readinessProbe:
                exec:
                  command:
                    - /bin/sh
                    - -c
                    - ps aux | grep 'ranker.celery.appSearch' | grep -v grep || exit 1
                initialDelaySeconds: 60
                periodSeconds: 30
              resources:
                limits:
                  nvidia.com/gpu: 1
                requests:
                  cpu: 1.5
                  memory: 1Gi
                  nvidia.com/gpu: 1
              securityContext:
                allowPrivilegeEscalation: false
                capabilities:
                  drop:
                    - ALL
                runAsGroup: 1001
                runAsNonRoot: true
                runAsUser: 1001
                seccompProfile:
                  type: RuntimeDefault
              volumeMounts:
                - mountPath: /workspace/config_models.py
                  name: config-models
                  subPath: config_models.py
                - mountPath: /workspace/config.py
                  name: config-volume
                  subPath: config.py
                - mountPath: /workspace/supervisord.conf
                  name: supervisord-volume
                  subPath: supervisord.conf
                - mountPath: /workspace/hf_models_cache
                  name: model-volume
              workingDir: /workspace
          initContainers:
            - command:
                - sh
                - -c
                - until nc -z cache.eyelevel.svc.cluster.local 6379; do echo waiting for cache; sleep 2; done
              image: public.ecr.aws/c9r4x6y5/eyelevel/busybox:1.0.0
              imagePullPolicy: IfNotPresent
              name: wait-for-cache
            - args:
                - echo 'Running ldconfig_symlink.sh on this node'; /scripts/ldconfig_symlink.sh
              command:
                - /bin/sh
                - -c
                - --
              image: public.ecr.aws/c9r4x6y5/eyelevel/busybox:1.0.0
              imagePullPolicy: IfNotPresent
              name: create-symlink
              resources:
                requests:
                  cpu: 10m
                  memory: 50Mi
              securityContext:
                privileged: true
              volumeMounts:
                - mountPath: /scripts/ldconfig_symlink.sh
                  name: ranker-inference
                  subPath: ldconfig_symlink.sh
                - mountPath: /host-sbin
                  name: host-sbin
                - mountPath: /host-usr-sbin
                  name: host-usr-sbin
                - mountPath: /host-bin
                  name: host-bin
                - mountPath: /host-usr-bin
                  name: host-usr-bin
            - command:
                - /bin/sh
                - -c
                - |
                  download_and_extract_model() {
                    echo "Model downloading started..."

                    touch /workspace/hf_models_cache/downloading

                    echo "00 01 02" | tr ' ' '\n' | xargs -n 1 -P 5 -I {} sh -c \
                      'MAX_RETRIES=3; RETRIES=0; SUCCESS=0; PART={}; URL=https://upload.groundx.ai/ranker/model/current/model.tar.gz.part.$PART; \
                      while [ $RETRIES -lt $MAX_RETRIES ]; do \
                        echo "Download [attempt $RETRIES] ranker.tar.gz.part.$PART"; \
                        wget -q -O /workspace/hf_models_cache/ranker.tar.gz.part.$PART $URL && { echo "Downloaded ranker.tar.gz.part.$PART successfully."; SUCCESS=1; break; }; \
                        echo "Failed to download $URL. Retrying..."; RETRIES=$((RETRIES + 1)); sleep 3; \
                      done; \
                      [ $SUCCESS -eq 0 ] && { echo "Failed to download $URL after $MAX_RETRIES attempts. Exiting."; rm /workspace/hf_models_cache/downloading; exit 1; }; \
                      echo "Unzipping ranker.tar.gz.part.$PART..."; tar -xzf /workspace/hf_models_cache/ranker.tar.gz.part.$PART -C /workspace/hf_models_cache/; echo "Unzipping ranker.tar.gz.part.$PART complete...";'

                    rm /workspace/hf_models_cache/ranker.tar.*
                    rm /workspace/hf_models_cache/downloading
                    touch /workspace/hf_models_cache/complete.model
                  }
                  if [ ! -f /workspace/hf_models_cache/complete.model ]; then
                    if [ ! -f /workspace/hf_models_cache/downloading ]; then
                      download_and_extract_model
                    else
                      echo "Download in progress by another pod. Waiting..."
                      while [ -f /workspace/hf_models_cache/downloading ] || [ ! -f /workspace/hf_models_cache/complete.model ]; do
                        sleep $((3 + RANDOM % 2))
                      done

                      if [ ! -f /workspace/hf_models_cache/complete.model ]; then
                        download_and_extract_model
                      else
                        echo "Model cache ready."
                      fi
                    fi
                  else
                    echo "Model cache already exists. Skipping download."
                  fi

                  echo "Model load done."
              image: public.ecr.aws/c9r4x6y5/eyelevel/busybox:1.0.0
              imagePullPolicy: IfNotPresent
              name: download-model
              securityContext:
                allowPrivilegeEscalation: false
                capabilities:
                  drop:
                    - ALL
                runAsGroup: 1001
                runAsNonRoot: true
                runAsUser: 1001
                seccompProfile:
                  type: RuntimeDefault
              volumeMounts:
                - mountPath: /workspace/hf_models_cache
                  name: model-volume
          nodeSelector:
            node: eyelevel-gpu-ranker
          securityContext:
            fsGroup: 1001
            fsGroupChangePolicy: OnRootMismatch
            runAsGroup: 1001
            runAsNonRoot: true
            runAsUser: 1001
            seccompProfile:
              type: RuntimeDefault
          tolerations:
            - effect: NoSchedule
              key: node
              value: eyelevel-gpu-ranker
          volumes:
            - configMap:
                name: config-models-map
              name: config-models
            - configMap:
                name: ranker-config-py-map
              name: config-volume
            - configMap:
                name: ranker-inference-supervisord-conf-map
              name: supervisord-volume
            - configMap:
                defaultMode: 365
                name: ldconfig-symlink-map
              name: ranker-inference
            - hostPath:
                path: /sbin
                type: Directory
              name: host-sbin
            - hostPath:
                path: /usr/sbin
                type: Directory
              name: host-usr-sbin
            - hostPath:
                path: /bin
                type: Directory
              name: host-bin
            - hostPath:
                path: /usr/bin
                type: Directory
              name: host-usr-bin
            - name: model-volume
              persistentVolumeClaim:
                claimName: ranker-model
  3: |
    apiVersion: v1
    kind: PersistentVolumeClaim
    metadata:
      labels:
        app: ranker-inference
      name: ranker-model
      namespace: eyelevel
    spec:
      accessModes:
        - ReadWriteOnce
      resources:
        requests:
          storage: 10Gi
      storageClassName: eyelevel-pv
  4: |
    apiVersion: apps/v1
    kind: Deployment
    metadata:
      labels:
        app: summary-inference
        appVersion: 0.1.0
        chart: groundx-0.1.0
        heritage: Helm
        version: 0.1.0
      name: summary-inference
      namespace: eyelevel
    spec:
      replicas: 2
      selector:
        matchLabels:
          app: summary-inference
      template:
        metadata:
          annotations:
            config-hash: 51b3f74b62e64c36d06ea7360481e2bce39d6048899f71f252e65339efe9ee25
            config-models-hash: 529542d6881ddf622683f3bc8516205a5707660e0a921243b32fd51fd3573f4f
            ldconfig-symlink-hash: 9958a113394211878ece8f9030f4c08a1860e77aa75b5852bfa0691fc3faf32f
            supervisord-hash: a48af0c98c4a6d0aafa9d919d204e9d8b1c51e416a36f766644a6c8d11e48a90
          labels:
            app: summary-inference
        spec:
          containers:
            - command:
                - /bin/sh
                - -c
                - |
                  export PYTHONPATH=/workspace:$PYTHONPATH &&  supervisord -c /workspace/supervisord.conf
              env:
                - name: POD_NAME
                  valueFrom:
                    fieldRef:
                      fieldPath: metadata.name
              image: public.ecr.aws/c9r4x6y5/eyelevel/summary-inference:0.1.0
              imagePullPolicy: IfNotPresent
              livenessProbe:
                failureThreshold: 8
                httpGet:
                  path: /alive
                  port: 8080
                initialDelaySeconds: 30
                periodSeconds: 15
              name: summary-inference
              ports:
                - containerPort: 8080
                  protocol: TCP
              readinessProbe:
                failureThreshold: 30
                httpGet:
                  path: /health
                  port: 8080
                initialDelaySeconds: 30
                periodSeconds: 15
              resources:
                requests:
                  cpu: 500m
                  memory: 1Gi
              securityContext:
                allowPrivilegeEscalation: false
                capabilities:
                  drop:
                    - ALL
                runAsGroup: 1001
                runAsNonRoot: true
                runAsUser: 1001
                seccompProfile:
                  type: RuntimeDefault
              volumeMounts:
                - mountPath: /workspace/config_models.py
                  name: config-models
                  subPath: config_models.py
                - mountPath: /workspace/config.py
                  name: config-volume
                  subPath: config.py
                - mountPath: /workspace/supervisord.conf
                  name: supervisord-volume
                  subPath: supervisord.conf
                - mountPath: /workspace/hf_models_cache
                  name: model-volume
              workingDir: /workspace
          initContainers:
            - command:
                - sh
                - -c
                - until nc -z cache.eyelevel.svc.cluster.local 6379; do echo waiting for cache; sleep 2; done
              image: public.ecr.aws/c9r4x6y5/eyelevel/busybox:1.0.0
              imagePullPolicy: IfNotPresent
              name: wait-for-cache
            - args:
                - echo 'Running ldconfig_symlink.sh on this node'; /scripts/ldconfig_symlink.sh
              command:
                - /bin/sh
                - -c
                - --
              image: public.ecr.aws/c9r4x6y5/eyelevel/busybox:1.0.0
              imagePullPolicy: IfNotPresent
              name: create-symlink
              resources:
                requests:
                  cpu: 10m
                  memory: 50Mi
              securityContext:
                privileged: true
              volumeMounts:
                - mountPath: /scripts/ldconfig_symlink.sh
                  name: summary-inference
                  subPath: ldconfig_symlink.sh
                - mountPath: /host-sbin
                  name: host-sbin
                - mountPath: /host-usr-sbin
                  name: host-usr-sbin
                - mountPath: /host-bin
                  name: host-bin
                - mountPath: /host-usr-bin
                  name: host-usr-bin
            - command:
                - /bin/sh
                - -c
                - |
                  download_and_extract_model() {
                    echo "Model downloading started..."

                    touch /workspace/hf_models_cache/downloading

                    echo "00 01 02 03 04" | tr ' ' '\n' | xargs -n 1 -P 5 -I {} sh -c \
                      'MAX_RETRIES=3; RETRIES=0; SUCCESS=0; PART={}; URL=https://upload.groundx.ai/summary/model/current/g34b.tar.gz.part.$PART; \
                      while [ $RETRIES -lt $MAX_RETRIES ]; do \
                        echo "Download [attempt $RETRIES] summary.tar.gz.part.$PART"; \
                        wget -q -O /workspace/hf_models_cache/summary.tar.gz.part.$PART $URL && { echo "Downloaded summary.tar.gz.part.$PART successfully."; SUCCESS=1; break; }; \
                        echo "Failed to download $URL. Retrying..."; RETRIES=$((RETRIES + 1)); sleep 3; \
                      done; \
                      [ $SUCCESS -eq 0 ] && { echo "Failed to download $URL after $MAX_RETRIES attempts. Exiting."; rm /workspace/hf_models_cache/downloading; exit 1; }; \
                      echo "Unzipping summary.tar.gz.part.$PART..."; tar -xzf /workspace/hf_models_cache/summary.tar.gz.part.$PART -C /workspace/hf_models_cache/; echo "Unzipping summary.tar.gz.part.$PART complete...";'

                    rm /workspace/hf_models_cache/summary.tar.*
                    rm /workspace/hf_models_cache/downloading
                    touch /workspace/hf_models_cache/complete.g34b
                  }
                  if [ ! -f /workspace/hf_models_cache/complete.g34b ]; then
                    if [ ! -f /workspace/hf_models_cache/downloading ]; then
                      download_and_extract_model
                    else
                      echo "Download in progress by another pod. Waiting..."
                      while [ -f /workspace/hf_models_cache/downloading ] || [ ! -f /workspace/hf_models_cache/complete.g34b ]; do
                        sleep $((3 + RANDOM % 2))
                      done

                      if [ ! -f /workspace/hf_models_cache/complete.g34b ]; then
                        download_and_extract_model
                      else
                        echo "Model cache ready."
                      fi
                    fi
                  else
                    echo "Model cache already exists. Skipping download."
                  fi

                  echo "Model load done."
              image: public.ecr.aws/c9r4x6y5/eyelevel/busybox:1.0.0
              imagePullPolicy: IfNotPresent
              name: download-model
              securityContext:
                allowPrivilegeEscalation: false
                capabilities:
                  drop:
                    - ALL
                runAsGroup: 1001
                runAsNonRoot: true
                runAsUser: 1001
                seccompProfile:
                  type: RuntimeDefault
              volumeMounts:
                - mountPath: /workspace/hf_models_cache
                  name: model-volume
          nodeSelector:
            node: eyelevel-gpu-summary
          securityContext:
            fsGroup: 1001
            fsGroupChangePolicy: OnRootMismatch
            runAsGroup: 1001
            runAsNonRoot: true
            runAsUser: 1001
            seccompProfile:
              type: RuntimeDefault
          tolerations:
            - effect: NoSchedule
              key: node
              value: eyelevel-gpu-summary
          volumes:
            - configMap:
                name: config-models-map
              name: config-models
            - configMap:
                name: summary-config-py-map
              name: config-volume
            - configMap:
                name: summary-inference-supervisord-conf-map
              name: supervisord-volume
            - configMap:
                defaultMode: 365
                name: ldconfig-symlink-map
              name: summary-inference
            - hostPath:
                path: /sbin
                type: Directory
              name: host-sbin
            - hostPath:
                path: /usr/sbin
                type: Directory
              name: host-usr-sbin
            - hostPath:
                path: /bin
                type: Directory
              name: host-bin
            - hostPath:
                path: /usr/bin
                type: Directory
              name: host-usr-bin
            - name: model-volume
              persistentVolumeClaim:
                claimName: summary-model
  5: |
    apiVersion: v1
    kind: PersistentVolumeClaim
    metadata:
      labels:
        app: summary-inference
      name: summary-model
      namespace: eyelevel
    spec:
      accessModes:
        - ReadWriteOnce
      resources:
        requests:
          storage: 20Gi
      storageClassName: eyelevel-pv
'disabled: inference':
'empty: inference':
  1: |
    apiVersion: apps/v1
    kind: Deployment
    metadata:
      labels:
        app: layout-inference
        appVersion: 0.1.0
        chart: groundx-0.1.0
        heritage: Helm
        version: 0.1.0
      name: layout-inference
      namespace: eyelevel
    spec:
      replicas: 1
      selector:
        matchLabels:
          app: layout-inference
      template:
        metadata:
          annotations:
            config-hash: ac70a23921bbd948745293be79d474cb3687af3882748951e056c20a584278a5
            config-models-hash: 529542d6881ddf622683f3bc8516205a5707660e0a921243b32fd51fd3573f4f
            ldconfig-symlink-hash: 9958a113394211878ece8f9030f4c08a1860e77aa75b5852bfa0691fc3faf32f
            supervisord-hash: 389d025411e33663295cbafcb9d7241d27e1d8736153cd1d14fa9c1b056107fe
          labels:
            app: layout-inference
        spec:
          containers:
            - command:
                - /bin/sh
                - -c
                - |
                  export PYTHONPATH=/app:$PYTHONPATH && python /app/init-layout.py && supervisord -c /app/supervisord.conf
              env:
                - name: POD_NAME
                  valueFrom:
                    fieldRef:
                      fieldPath: metadata.name
              image: public.ecr.aws/c9r4x6y5/eyelevel/layout-inference:0.1.0
              imagePullPolicy: IfNotPresent
              livenessProbe:
                failureThreshold: 8
                httpGet:
                  path: /alive
                  port: 8080
                initialDelaySeconds: 30
                periodSeconds: 15
              name: layout-inference
              ports:
                - containerPort: 8080
                  protocol: TCP
              readinessProbe:
                failureThreshold: 30
                httpGet:
                  path: /health
                  port: 8080
                initialDelaySeconds: 30
                periodSeconds: 15
              resources:
                limits:
                  nvidia.com/gpu: 1
                requests:
                  cpu: 500m
                  memory: 2Gi
                  nvidia.com/gpu: 1
              securityContext:
                allowPrivilegeEscalation: false
                capabilities:
                  drop:
                    - ALL
                runAsGroup: 1001
                runAsNonRoot: true
                runAsUser: 1001
                seccompProfile:
                  type: RuntimeDefault
              volumeMounts:
                - mountPath: /app/config_models.py
                  name: config-models
                  subPath: config_models.py
                - mountPath: /app/config.py
                  name: config-volume
                  subPath: config.py
                - mountPath: /app/supervisord.conf
                  name: supervisord-volume
                  subPath: supervisord.conf
              workingDir: /app
          initContainers:
            - command:
                - sh
                - -c
                - until nc -z cache.eyelevel.svc.cluster.local 6379; do echo waiting for cache; sleep 2; done
              image: public.ecr.aws/c9r4x6y5/eyelevel/busybox:1.0.0
              imagePullPolicy: IfNotPresent
              name: wait-for-cache
            - command:
                - sh
                - -c
                - until nc -z minio-tenant-hl.eyelevel.svc.cluster.local 9000; do echo waiting for file storage; sleep 2; done
              image: public.ecr.aws/c9r4x6y5/eyelevel/busybox:1.0.0
              imagePullPolicy: IfNotPresent
              name: wait-for-file-storage
            - args:
                - echo 'Running ldconfig_symlink.sh on this node'; /scripts/ldconfig_symlink.sh
              command:
                - /bin/sh
                - -c
                - --
              image: public.ecr.aws/c9r4x6y5/eyelevel/busybox:1.0.0
              imagePullPolicy: IfNotPresent
              name: create-symlink
              resources:
                requests:
                  cpu: 10m
                  memory: 50Mi
              securityContext:
                privileged: true
              volumeMounts:
                - mountPath: /scripts/ldconfig_symlink.sh
                  name: layout-inference
                  subPath: ldconfig_symlink.sh
                - mountPath: /host-sbin
                  name: host-sbin
                - mountPath: /host-usr-sbin
                  name: host-usr-sbin
                - mountPath: /host-bin
                  name: host-bin
                - mountPath: /host-usr-bin
                  name: host-usr-bin
          nodeSelector:
            node: eyelevel-gpu-layout
          securityContext:
            fsGroup: 1001
            fsGroupChangePolicy: OnRootMismatch
            runAsGroup: 1001
            runAsNonRoot: true
            runAsUser: 1001
            seccompProfile:
              type: RuntimeDefault
          tolerations:
            - effect: NoSchedule
              key: node
              value: eyelevel-gpu-layout
          volumes:
            - configMap:
                name: config-models-map
              name: config-models
            - configMap:
                name: layout-config-py-map
              name: config-volume
            - configMap:
                name: layout-inference-supervisord-conf-map
              name: supervisord-volume
            - configMap:
                defaultMode: 365
                name: ldconfig-symlink-map
              name: layout-inference
            - hostPath:
                path: /sbin
                type: Directory
              name: host-sbin
            - hostPath:
                path: /usr/sbin
                type: Directory
              name: host-usr-sbin
            - hostPath:
                path: /bin
                type: Directory
              name: host-bin
            - hostPath:
                path: /usr/bin
                type: Directory
              name: host-usr-bin
  2: |
    apiVersion: apps/v1
    kind: Deployment
    metadata:
      labels:
        app: ranker-inference
        appVersion: 0.1.0
        chart: groundx-0.1.0
        heritage: Helm
        version: 0.1.0
      name: ranker-inference
      namespace: eyelevel
    spec:
      replicas: 1
      selector:
        matchLabels:
          app: ranker-inference
      template:
        metadata:
          annotations:
            config-hash: 8de2baea042228f54db256891d5da302316aab7828362929c3145cbfcfa75146
            config-models-hash: 529542d6881ddf622683f3bc8516205a5707660e0a921243b32fd51fd3573f4f
            ldconfig-symlink-hash: 9958a113394211878ece8f9030f4c08a1860e77aa75b5852bfa0691fc3faf32f
            supervisord-hash: c3de8d835a18146d0f59120a18513f20056efbb1cda896213ca789277d88a71b
          labels:
            app: ranker-inference
        spec:
          containers:
            - command:
                - /bin/sh
                - -c
                - |
                  export PYTHONPATH=/workspace:$PYTHONPATH &&  supervisord -c /workspace/supervisord.conf
              env:
                - name: POD_NAME
                  valueFrom:
                    fieldRef:
                      fieldPath: metadata.name
              image: public.ecr.aws/c9r4x6y5/eyelevel/ranker-inference:0.1.0
              imagePullPolicy: IfNotPresent
              livenessProbe:
                exec:
                  command:
                    - /bin/sh
                    - -c
                    - ps aux | grep 'ranker.celery.appSearch' | grep -v grep || exit 1
                failureThreshold: 10
                initialDelaySeconds: 60
                periodSeconds: 30
              name: ranker-inference
              readinessProbe:
                exec:
                  command:
                    - /bin/sh
                    - -c
                    - ps aux | grep 'ranker.celery.appSearch' | grep -v grep || exit 1
                initialDelaySeconds: 60
                periodSeconds: 30
              resources:
                limits:
                  nvidia.com/gpu: 1
                requests:
                  cpu: 1.5
                  memory: 1Gi
                  nvidia.com/gpu: 1
              securityContext:
                allowPrivilegeEscalation: false
                capabilities:
                  drop:
                    - ALL
                runAsGroup: 1001
                runAsNonRoot: true
                runAsUser: 1001
                seccompProfile:
                  type: RuntimeDefault
              volumeMounts:
                - mountPath: /workspace/config_models.py
                  name: config-models
                  subPath: config_models.py
                - mountPath: /workspace/config.py
                  name: config-volume
                  subPath: config.py
                - mountPath: /workspace/supervisord.conf
                  name: supervisord-volume
                  subPath: supervisord.conf
                - mountPath: /workspace/hf_models_cache
                  name: model-volume
              workingDir: /workspace
          initContainers:
            - command:
                - sh
                - -c
                - until nc -z cache.eyelevel.svc.cluster.local 6379; do echo waiting for cache; sleep 2; done
              image: public.ecr.aws/c9r4x6y5/eyelevel/busybox:1.0.0
              imagePullPolicy: IfNotPresent
              name: wait-for-cache
            - args:
                - echo 'Running ldconfig_symlink.sh on this node'; /scripts/ldconfig_symlink.sh
              command:
                - /bin/sh
                - -c
                - --
              image: public.ecr.aws/c9r4x6y5/eyelevel/busybox:1.0.0
              imagePullPolicy: IfNotPresent
              name: create-symlink
              resources:
                requests:
                  cpu: 10m
                  memory: 50Mi
              securityContext:
                privileged: true
              volumeMounts:
                - mountPath: /scripts/ldconfig_symlink.sh
                  name: ranker-inference
                  subPath: ldconfig_symlink.sh
                - mountPath: /host-sbin
                  name: host-sbin
                - mountPath: /host-usr-sbin
                  name: host-usr-sbin
                - mountPath: /host-bin
                  name: host-bin
                - mountPath: /host-usr-bin
                  name: host-usr-bin
            - command:
                - /bin/sh
                - -c
                - |
                  download_and_extract_model() {
                    echo "Model downloading started..."

                    touch /workspace/hf_models_cache/downloading

                    echo "00 01 02" | tr ' ' '\n' | xargs -n 1 -P 5 -I {} sh -c \
                      'MAX_RETRIES=3; RETRIES=0; SUCCESS=0; PART={}; URL=https://upload.groundx.ai/ranker/model/current/model.tar.gz.part.$PART; \
                      while [ $RETRIES -lt $MAX_RETRIES ]; do \
                        echo "Download [attempt $RETRIES] ranker.tar.gz.part.$PART"; \
                        wget -q -O /workspace/hf_models_cache/ranker.tar.gz.part.$PART $URL && { echo "Downloaded ranker.tar.gz.part.$PART successfully."; SUCCESS=1; break; }; \
                        echo "Failed to download $URL. Retrying..."; RETRIES=$((RETRIES + 1)); sleep 3; \
                      done; \
                      [ $SUCCESS -eq 0 ] && { echo "Failed to download $URL after $MAX_RETRIES attempts. Exiting."; rm /workspace/hf_models_cache/downloading; exit 1; }; \
                      echo "Unzipping ranker.tar.gz.part.$PART..."; tar -xzf /workspace/hf_models_cache/ranker.tar.gz.part.$PART -C /workspace/hf_models_cache/; echo "Unzipping ranker.tar.gz.part.$PART complete...";'

                    rm /workspace/hf_models_cache/ranker.tar.*
                    rm /workspace/hf_models_cache/downloading
                    touch /workspace/hf_models_cache/complete.model
                  }
                  if [ ! -f /workspace/hf_models_cache/complete.model ]; then
                    if [ ! -f /workspace/hf_models_cache/downloading ]; then
                      download_and_extract_model
                    else
                      echo "Download in progress by another pod. Waiting..."
                      while [ -f /workspace/hf_models_cache/downloading ] || [ ! -f /workspace/hf_models_cache/complete.model ]; do
                        sleep $((3 + RANDOM % 2))
                      done

                      if [ ! -f /workspace/hf_models_cache/complete.model ]; then
                        download_and_extract_model
                      else
                        echo "Model cache ready."
                      fi
                    fi
                  else
                    echo "Model cache already exists. Skipping download."
                  fi

                  echo "Model load done."
              image: public.ecr.aws/c9r4x6y5/eyelevel/busybox:1.0.0
              imagePullPolicy: IfNotPresent
              name: download-model
              securityContext:
                allowPrivilegeEscalation: false
                capabilities:
                  drop:
                    - ALL
                runAsGroup: 1001
                runAsNonRoot: true
                runAsUser: 1001
                seccompProfile:
                  type: RuntimeDefault
              volumeMounts:
                - mountPath: /workspace/hf_models_cache
                  name: model-volume
          nodeSelector:
            node: eyelevel-gpu-ranker
          securityContext:
            fsGroup: 1001
            fsGroupChangePolicy: OnRootMismatch
            runAsGroup: 1001
            runAsNonRoot: true
            runAsUser: 1001
            seccompProfile:
              type: RuntimeDefault
          tolerations:
            - effect: NoSchedule
              key: node
              value: eyelevel-gpu-ranker
          volumes:
            - configMap:
                name: config-models-map
              name: config-models
            - configMap:
                name: ranker-config-py-map
              name: config-volume
            - configMap:
                name: ranker-inference-supervisord-conf-map
              name: supervisord-volume
            - configMap:
                defaultMode: 365
                name: ldconfig-symlink-map
              name: ranker-inference
            - hostPath:
                path: /sbin
                type: Directory
              name: host-sbin
            - hostPath:
                path: /usr/sbin
                type: Directory
              name: host-usr-sbin
            - hostPath:
                path: /bin
                type: Directory
              name: host-bin
            - hostPath:
                path: /usr/bin
                type: Directory
              name: host-usr-bin
            - name: model-volume
              persistentVolumeClaim:
                claimName: ranker-model
  3: |
    apiVersion: v1
    kind: PersistentVolumeClaim
    metadata:
      labels:
        app: ranker-inference
      name: ranker-model
      namespace: eyelevel
    spec:
      accessModes:
        - ReadWriteOnce
      resources:
        requests:
          storage: 10Gi
      storageClassName: eyelevel-pv
  4: |
    apiVersion: apps/v1
    kind: Deployment
    metadata:
      labels:
        app: summary-inference
        appVersion: 0.1.0
        chart: groundx-0.1.0
        heritage: Helm
        version: 0.1.0
      name: summary-inference
      namespace: eyelevel
    spec:
      replicas: 2
      selector:
        matchLabels:
          app: summary-inference
      template:
        metadata:
          annotations:
            config-hash: 51b3f74b62e64c36d06ea7360481e2bce39d6048899f71f252e65339efe9ee25
            config-models-hash: 529542d6881ddf622683f3bc8516205a5707660e0a921243b32fd51fd3573f4f
            ldconfig-symlink-hash: 9958a113394211878ece8f9030f4c08a1860e77aa75b5852bfa0691fc3faf32f
            supervisord-hash: a48af0c98c4a6d0aafa9d919d204e9d8b1c51e416a36f766644a6c8d11e48a90
          labels:
            app: summary-inference
        spec:
          containers:
            - command:
                - /bin/sh
                - -c
                - |
                  export PYTHONPATH=/workspace:$PYTHONPATH &&  supervisord -c /workspace/supervisord.conf
              env:
                - name: POD_NAME
                  valueFrom:
                    fieldRef:
                      fieldPath: metadata.name
              image: public.ecr.aws/c9r4x6y5/eyelevel/summary-inference:0.1.0
              imagePullPolicy: IfNotPresent
              livenessProbe:
                failureThreshold: 8
                httpGet:
                  path: /alive
                  port: 8080
                initialDelaySeconds: 30
                periodSeconds: 15
              name: summary-inference
              ports:
                - containerPort: 8080
                  protocol: TCP
              readinessProbe:
                failureThreshold: 30
                httpGet:
                  path: /health
                  port: 8080
                initialDelaySeconds: 30
                periodSeconds: 15
              resources:
                requests:
                  cpu: 500m
                  memory: 1Gi
              securityContext:
                allowPrivilegeEscalation: false
                capabilities:
                  drop:
                    - ALL
                runAsGroup: 1001
                runAsNonRoot: true
                runAsUser: 1001
                seccompProfile:
                  type: RuntimeDefault
              volumeMounts:
                - mountPath: /workspace/config_models.py
                  name: config-models
                  subPath: config_models.py
                - mountPath: /workspace/config.py
                  name: config-volume
                  subPath: config.py
                - mountPath: /workspace/supervisord.conf
                  name: supervisord-volume
                  subPath: supervisord.conf
                - mountPath: /workspace/hf_models_cache
                  name: model-volume
              workingDir: /workspace
          initContainers:
            - command:
                - sh
                - -c
                - until nc -z cache.eyelevel.svc.cluster.local 6379; do echo waiting for cache; sleep 2; done
              image: public.ecr.aws/c9r4x6y5/eyelevel/busybox:1.0.0
              imagePullPolicy: IfNotPresent
              name: wait-for-cache
            - args:
                - echo 'Running ldconfig_symlink.sh on this node'; /scripts/ldconfig_symlink.sh
              command:
                - /bin/sh
                - -c
                - --
              image: public.ecr.aws/c9r4x6y5/eyelevel/busybox:1.0.0
              imagePullPolicy: IfNotPresent
              name: create-symlink
              resources:
                requests:
                  cpu: 10m
                  memory: 50Mi
              securityContext:
                privileged: true
              volumeMounts:
                - mountPath: /scripts/ldconfig_symlink.sh
                  name: summary-inference
                  subPath: ldconfig_symlink.sh
                - mountPath: /host-sbin
                  name: host-sbin
                - mountPath: /host-usr-sbin
                  name: host-usr-sbin
                - mountPath: /host-bin
                  name: host-bin
                - mountPath: /host-usr-bin
                  name: host-usr-bin
            - command:
                - /bin/sh
                - -c
                - |
                  download_and_extract_model() {
                    echo "Model downloading started..."

                    touch /workspace/hf_models_cache/downloading

                    echo "00 01 02 03 04" | tr ' ' '\n' | xargs -n 1 -P 5 -I {} sh -c \
                      'MAX_RETRIES=3; RETRIES=0; SUCCESS=0; PART={}; URL=https://upload.groundx.ai/summary/model/current/g34b.tar.gz.part.$PART; \
                      while [ $RETRIES -lt $MAX_RETRIES ]; do \
                        echo "Download [attempt $RETRIES] summary.tar.gz.part.$PART"; \
                        wget -q -O /workspace/hf_models_cache/summary.tar.gz.part.$PART $URL && { echo "Downloaded summary.tar.gz.part.$PART successfully."; SUCCESS=1; break; }; \
                        echo "Failed to download $URL. Retrying..."; RETRIES=$((RETRIES + 1)); sleep 3; \
                      done; \
                      [ $SUCCESS -eq 0 ] && { echo "Failed to download $URL after $MAX_RETRIES attempts. Exiting."; rm /workspace/hf_models_cache/downloading; exit 1; }; \
                      echo "Unzipping summary.tar.gz.part.$PART..."; tar -xzf /workspace/hf_models_cache/summary.tar.gz.part.$PART -C /workspace/hf_models_cache/; echo "Unzipping summary.tar.gz.part.$PART complete...";'

                    rm /workspace/hf_models_cache/summary.tar.*
                    rm /workspace/hf_models_cache/downloading
                    touch /workspace/hf_models_cache/complete.g34b
                  }
                  if [ ! -f /workspace/hf_models_cache/complete.g34b ]; then
                    if [ ! -f /workspace/hf_models_cache/downloading ]; then
                      download_and_extract_model
                    else
                      echo "Download in progress by another pod. Waiting..."
                      while [ -f /workspace/hf_models_cache/downloading ] || [ ! -f /workspace/hf_models_cache/complete.g34b ]; do
                        sleep $((3 + RANDOM % 2))
                      done

                      if [ ! -f /workspace/hf_models_cache/complete.g34b ]; then
                        download_and_extract_model
                      else
                        echo "Model cache ready."
                      fi
                    fi
                  else
                    echo "Model cache already exists. Skipping download."
                  fi

                  echo "Model load done."
              image: public.ecr.aws/c9r4x6y5/eyelevel/busybox:1.0.0
              imagePullPolicy: IfNotPresent
              name: download-model
              securityContext:
                allowPrivilegeEscalation: false
                capabilities:
                  drop:
                    - ALL
                runAsGroup: 1001
                runAsNonRoot: true
                runAsUser: 1001
                seccompProfile:
                  type: RuntimeDefault
              volumeMounts:
                - mountPath: /workspace/hf_models_cache
                  name: model-volume
          nodeSelector:
            node: eyelevel-gpu-summary
          securityContext:
            fsGroup: 1001
            fsGroupChangePolicy: OnRootMismatch
            runAsGroup: 1001
            runAsNonRoot: true
            runAsUser: 1001
            seccompProfile:
              type: RuntimeDefault
          tolerations:
            - effect: NoSchedule
              key: node
              value: eyelevel-gpu-summary
          volumes:
            - configMap:
                name: config-models-map
              name: config-models
            - configMap:
                name: summary-config-py-map
              name: config-volume
            - configMap:
                name: summary-inference-supervisord-conf-map
              name: supervisord-volume
            - configMap:
                defaultMode: 365
                name: ldconfig-symlink-map
              name: summary-inference
            - hostPath:
                path: /sbin
                type: Directory
              name: host-sbin
            - hostPath:
                path: /usr/sbin
                type: Directory
              name: host-usr-sbin
            - hostPath:
                path: /bin
                type: Directory
              name: host-bin
            - hostPath:
                path: /usr/bin
                type: Directory
              name: host-usr-bin
            - name: model-volume
              persistentVolumeClaim:
                claimName: summary-model
  5: |
    apiVersion: v1
    kind: PersistentVolumeClaim
    metadata:
      labels:
        app: summary-inference
      name: summary-model
      namespace: eyelevel
    spec:
      accessModes:
        - ReadWriteOnce
      resources:
        requests:
          storage: 20Gi
      storageClassName: eyelevel-pv
'existing: inference':
  1: |
    apiVersion: apps/v1
    kind: Deployment
    metadata:
      labels:
        app: layout-inference
        appVersion: 0.1.0
        chart: groundx-0.1.0
        heritage: Helm
        version: 0.1.0
      name: layout-inference
      namespace: eyelevel
    spec:
      replicas: 1
      selector:
        matchLabels:
          app: layout-inference
      template:
        metadata:
          annotations:
            config-hash: 0de2246e3c3210e37d477190276a11b8c8a79fb3824c4b5c09fd52600870687d
            config-models-hash: 529542d6881ddf622683f3bc8516205a5707660e0a921243b32fd51fd3573f4f
            ldconfig-symlink-hash: 9958a113394211878ece8f9030f4c08a1860e77aa75b5852bfa0691fc3faf32f
            supervisord-hash: 389d025411e33663295cbafcb9d7241d27e1d8736153cd1d14fa9c1b056107fe
          labels:
            app: layout-inference
        spec:
          containers:
            - command:
                - /bin/sh
                - -c
                - |
                  export PYTHONPATH=/app:$PYTHONPATH && python /app/init-layout.py && supervisord -c /app/supervisord.conf
              env:
                - name: POD_NAME
                  valueFrom:
                    fieldRef:
                      fieldPath: metadata.name
              image: public.ecr.aws/c9r4x6y5/eyelevel/layout-inference:0.1.0
              imagePullPolicy: IfNotPresent
              livenessProbe:
                failureThreshold: 8
                httpGet:
                  path: /alive
                  port: 8080
                initialDelaySeconds: 30
                periodSeconds: 15
              name: layout-inference
              ports:
                - containerPort: 8080
                  protocol: TCP
              readinessProbe:
                failureThreshold: 30
                httpGet:
                  path: /health
                  port: 8080
                initialDelaySeconds: 30
                periodSeconds: 15
              resources:
                limits:
                  nvidia.com/gpu: 1
                requests:
                  cpu: 500m
                  memory: 2Gi
                  nvidia.com/gpu: 1
              securityContext:
                allowPrivilegeEscalation: false
                capabilities:
                  drop:
                    - ALL
                runAsGroup: 1001
                runAsNonRoot: true
                runAsUser: 1001
                seccompProfile:
                  type: RuntimeDefault
              volumeMounts:
                - mountPath: /app/config_models.py
                  name: config-models
                  subPath: config_models.py
                - mountPath: /app/config.py
                  name: config-volume
                  subPath: config.py
                - mountPath: /app/supervisord.conf
                  name: supervisord-volume
                  subPath: supervisord.conf
              workingDir: /app
          initContainers:
            - command:
                - sh
                - -c
                - until nc -z cache.existing.com 6379; do echo waiting for cache; sleep 2; done
              image: public.ecr.aws/c9r4x6y5/eyelevel/busybox:1.0.0
              imagePullPolicy: IfNotPresent
              name: wait-for-cache
            - command:
                - sh
                - -c
                - until nc -z file.existing.com 9000; do echo waiting for file storage; sleep 2; done
              image: public.ecr.aws/c9r4x6y5/eyelevel/busybox:1.0.0
              imagePullPolicy: IfNotPresent
              name: wait-for-file-storage
            - args:
                - echo 'Running ldconfig_symlink.sh on this node'; /scripts/ldconfig_symlink.sh
              command:
                - /bin/sh
                - -c
                - --
              image: public.ecr.aws/c9r4x6y5/eyelevel/busybox:1.0.0
              imagePullPolicy: IfNotPresent
              name: create-symlink
              resources:
                requests:
                  cpu: 10m
                  memory: 50Mi
              securityContext:
                privileged: true
              volumeMounts:
                - mountPath: /scripts/ldconfig_symlink.sh
                  name: layout-inference
                  subPath: ldconfig_symlink.sh
                - mountPath: /host-sbin
                  name: host-sbin
                - mountPath: /host-usr-sbin
                  name: host-usr-sbin
                - mountPath: /host-bin
                  name: host-bin
                - mountPath: /host-usr-bin
                  name: host-usr-bin
          nodeSelector:
            node: eyelevel-gpu-layout
          securityContext:
            fsGroup: 1001
            fsGroupChangePolicy: OnRootMismatch
            runAsGroup: 1001
            runAsNonRoot: true
            runAsUser: 1001
            seccompProfile:
              type: RuntimeDefault
          tolerations:
            - effect: NoSchedule
              key: node
              value: eyelevel-gpu-layout
          volumes:
            - configMap:
                name: config-models-map
              name: config-models
            - configMap:
                name: layout-config-py-map
              name: config-volume
            - configMap:
                name: layout-inference-supervisord-conf-map
              name: supervisord-volume
            - configMap:
                defaultMode: 365
                name: ldconfig-symlink-map
              name: layout-inference
            - hostPath:
                path: /sbin
                type: Directory
              name: host-sbin
            - hostPath:
                path: /usr/sbin
                type: Directory
              name: host-usr-sbin
            - hostPath:
                path: /bin
                type: Directory
              name: host-bin
            - hostPath:
                path: /usr/bin
                type: Directory
              name: host-usr-bin
  2: |
    apiVersion: apps/v1
    kind: Deployment
    metadata:
      labels:
        app: ranker-inference
        appVersion: 0.1.0
        chart: groundx-0.1.0
        heritage: Helm
        version: 0.1.0
      name: ranker-inference
      namespace: eyelevel
    spec:
      replicas: 1
      selector:
        matchLabels:
          app: ranker-inference
      template:
        metadata:
          annotations:
            config-hash: 946de7864b7709be657b4d9b5f2a8abdb8b6ff9a50cc9ce6fdb2146b07f289ee
            config-models-hash: 529542d6881ddf622683f3bc8516205a5707660e0a921243b32fd51fd3573f4f
            ldconfig-symlink-hash: 9958a113394211878ece8f9030f4c08a1860e77aa75b5852bfa0691fc3faf32f
            supervisord-hash: c3de8d835a18146d0f59120a18513f20056efbb1cda896213ca789277d88a71b
          labels:
            app: ranker-inference
        spec:
          containers:
            - command:
                - /bin/sh
                - -c
                - |
                  export PYTHONPATH=/workspace:$PYTHONPATH &&  supervisord -c /workspace/supervisord.conf
              env:
                - name: POD_NAME
                  valueFrom:
                    fieldRef:
                      fieldPath: metadata.name
              image: public.ecr.aws/c9r4x6y5/eyelevel/ranker-inference:0.1.0
              imagePullPolicy: IfNotPresent
              livenessProbe:
                exec:
                  command:
                    - /bin/sh
                    - -c
                    - ps aux | grep 'ranker.celery.appSearch' | grep -v grep || exit 1
                failureThreshold: 10
                initialDelaySeconds: 60
                periodSeconds: 30
              name: ranker-inference
              readinessProbe:
                exec:
                  command:
                    - /bin/sh
                    - -c
                    - ps aux | grep 'ranker.celery.appSearch' | grep -v grep || exit 1
                initialDelaySeconds: 60
                periodSeconds: 30
              resources:
                limits:
                  nvidia.com/gpu: 1
                requests:
                  cpu: 1.5
                  memory: 1Gi
                  nvidia.com/gpu: 1
              securityContext:
                allowPrivilegeEscalation: false
                capabilities:
                  drop:
                    - ALL
                runAsGroup: 1001
                runAsNonRoot: true
                runAsUser: 1001
                seccompProfile:
                  type: RuntimeDefault
              volumeMounts:
                - mountPath: /workspace/config_models.py
                  name: config-models
                  subPath: config_models.py
                - mountPath: /workspace/config.py
                  name: config-volume
                  subPath: config.py
                - mountPath: /workspace/supervisord.conf
                  name: supervisord-volume
                  subPath: supervisord.conf
                - mountPath: /workspace/hf_models_cache
                  name: model-volume
              workingDir: /workspace
          initContainers:
            - command:
                - sh
                - -c
                - until nc -z cache.existing.com 6379; do echo waiting for cache; sleep 2; done
              image: public.ecr.aws/c9r4x6y5/eyelevel/busybox:1.0.0
              imagePullPolicy: IfNotPresent
              name: wait-for-cache
            - args:
                - echo 'Running ldconfig_symlink.sh on this node'; /scripts/ldconfig_symlink.sh
              command:
                - /bin/sh
                - -c
                - --
              image: public.ecr.aws/c9r4x6y5/eyelevel/busybox:1.0.0
              imagePullPolicy: IfNotPresent
              name: create-symlink
              resources:
                requests:
                  cpu: 10m
                  memory: 50Mi
              securityContext:
                privileged: true
              volumeMounts:
                - mountPath: /scripts/ldconfig_symlink.sh
                  name: ranker-inference
                  subPath: ldconfig_symlink.sh
                - mountPath: /host-sbin
                  name: host-sbin
                - mountPath: /host-usr-sbin
                  name: host-usr-sbin
                - mountPath: /host-bin
                  name: host-bin
                - mountPath: /host-usr-bin
                  name: host-usr-bin
            - command:
                - /bin/sh
                - -c
                - |
                  download_and_extract_model() {
                    echo "Model downloading started..."

                    touch /workspace/hf_models_cache/downloading

                    echo "00 01 02" | tr ' ' '\n' | xargs -n 1 -P 5 -I {} sh -c \
                      'MAX_RETRIES=3; RETRIES=0; SUCCESS=0; PART={}; URL=https://upload.groundx.ai/ranker/model/current/model.tar.gz.part.$PART; \
                      while [ $RETRIES -lt $MAX_RETRIES ]; do \
                        echo "Download [attempt $RETRIES] ranker.tar.gz.part.$PART"; \
                        wget -q -O /workspace/hf_models_cache/ranker.tar.gz.part.$PART $URL && { echo "Downloaded ranker.tar.gz.part.$PART successfully."; SUCCESS=1; break; }; \
                        echo "Failed to download $URL. Retrying..."; RETRIES=$((RETRIES + 1)); sleep 3; \
                      done; \
                      [ $SUCCESS -eq 0 ] && { echo "Failed to download $URL after $MAX_RETRIES attempts. Exiting."; rm /workspace/hf_models_cache/downloading; exit 1; }; \
                      echo "Unzipping ranker.tar.gz.part.$PART..."; tar -xzf /workspace/hf_models_cache/ranker.tar.gz.part.$PART -C /workspace/hf_models_cache/; echo "Unzipping ranker.tar.gz.part.$PART complete...";'

                    rm /workspace/hf_models_cache/ranker.tar.*
                    rm /workspace/hf_models_cache/downloading
                    touch /workspace/hf_models_cache/complete.model
                  }
                  if [ ! -f /workspace/hf_models_cache/complete.model ]; then
                    if [ ! -f /workspace/hf_models_cache/downloading ]; then
                      download_and_extract_model
                    else
                      echo "Download in progress by another pod. Waiting..."
                      while [ -f /workspace/hf_models_cache/downloading ] || [ ! -f /workspace/hf_models_cache/complete.model ]; do
                        sleep $((3 + RANDOM % 2))
                      done

                      if [ ! -f /workspace/hf_models_cache/complete.model ]; then
                        download_and_extract_model
                      else
                        echo "Model cache ready."
                      fi
                    fi
                  else
                    echo "Model cache already exists. Skipping download."
                  fi

                  echo "Model load done."
              image: public.ecr.aws/c9r4x6y5/eyelevel/busybox:1.0.0
              imagePullPolicy: IfNotPresent
              name: download-model
              securityContext:
                allowPrivilegeEscalation: false
                capabilities:
                  drop:
                    - ALL
                runAsGroup: 1001
                runAsNonRoot: true
                runAsUser: 1001
                seccompProfile:
                  type: RuntimeDefault
              volumeMounts:
                - mountPath: /workspace/hf_models_cache
                  name: model-volume
          nodeSelector:
            node: eyelevel-gpu-ranker
          securityContext:
            fsGroup: 1001
            fsGroupChangePolicy: OnRootMismatch
            runAsGroup: 1001
            runAsNonRoot: true
            runAsUser: 1001
            seccompProfile:
              type: RuntimeDefault
          tolerations:
            - effect: NoSchedule
              key: node
              value: eyelevel-gpu-ranker
          volumes:
            - configMap:
                name: config-models-map
              name: config-models
            - configMap:
                name: ranker-config-py-map
              name: config-volume
            - configMap:
                name: ranker-inference-supervisord-conf-map
              name: supervisord-volume
            - configMap:
                defaultMode: 365
                name: ldconfig-symlink-map
              name: ranker-inference
            - hostPath:
                path: /sbin
                type: Directory
              name: host-sbin
            - hostPath:
                path: /usr/sbin
                type: Directory
              name: host-usr-sbin
            - hostPath:
                path: /bin
                type: Directory
              name: host-bin
            - hostPath:
                path: /usr/bin
                type: Directory
              name: host-usr-bin
            - name: model-volume
              persistentVolumeClaim:
                claimName: ranker-model
  3: |
    apiVersion: v1
    kind: PersistentVolumeClaim
    metadata:
      labels:
        app: ranker-inference
      name: ranker-model
      namespace: eyelevel
    spec:
      accessModes:
        - ReadWriteOnce
      resources:
        requests:
          storage: 10Gi
      storageClassName: eyelevel-pv
'extract.microservice: inference':
  1: |
    apiVersion: apps/v1
    kind: Deployment
    metadata:
      labels:
        app: layout-inference
        appVersion: 0.1.0
        chart: groundx-0.1.0
        heritage: Helm
        version: 0.1.0
      name: layout-inference
      namespace: eyelevel
    spec:
      replicas: 2
      selector:
        matchLabels:
          app: layout-inference
      template:
        metadata:
          annotations:
            config-hash: 85dbe7ef96e5e50dfb1748bbfc2a95233bdd20a32502740ce2aa3925611fef31
            config-models-hash: 529542d6881ddf622683f3bc8516205a5707660e0a921243b32fd51fd3573f4f
            supervisord-hash: 389d025411e33663295cbafcb9d7241d27e1d8736153cd1d14fa9c1b056107fe
          labels:
            app: layout-inference
        spec:
          containers:
            - command:
                - /bin/sh
                - -c
                - |
                  export PYTHONPATH=/app:$PYTHONPATH && python /app/init-layout.py && supervisord -c /app/supervisord.conf
              env:
                - name: POD_NAME
                  valueFrom:
                    fieldRef:
                      fieldPath: metadata.name
              image: public.ecr.aws/c9r4x6y5/eyelevel/layout-inference:0.1.0
              imagePullPolicy: Always
              livenessProbe:
                failureThreshold: 8
                httpGet:
                  path: /alive
                  port: 8080
                initialDelaySeconds: 30
                periodSeconds: 15
              name: layout-inference
              ports:
                - containerPort: 8080
                  protocol: TCP
              readinessProbe:
                failureThreshold: 30
                httpGet:
                  path: /health
                  port: 8080
                initialDelaySeconds: 30
                periodSeconds: 15
              resources:
                limits:
                  nvidia.com/gpu: 1
                requests:
                  cpu: 500m
                  memory: 2Gi
                  nvidia.com/gpu: 1
              securityContext:
                allowPrivilegeEscalation: false
                capabilities:
                  drop:
                    - ALL
                runAsNonRoot: true
                seccompProfile:
                  type: RuntimeDefault
              volumeMounts:
                - mountPath: /app/config_models.py
                  name: config-models
                  subPath: config_models.py
                - mountPath: /app/config.py
                  name: config-volume
                  subPath: config.py
                - mountPath: /app/supervisord.conf
                  name: supervisord-volume
                  subPath: supervisord.conf
              workingDir: /app
          initContainers:
            - command:
                - sh
                - -c
                - until nc -z cache.eyelevel.svc.cluster.local 6379; do echo waiting for cache; sleep 2; done
              image: public.ecr.aws/c9r4x6y5/eyelevel/busybox:1.0.0
              imagePullPolicy: Always
              name: wait-for-cache
            - command:
                - sh
                - -c
                - until nc -z minio-tenant-hl.eyelevel.svc.cluster.local 9000; do echo waiting for file storage; sleep 2; done
              image: public.ecr.aws/c9r4x6y5/eyelevel/busybox:1.0.0
              imagePullPolicy: Always
              name: wait-for-file-storage
          nodeSelector:
            node: eyelevel-gpu
          securityContext:
            runAsNonRoot: true
            seccompProfile:
              type: RuntimeDefault
          tolerations:
            - effect: NoSchedule
              key: node
              value: eyelevel-gpu
          volumes:
            - configMap:
                name: config-models-map
              name: config-models
            - configMap:
                name: layout-config-py-map
              name: config-volume
            - configMap:
                name: layout-inference-supervisord-conf-map
              name: supervisord-volume
  2: |
    apiVersion: apps/v1
    kind: Deployment
    metadata:
      labels:
        app: ranker-inference
        appVersion: 0.1.0
        chart: groundx-0.1.0
        heritage: Helm
        version: 0.1.0
      name: ranker-inference
      namespace: eyelevel
    spec:
      replicas: 4
      selector:
        matchLabels:
          app: ranker-inference
      template:
        metadata:
          annotations:
            config-hash: 12670fa00af2b4327652923b4de6a502c3c291975dad44bbe6726f2b1086d7fb
            config-models-hash: 529542d6881ddf622683f3bc8516205a5707660e0a921243b32fd51fd3573f4f
            supervisord-hash: c3de8d835a18146d0f59120a18513f20056efbb1cda896213ca789277d88a71b
          labels:
            app: ranker-inference
        spec:
          containers:
            - command:
                - /bin/sh
                - -c
                - |
                  export PYTHONPATH=/workspace:$PYTHONPATH &&  supervisord -c /workspace/supervisord.conf
              env:
                - name: POD_NAME
                  valueFrom:
                    fieldRef:
                      fieldPath: metadata.name
              image: public.ecr.aws/c9r4x6y5/eyelevel/ranker-inference:0.1.0
              imagePullPolicy: Always
              livenessProbe:
                exec:
                  command:
                    - /bin/sh
                    - -c
                    - ps aux | grep 'ranker.celery.appSearch' | grep -v grep || exit 1
                failureThreshold: 10
                initialDelaySeconds: 60
                periodSeconds: 30
              name: ranker-inference
              readinessProbe:
                exec:
                  command:
                    - /bin/sh
                    - -c
                    - ps aux | grep 'ranker.celery.appSearch' | grep -v grep || exit 1
                initialDelaySeconds: 60
                periodSeconds: 30
              resources:
                limits:
                  nvidia.com/gpu: 1
                requests:
                  cpu: 1.5
                  memory: 1Gi
                  nvidia.com/gpu: 1
              securityContext:
                allowPrivilegeEscalation: false
                capabilities:
                  drop:
                    - ALL
                runAsNonRoot: true
                seccompProfile:
                  type: RuntimeDefault
              volumeMounts:
                - mountPath: /workspace/config_models.py
                  name: config-models
                  subPath: config_models.py
                - mountPath: /workspace/config.py
                  name: config-volume
                  subPath: config.py
                - mountPath: /workspace/supervisord.conf
                  name: supervisord-volume
                  subPath: supervisord.conf
                - mountPath: /workspace/hf_models_cache
                  name: model-volume
              workingDir: /workspace
          initContainers:
            - command:
                - sh
                - -c
                - until nc -z cache.eyelevel.svc.cluster.local 6379; do echo waiting for cache; sleep 2; done
              image: public.ecr.aws/c9r4x6y5/eyelevel/busybox:1.0.0
              imagePullPolicy: Always
              name: wait-for-cache
            - command:
                - /bin/sh
                - -c
                - |
                  download_and_extract_model() {
                    echo "Model downloading started..."

                    touch /workspace/hf_models_cache/downloading

                    echo "00 01 02" | tr ' ' '\n' | xargs -n 1 -P 5 -I {} sh -c \
                      'MAX_RETRIES=3; RETRIES=0; SUCCESS=0; PART={}; URL=https://upload.groundx.ai/ranker/model/current/model.tar.gz.part.$PART; \
                      while [ $RETRIES -lt $MAX_RETRIES ]; do \
                        echo "Download [attempt $RETRIES] ranker.tar.gz.part.$PART"; \
                        wget -q -O /workspace/hf_models_cache/ranker.tar.gz.part.$PART $URL && { echo "Downloaded ranker.tar.gz.part.$PART successfully."; SUCCESS=1; break; }; \
                        echo "Failed to download $URL. Retrying..."; RETRIES=$((RETRIES + 1)); sleep 3; \
                      done; \
                      [ $SUCCESS -eq 0 ] && { echo "Failed to download $URL after $MAX_RETRIES attempts. Exiting."; rm /workspace/hf_models_cache/downloading; exit 1; }; \
                      echo "Unzipping ranker.tar.gz.part.$PART..."; tar -xzf /workspace/hf_models_cache/ranker.tar.gz.part.$PART -C /workspace/hf_models_cache/; echo "Unzipping ranker.tar.gz.part.$PART complete...";'

                    rm /workspace/hf_models_cache/ranker.tar.*
                    rm /workspace/hf_models_cache/downloading
                    touch /workspace/hf_models_cache/complete.model
                  }
                  if [ ! -f /workspace/hf_models_cache/complete.model ]; then
                    if [ ! -f /workspace/hf_models_cache/downloading ]; then
                      download_and_extract_model
                    else
                      echo "Download in progress by another pod. Waiting..."
                      while [ -f /workspace/hf_models_cache/downloading ] || [ ! -f /workspace/hf_models_cache/complete.model ]; do
                        sleep $((3 + RANDOM % 2))
                      done

                      if [ ! -f /workspace/hf_models_cache/complete.model ]; then
                        download_and_extract_model
                      else
                        echo "Model cache ready."
                      fi
                    fi
                  else
                    echo "Model cache already exists. Skipping download."
                  fi

                  echo "Model load done."
              image: public.ecr.aws/c9r4x6y5/eyelevel/busybox:1.0.0
              imagePullPolicy: Always
              name: download-model
              securityContext:
                allowPrivilegeEscalation: false
                capabilities:
                  drop:
                    - ALL
                runAsNonRoot: true
                seccompProfile:
                  type: RuntimeDefault
              volumeMounts:
                - mountPath: /workspace/hf_models_cache
                  name: model-volume
          nodeSelector:
            node: eyelevel-gpu
          securityContext:
            runAsNonRoot: true
            seccompProfile:
              type: RuntimeDefault
          tolerations:
            - effect: NoSchedule
              key: node
              value: eyelevel-gpu
          volumes:
            - configMap:
                name: config-models-map
              name: config-models
            - configMap:
                name: ranker-config-py-map
              name: config-volume
            - configMap:
                name: ranker-inference-supervisord-conf-map
              name: supervisord-volume
            - name: model-volume
              persistentVolumeClaim:
                claimName: ranker-model
  3: |
    apiVersion: v1
    kind: PersistentVolumeClaim
    metadata:
      labels:
        app: ranker-inference
      name: ranker-model
      namespace: eyelevel
    spec:
      accessModes:
        - ReadWriteOnce
      resources:
        requests:
          storage: 10Gi
      storageClassName: eyelevel-pv
  4: |
    apiVersion: apps/v1
    kind: Deployment
    metadata:
      labels:
        app: summary-inference
        appVersion: 0.1.0
        chart: groundx-0.1.0
        heritage: Helm
        version: 0.1.0
      name: summary-inference
      namespace: eyelevel
    spec:
      replicas: 24
      selector:
        matchLabels:
          app: summary-inference
      template:
        metadata:
          annotations:
            config-hash: 4307fbece5ce04051de2de2bb0cb57513a97cac104ca46e86991456a0d827081
            config-models-hash: 529542d6881ddf622683f3bc8516205a5707660e0a921243b32fd51fd3573f4f
            supervisord-hash: a48af0c98c4a6d0aafa9d919d204e9d8b1c51e416a36f766644a6c8d11e48a90
          labels:
            app: summary-inference
        spec:
          containers:
            - command:
                - /bin/sh
                - -c
                - |
                  export PYTHONPATH=/workspace:$PYTHONPATH &&  supervisord -c /workspace/supervisord.conf
              env:
                - name: POD_NAME
                  valueFrom:
                    fieldRef:
                      fieldPath: metadata.name
              image: public.ecr.aws/c9r4x6y5/eyelevel/summary-inference:0.1.0
              imagePullPolicy: Always
              livenessProbe:
                failureThreshold: 8
                httpGet:
                  path: /alive
                  port: 8080
                initialDelaySeconds: 30
                periodSeconds: 15
              name: summary-inference
              ports:
                - containerPort: 8080
                  protocol: TCP
              readinessProbe:
                failureThreshold: 30
                httpGet:
                  path: /health
                  port: 8080
                initialDelaySeconds: 30
                periodSeconds: 15
              resources:
                limits:
                  nvidia.com/gpu: 1
                requests:
                  cpu: 500m
                  memory: 1Gi
                  nvidia.com/gpu: 1
              securityContext:
                allowPrivilegeEscalation: false
                capabilities:
                  drop:
                    - ALL
                runAsNonRoot: true
                seccompProfile:
                  type: RuntimeDefault
              volumeMounts:
                - mountPath: /workspace/config_models.py
                  name: config-models
                  subPath: config_models.py
                - mountPath: /workspace/config.py
                  name: config-volume
                  subPath: config.py
                - mountPath: /workspace/supervisord.conf
                  name: supervisord-volume
                  subPath: supervisord.conf
                - mountPath: /workspace/hf_models_cache
                  name: model-volume
              workingDir: /workspace
          initContainers:
            - command:
                - sh
                - -c
                - until nc -z cache.eyelevel.svc.cluster.local 6379; do echo waiting for cache; sleep 2; done
              image: public.ecr.aws/c9r4x6y5/eyelevel/busybox:1.0.0
              imagePullPolicy: Always
              name: wait-for-cache
            - command:
                - /bin/sh
                - -c
                - |
                  download_and_extract_model() {
                    echo "Model downloading started..."

                    touch /workspace/hf_models_cache/downloading

                    echo "00 01 02 03 04" | tr ' ' '\n' | xargs -n 1 -P 5 -I {} sh -c \
                      'MAX_RETRIES=3; RETRIES=0; SUCCESS=0; PART={}; URL=https://upload.groundx.ai/summary/model/current/g34b.tar.gz.part.$PART; \
                      while [ $RETRIES -lt $MAX_RETRIES ]; do \
                        echo "Download [attempt $RETRIES] summary.tar.gz.part.$PART"; \
                        wget -q -O /workspace/hf_models_cache/summary.tar.gz.part.$PART $URL && { echo "Downloaded summary.tar.gz.part.$PART successfully."; SUCCESS=1; break; }; \
                        echo "Failed to download $URL. Retrying..."; RETRIES=$((RETRIES + 1)); sleep 3; \
                      done; \
                      [ $SUCCESS -eq 0 ] && { echo "Failed to download $URL after $MAX_RETRIES attempts. Exiting."; rm /workspace/hf_models_cache/downloading; exit 1; }; \
                      echo "Unzipping summary.tar.gz.part.$PART..."; tar -xzf /workspace/hf_models_cache/summary.tar.gz.part.$PART -C /workspace/hf_models_cache/; echo "Unzipping summary.tar.gz.part.$PART complete...";'

                    rm /workspace/hf_models_cache/summary.tar.*
                    rm /workspace/hf_models_cache/downloading
                    touch /workspace/hf_models_cache/complete.g34b
                  }
                  if [ ! -f /workspace/hf_models_cache/complete.g34b ]; then
                    if [ ! -f /workspace/hf_models_cache/downloading ]; then
                      download_and_extract_model
                    else
                      echo "Download in progress by another pod. Waiting..."
                      while [ -f /workspace/hf_models_cache/downloading ] || [ ! -f /workspace/hf_models_cache/complete.g34b ]; do
                        sleep $((3 + RANDOM % 2))
                      done

                      if [ ! -f /workspace/hf_models_cache/complete.g34b ]; then
                        download_and_extract_model
                      else
                        echo "Model cache ready."
                      fi
                    fi
                  else
                    echo "Model cache already exists. Skipping download."
                  fi

                  echo "Model load done."
              image: public.ecr.aws/c9r4x6y5/eyelevel/busybox:1.0.0
              imagePullPolicy: Always
              name: download-model
              securityContext:
                allowPrivilegeEscalation: false
                capabilities:
                  drop:
                    - ALL
                runAsNonRoot: true
                seccompProfile:
                  type: RuntimeDefault
              volumeMounts:
                - mountPath: /workspace/hf_models_cache
                  name: model-volume
          nodeSelector:
            node: eyelevel-gpu
          securityContext:
            runAsNonRoot: true
            seccompProfile:
              type: RuntimeDefault
          tolerations:
            - effect: NoSchedule
              key: node
              value: eyelevel-gpu
          volumes:
            - configMap:
                name: config-models-map
              name: config-models
            - configMap:
                name: summary-config-py-map
              name: config-volume
            - configMap:
                name: summary-inference-supervisord-conf-map
              name: supervisord-volume
            - name: model-volume
              persistentVolumeClaim:
                claimName: summary-model
  5: |
    apiVersion: v1
    kind: PersistentVolumeClaim
    metadata:
      labels:
        app: summary-inference
      name: summary-model
      namespace: eyelevel
    spec:
      accessModes:
        - ReadWriteOnce
      resources:
        requests:
          storage: 20Gi
      storageClassName: eyelevel-pv
'extract: inference':
  1: |
    apiVersion: apps/v1
    kind: Deployment
    metadata:
      labels:
        app: layout-inference
        appVersion: 0.1.0
        chart: groundx-0.1.0
        heritage: Helm
        version: 0.1.0
      name: layout-inference
      namespace: eyelevel
    spec:
      replicas: 1
      selector:
        matchLabels:
          app: layout-inference
      template:
        metadata:
          annotations:
            config-hash: 312ea833a17a4544bad67918bc525c13e4f4d596f8964967521f84d7e154b769
            config-models-hash: 529542d6881ddf622683f3bc8516205a5707660e0a921243b32fd51fd3573f4f
            ldconfig-symlink-hash: 9958a113394211878ece8f9030f4c08a1860e77aa75b5852bfa0691fc3faf32f
            supervisord-hash: 389d025411e33663295cbafcb9d7241d27e1d8736153cd1d14fa9c1b056107fe
          labels:
            app: layout-inference
        spec:
          containers:
            - command:
                - /bin/sh
                - -c
                - |
                  export PYTHONPATH=/app:$PYTHONPATH && python /app/init-layout.py && supervisord -c /app/supervisord.conf
              env:
                - name: POD_NAME
                  valueFrom:
                    fieldRef:
                      fieldPath: metadata.name
              image: public.ecr.aws/c9r4x6y5/eyelevel/layout-inference:0.1.0
              imagePullPolicy: IfNotPresent
              livenessProbe:
                failureThreshold: 8
                httpGet:
                  path: /alive
                  port: 8080
                initialDelaySeconds: 30
                periodSeconds: 15
              name: layout-inference
              ports:
                - containerPort: 8080
                  protocol: TCP
              readinessProbe:
                failureThreshold: 30
                httpGet:
                  path: /health
                  port: 8080
                initialDelaySeconds: 30
                periodSeconds: 15
              resources:
                limits:
                  nvidia.com/gpu: 1
                requests:
                  cpu: 500m
                  memory: 2Gi
                  nvidia.com/gpu: 1
              securityContext:
                allowPrivilegeEscalation: false
                capabilities:
                  drop:
                    - ALL
                runAsGroup: 1001
                runAsNonRoot: true
                runAsUser: 1001
                seccompProfile:
                  type: RuntimeDefault
              volumeMounts:
                - mountPath: /app/config_models.py
                  name: config-models
                  subPath: config_models.py
                - mountPath: /app/config.py
                  name: config-volume
                  subPath: config.py
                - mountPath: /app/supervisord.conf
                  name: supervisord-volume
                  subPath: supervisord.conf
              workingDir: /app
          initContainers:
            - command:
                - sh
                - -c
                - until nc -z X.X.X.use2.cache.amazonaws.com 6379; do echo waiting for cache; sleep 2; done
              image: public.ecr.aws/c9r4x6y5/eyelevel/busybox:1.0.0
              imagePullPolicy: IfNotPresent
              name: wait-for-cache
            - command:
                - sh
                - -c
                - until nc -z X.s3.us-west-2.amazonaws.com 443; do echo waiting for file storage; sleep 2; done
              image: public.ecr.aws/c9r4x6y5/eyelevel/busybox:1.0.0
              imagePullPolicy: IfNotPresent
              name: wait-for-file-storage
            - args:
                - echo 'Running ldconfig_symlink.sh on this node'; /scripts/ldconfig_symlink.sh
              command:
                - /bin/sh
                - -c
                - --
              image: public.ecr.aws/c9r4x6y5/eyelevel/busybox:1.0.0
              imagePullPolicy: IfNotPresent
              name: create-symlink
              resources:
                requests:
                  cpu: 10m
                  memory: 50Mi
              securityContext:
                privileged: true
              volumeMounts:
                - mountPath: /scripts/ldconfig_symlink.sh
                  name: layout-inference
                  subPath: ldconfig_symlink.sh
                - mountPath: /host-sbin
                  name: host-sbin
                - mountPath: /host-usr-sbin
                  name: host-usr-sbin
                - mountPath: /host-bin
                  name: host-bin
                - mountPath: /host-usr-bin
                  name: host-usr-bin
          nodeSelector:
            node: eyelevel-gpu-layout
          securityContext:
            fsGroup: 1001
            fsGroupChangePolicy: OnRootMismatch
            runAsGroup: 1001
            runAsNonRoot: true
            runAsUser: 1001
            seccompProfile:
              type: RuntimeDefault
          tolerations:
            - effect: NoSchedule
              key: node
              value: eyelevel-gpu-layout
          volumes:
            - configMap:
                name: config-models-map
              name: config-models
            - configMap:
                name: layout-config-py-map
              name: config-volume
            - configMap:
                name: layout-inference-supervisord-conf-map
              name: supervisord-volume
            - configMap:
                defaultMode: 365
                name: ldconfig-symlink-map
              name: layout-inference
            - hostPath:
                path: /sbin
                type: Directory
              name: host-sbin
            - hostPath:
                path: /usr/sbin
                type: Directory
              name: host-usr-sbin
            - hostPath:
                path: /bin
                type: Directory
              name: host-bin
            - hostPath:
                path: /usr/bin
                type: Directory
              name: host-usr-bin
  2: |
    apiVersion: apps/v1
    kind: Deployment
    metadata:
      labels:
        app: summary-inference
        appVersion: 0.1.0
        chart: groundx-0.1.0
        heritage: Helm
        version: 0.1.0
      name: summary-inference
      namespace: eyelevel
    spec:
      replicas: 2
      selector:
        matchLabels:
          app: summary-inference
      template:
        metadata:
          annotations:
            config-hash: 2e9432e7927d2f5c53c8cdb87fa2a9a545c618f950c4ea653afe64e36ae0aa39
            config-models-hash: 529542d6881ddf622683f3bc8516205a5707660e0a921243b32fd51fd3573f4f
            ldconfig-symlink-hash: 9958a113394211878ece8f9030f4c08a1860e77aa75b5852bfa0691fc3faf32f
            supervisord-hash: a48af0c98c4a6d0aafa9d919d204e9d8b1c51e416a36f766644a6c8d11e48a90
          labels:
            app: summary-inference
        spec:
          containers:
            - command:
                - /bin/sh
                - -c
                - |
                  export PYTHONPATH=/workspace:$PYTHONPATH &&  supervisord -c /workspace/supervisord.conf
              env:
                - name: POD_NAME
                  valueFrom:
                    fieldRef:
                      fieldPath: metadata.name
              image: public.ecr.aws/c9r4x6y5/eyelevel/summary-inference:0.1.0
              imagePullPolicy: IfNotPresent
              livenessProbe:
                failureThreshold: 8
                httpGet:
                  path: /alive
                  port: 8080
                initialDelaySeconds: 30
                periodSeconds: 15
              name: summary-inference
              ports:
                - containerPort: 8080
                  protocol: TCP
              readinessProbe:
                failureThreshold: 30
                httpGet:
                  path: /health
                  port: 8080
                initialDelaySeconds: 30
                periodSeconds: 15
              resources:
                requests:
                  cpu: 500m
                  memory: 1Gi
              securityContext:
                allowPrivilegeEscalation: false
                capabilities:
                  drop:
                    - ALL
                runAsGroup: 1001
                runAsNonRoot: true
                runAsUser: 1001
                seccompProfile:
                  type: RuntimeDefault
              volumeMounts:
                - mountPath: /workspace/config_models.py
                  name: config-models
                  subPath: config_models.py
                - mountPath: /workspace/config.py
                  name: config-volume
                  subPath: config.py
                - mountPath: /workspace/supervisord.conf
                  name: supervisord-volume
                  subPath: supervisord.conf
                - mountPath: /workspace/hf_models_cache
                  name: model-volume
              workingDir: /workspace
          initContainers:
            - command:
                - sh
                - -c
                - until nc -z X.X.X.use2.cache.amazonaws.com 6379; do echo waiting for cache; sleep 2; done
              image: public.ecr.aws/c9r4x6y5/eyelevel/busybox:1.0.0
              imagePullPolicy: IfNotPresent
              name: wait-for-cache
            - args:
                - echo 'Running ldconfig_symlink.sh on this node'; /scripts/ldconfig_symlink.sh
              command:
                - /bin/sh
                - -c
                - --
              image: public.ecr.aws/c9r4x6y5/eyelevel/busybox:1.0.0
              imagePullPolicy: IfNotPresent
              name: create-symlink
              resources:
                requests:
                  cpu: 10m
                  memory: 50Mi
              securityContext:
                privileged: true
              volumeMounts:
                - mountPath: /scripts/ldconfig_symlink.sh
                  name: summary-inference
                  subPath: ldconfig_symlink.sh
                - mountPath: /host-sbin
                  name: host-sbin
                - mountPath: /host-usr-sbin
                  name: host-usr-sbin
                - mountPath: /host-bin
                  name: host-bin
                - mountPath: /host-usr-bin
                  name: host-usr-bin
            - command:
                - /bin/sh
                - -c
                - |
                  download_and_extract_model() {
                    echo "Model downloading started..."

                    touch /workspace/hf_models_cache/downloading

                    echo "00 01 02 03 04" | tr ' ' '\n' | xargs -n 1 -P 5 -I {} sh -c \
                      'MAX_RETRIES=3; RETRIES=0; SUCCESS=0; PART={}; URL=https://upload.groundx.ai/summary/model/current/g34b.tar.gz.part.$PART; \
                      while [ $RETRIES -lt $MAX_RETRIES ]; do \
                        echo "Download [attempt $RETRIES] summary.tar.gz.part.$PART"; \
                        wget -q -O /workspace/hf_models_cache/summary.tar.gz.part.$PART $URL && { echo "Downloaded summary.tar.gz.part.$PART successfully."; SUCCESS=1; break; }; \
                        echo "Failed to download $URL. Retrying..."; RETRIES=$((RETRIES + 1)); sleep 3; \
                      done; \
                      [ $SUCCESS -eq 0 ] && { echo "Failed to download $URL after $MAX_RETRIES attempts. Exiting."; rm /workspace/hf_models_cache/downloading; exit 1; }; \
                      echo "Unzipping summary.tar.gz.part.$PART..."; tar -xzf /workspace/hf_models_cache/summary.tar.gz.part.$PART -C /workspace/hf_models_cache/; echo "Unzipping summary.tar.gz.part.$PART complete...";'

                    rm /workspace/hf_models_cache/summary.tar.*
                    rm /workspace/hf_models_cache/downloading
                    touch /workspace/hf_models_cache/complete.g34b
                  }
                  if [ ! -f /workspace/hf_models_cache/complete.g34b ]; then
                    if [ ! -f /workspace/hf_models_cache/downloading ]; then
                      download_and_extract_model
                    else
                      echo "Download in progress by another pod. Waiting..."
                      while [ -f /workspace/hf_models_cache/downloading ] || [ ! -f /workspace/hf_models_cache/complete.g34b ]; do
                        sleep $((3 + RANDOM % 2))
                      done

                      if [ ! -f /workspace/hf_models_cache/complete.g34b ]; then
                        download_and_extract_model
                      else
                        echo "Model cache ready."
                      fi
                    fi
                  else
                    echo "Model cache already exists. Skipping download."
                  fi

                  echo "Model load done."
              image: public.ecr.aws/c9r4x6y5/eyelevel/busybox:1.0.0
              imagePullPolicy: IfNotPresent
              name: download-model
              securityContext:
                allowPrivilegeEscalation: false
                capabilities:
                  drop:
                    - ALL
                runAsGroup: 1001
                runAsNonRoot: true
                runAsUser: 1001
                seccompProfile:
                  type: RuntimeDefault
              volumeMounts:
                - mountPath: /workspace/hf_models_cache
                  name: model-volume
          nodeSelector:
            node: eyelevel-gpu-summary
          securityContext:
            fsGroup: 1001
            fsGroupChangePolicy: OnRootMismatch
            runAsGroup: 1001
            runAsNonRoot: true
            runAsUser: 1001
            seccompProfile:
              type: RuntimeDefault
          tolerations:
            - effect: NoSchedule
              key: node
              value: eyelevel-gpu-summary
          volumes:
            - configMap:
                name: config-models-map
              name: config-models
            - configMap:
                name: summary-config-py-map
              name: config-volume
            - configMap:
                name: summary-inference-supervisord-conf-map
              name: supervisord-volume
            - configMap:
                defaultMode: 365
                name: ldconfig-symlink-map
              name: summary-inference
            - hostPath:
                path: /sbin
                type: Directory
              name: host-sbin
            - hostPath:
                path: /usr/sbin
                type: Directory
              name: host-usr-sbin
            - hostPath:
                path: /bin
                type: Directory
              name: host-bin
            - hostPath:
                path: /usr/bin
                type: Directory
              name: host-usr-bin
            - name: model-volume
              persistentVolumeClaim:
                claimName: summary-model
  3: |
    apiVersion: v1
    kind: PersistentVolumeClaim
    metadata:
      labels:
        app: summary-inference
      name: summary-model
      namespace: eyelevel
    spec:
      accessModes:
        - ReadWriteOnce
      resources:
        requests:
          storage: 20Gi
      storageClassName: eyelevel-pv
'metadata: inference':
  1: |
    apiVersion: apps/v1
    kind: Deployment
    metadata:
      labels:
        app: myapp-inference
        appVersion: 0.1.0
        chart: groundx-0.1.0
        heritage: Helm
        version: 0.1.0
      name: myapp-inference
      namespace: eyelevel
    spec:
      replicas: 1
      selector:
        matchLabels:
          app: myapp-inference
      template:
        metadata:
          annotations:
            config-hash: f01ce7380e7f90d9ad1a77d0643c31af59769c162513beb386dccdb47f653e9f
            config-models-hash: 06ba464c30a765382364510ccee1e65088f7d2acbc11a746b7d14d84c220dd3b
            ldconfig-symlink-hash: 9958a113394211878ece8f9030f4c08a1860e77aa75b5852bfa0691fc3faf32f
            prometheus.io/port: "8081"
            supervisord-hash: b39bd7d75862c4a85780b4e3d76fe459b3beaa52f391376e7c95cb26ef6068ec
          labels:
            app: myapp-inference
            app.kubernetes.io/name: myapp
        spec:
          affinity:
            requiredDuringSchedulingIgnoredDuringExecution:
              - labelSelector:
                  matchExpressions:
                    - key: app
                      operator: In
                      values:
                        - myapp
                topologyKey: kubernetes.io/hostname
          containers:
            - command:
                - /bin/sh
                - -c
                - |
                  export PYTHONPATH=/app:$PYTHONPATH && python /app/init-layout.py && supervisord -c /app/supervisord.conf
              env:
                - name: POD_NAME
                  valueFrom:
                    fieldRef:
                      fieldPath: metadata.name
              image: test.image:v1
              imagePullPolicy: Never
              livenessProbe:
                failureThreshold: 8
                httpGet:
                  path: /alive
                  port: 8081
                initialDelaySeconds: 30
                periodSeconds: 15
              name: myapp-inference
              ports:
                - containerPort: 8081
                  protocol: TCP
              readinessProbe:
                failureThreshold: 30
                httpGet:
                  path: /health
                  port: 8081
                initialDelaySeconds: 30
                periodSeconds: 15
              resources:
                limits:
                  nvidia.com/gpu: 1
                requests:
                  cpu: 500m
                  memory: 2Gi
                  nvidia.com/gpu: 1
              securityContext:
                readOnlyRootFilesystem: true
              volumeMounts:
                - mountPath: /app/config_models.py
                  name: config-models
                  subPath: config_models.py
                - mountPath: /app/config.py
                  name: config-volume
                  subPath: config.py
                - mountPath: /app/supervisord.conf
                  name: supervisord-volume
                  subPath: supervisord.conf
              workingDir: /app
          initContainers:
            - command:
                - sh
                - -c
                - until nc -z myapp.eyelevel.svc.cluster.local 6377; do echo waiting for cache; sleep 2; done
              image: test.image:v1
              imagePullPolicy: Always
              name: wait-for-cache
            - command:
                - sh
                - -c
                - until nc -z minio-tenant-hl.eyelevel.svc.cluster.local 9000; do echo waiting for file storage; sleep 2; done
              image: test.image:v1
              imagePullPolicy: Always
              name: wait-for-file-storage
            - args:
                - echo 'Running ldconfig_symlink.sh on this node'; /scripts/ldconfig_symlink.sh
              command:
                - /bin/sh
                - -c
                - --
              image: test.image:v1
              imagePullPolicy: Always
              name: create-symlink
              resources:
                requests:
                  cpu: 10m
                  memory: 50Mi
              securityContext:
                privileged: true
              volumeMounts:
                - mountPath: /scripts/ldconfig_symlink.sh
                  name: myapp-inference
                  subPath: ldconfig_symlink.sh
                - mountPath: /host-sbin
                  name: host-sbin
                - mountPath: /host-usr-sbin
                  name: host-usr-sbin
                - mountPath: /host-bin
                  name: host-bin
                - mountPath: /host-usr-bin
                  name: host-usr-bin
          nodeSelector:
            disktype: ssd
          securityContext:
            fsGroup: 2000
          tolerations:
            - effect: NoSchedule
              key: node
              value: test-label-1
          volumes:
            - configMap:
                name: config-models-map
              name: config-models
            - configMap:
                name: myapp-config-py-map
              name: config-volume
            - configMap:
                name: myapp-inference-supervisord-conf-map
              name: supervisord-volume
            - configMap:
                defaultMode: 365
                name: ldconfig-symlink-map
              name: myapp-inference
            - hostPath:
                path: /sbin
                type: Directory
              name: host-sbin
            - hostPath:
                path: /usr/sbin
                type: Directory
              name: host-usr-sbin
            - hostPath:
                path: /bin
                type: Directory
              name: host-bin
            - hostPath:
                path: /usr/bin
                type: Directory
              name: host-usr-bin
  2: |
    apiVersion: apps/v1
    kind: Deployment
    metadata:
      labels:
        app: myapp-inference
        appVersion: 0.1.0
        chart: groundx-0.1.0
        heritage: Helm
        version: 0.1.0
      name: myapp-inference
      namespace: eyelevel
    spec:
      replicas: 1
      selector:
        matchLabels:
          app: myapp-inference
      template:
        metadata:
          annotations:
            config-hash: 3ff5970cb3358e2055b9f63e2c99858bce5cf7f8021276fe621669c4d7a6095b
            config-models-hash: 06ba464c30a765382364510ccee1e65088f7d2acbc11a746b7d14d84c220dd3b
            ldconfig-symlink-hash: 9958a113394211878ece8f9030f4c08a1860e77aa75b5852bfa0691fc3faf32f
            supervisord-hash: a16c30167d8dc53d033246f4104113e03f8726f3a97dc8a7bb0af9a936a58c80
          labels:
            app: myapp-inference
        spec:
          containers:
            - command:
                - /bin/sh
                - -c
                - |
                  export PYTHONPATH=/workspace:$PYTHONPATH &&  supervisord -c /workspace/supervisord.conf
              env:
                - name: POD_NAME
                  valueFrom:
                    fieldRef:
                      fieldPath: metadata.name
              image: public.ecr.aws/c9r4x6y5/eyelevel/ranker-inference:0.1.0
              imagePullPolicy: IfNotPresent
              livenessProbe:
                exec:
                  command:
                    - /bin/sh
                    - -c
                    - ps aux | grep 'ranker.celery.appSearch' | grep -v grep || exit 1
                failureThreshold: 10
                initialDelaySeconds: 60
                periodSeconds: 30
              name: myapp-inference
              readinessProbe:
                exec:
                  command:
                    - /bin/sh
                    - -c
                    - ps aux | grep 'ranker.celery.appSearch' | grep -v grep || exit 1
                initialDelaySeconds: 60
                periodSeconds: 30
              resources:
                limits:
                  nvidia.com/gpu: 1
                requests:
                  cpu: 1.5
                  memory: 1Gi
                  nvidia.com/gpu: 1
              securityContext:
                allowPrivilegeEscalation: false
                capabilities:
                  drop:
                    - ALL
                runAsGroup: 1001
                runAsNonRoot: true
                runAsUser: 1001
                seccompProfile:
                  type: RuntimeDefault
              volumeMounts:
                - mountPath: /workspace/config_models.py
                  name: config-models
                  subPath: config_models.py
                - mountPath: /workspace/config.py
                  name: config-volume
                  subPath: config.py
                - mountPath: /workspace/supervisord.conf
                  name: supervisord-volume
                  subPath: supervisord.conf
                - mountPath: /workspace/hf_models_cache
                  name: model-volume
              workingDir: /workspace
          initContainers:
            - command:
                - sh
                - -c
                - until nc -z myapp.eyelevel.svc.cluster.local 6377; do echo waiting for cache; sleep 2; done
              image: test.image:v1
              imagePullPolicy: Always
              name: wait-for-cache
            - args:
                - echo 'Running ldconfig_symlink.sh on this node'; /scripts/ldconfig_symlink.sh
              command:
                - /bin/sh
                - -c
                - --
              image: test.image:v1
              imagePullPolicy: Always
              name: create-symlink
              resources:
                requests:
                  cpu: 10m
                  memory: 50Mi
              securityContext:
                privileged: true
              volumeMounts:
                - mountPath: /scripts/ldconfig_symlink.sh
                  name: myapp-inference
                  subPath: ldconfig_symlink.sh
                - mountPath: /host-sbin
                  name: host-sbin
                - mountPath: /host-usr-sbin
                  name: host-usr-sbin
                - mountPath: /host-bin
                  name: host-bin
                - mountPath: /host-usr-bin
                  name: host-usr-bin
            - command:
                - /bin/sh
                - -c
                - |
                  download_and_extract_model() {
                    echo "Model downloading started..."

                    touch /workspace/hf_models_cache/downloading

                    echo "00 01 02" | tr ' ' '\n' | xargs -n 1 -P 5 -I {} sh -c \
                      'MAX_RETRIES=3; RETRIES=0; SUCCESS=0; PART={}; URL=https://upload.groundx.ai/myapp/model/current/model.tar.gz.part.$PART; \
                      while [ $RETRIES -lt $MAX_RETRIES ]; do \
                        echo "Download [attempt $RETRIES] myapp.tar.gz.part.$PART"; \
                        wget -q -O /workspace/hf_models_cache/myapp.tar.gz.part.$PART $URL && { echo "Downloaded myapp.tar.gz.part.$PART successfully."; SUCCESS=1; break; }; \
                        echo "Failed to download $URL. Retrying..."; RETRIES=$((RETRIES + 1)); sleep 3; \
                      done; \
                      [ $SUCCESS -eq 0 ] && { echo "Failed to download $URL after $MAX_RETRIES attempts. Exiting."; rm /workspace/hf_models_cache/downloading; exit 1; }; \
                      echo "Unzipping myapp.tar.gz.part.$PART..."; tar -xzf /workspace/hf_models_cache/myapp.tar.gz.part.$PART -C /workspace/hf_models_cache/; echo "Unzipping myapp.tar.gz.part.$PART complete...";'

                    rm /workspace/hf_models_cache/myapp.tar.*
                    rm /workspace/hf_models_cache/downloading
                    touch /workspace/hf_models_cache/complete.model
                  }
                  if [ ! -f /workspace/hf_models_cache/complete.model ]; then
                    if [ ! -f /workspace/hf_models_cache/downloading ]; then
                      download_and_extract_model
                    else
                      echo "Download in progress by another pod. Waiting..."
                      while [ -f /workspace/hf_models_cache/downloading ] || [ ! -f /workspace/hf_models_cache/complete.model ]; do
                        sleep $((3 + RANDOM % 2))
                      done

                      if [ ! -f /workspace/hf_models_cache/complete.model ]; then
                        download_and_extract_model
                      else
                        echo "Model cache ready."
                      fi
                    fi
                  else
                    echo "Model cache already exists. Skipping download."
                  fi

                  echo "Model load done."
              image: test.image:v1
              imagePullPolicy: Always
              name: download-model
              securityContext:
                allowPrivilegeEscalation: false
                capabilities:
                  drop:
                    - ALL
                runAsGroup: 1001
                runAsNonRoot: true
                runAsUser: 1001
                seccompProfile:
                  type: RuntimeDefault
              volumeMounts:
                - mountPath: /workspace/hf_models_cache
                  name: model-volume
          nodeSelector:
            node: test-label-1
          securityContext:
            fsGroup: 1001
            fsGroupChangePolicy: OnRootMismatch
            runAsGroup: 1001
            runAsNonRoot: true
            runAsUser: 1001
            seccompProfile:
              type: RuntimeDefault
          tolerations:
            - effect: NoSchedule
              key: workload-type
              operator: Equal
              value: batch
          volumes:
            - configMap:
                name: config-models-map
              name: config-models
            - configMap:
                name: myapp-config-py-map
              name: config-volume
            - configMap:
                name: myapp-inference-supervisord-conf-map
              name: supervisord-volume
            - configMap:
                defaultMode: 365
                name: ldconfig-symlink-map
              name: myapp-inference
            - hostPath:
                path: /sbin
                type: Directory
              name: host-sbin
            - hostPath:
                path: /usr/sbin
                type: Directory
              name: host-usr-sbin
            - hostPath:
                path: /bin
                type: Directory
              name: host-bin
            - hostPath:
                path: /usr/bin
                type: Directory
              name: host-usr-bin
            - name: model-volume
              persistentVolumeClaim:
                claimName: myapp-model
  3: |
    apiVersion: v1
    kind: PersistentVolumeClaim
    metadata:
      labels:
        app: myapp-inference
      name: myapp-model
      namespace: eyelevel
    spec:
      accessModes:
        - ReadWriteOnce
      resources:
        requests:
          storage: 1Gi
      storageClassName: eyelevel-pv
  4: |
    apiVersion: apps/v1
    kind: Deployment
    metadata:
      labels:
        app: myapp-inference
        appVersion: 0.1.0
        chart: groundx-0.1.0
        heritage: Helm
        version: 0.1.0
      name: myapp-inference
      namespace: eyelevel
    spec:
      replicas: 1
      selector:
        matchLabels:
          app: myapp-inference
      template:
        metadata:
          annotations:
            config-hash: 768b67abc53462b44e924bc5c0c1e34b98ebb80bf87cc2d09b92699666194fa3
            config-models-hash: 06ba464c30a765382364510ccee1e65088f7d2acbc11a746b7d14d84c220dd3b
            ldconfig-symlink-hash: 9958a113394211878ece8f9030f4c08a1860e77aa75b5852bfa0691fc3faf32f
            prometheus.io/port: "8081"
            supervisord-hash: 2c08849e1942705d4ea6410c06e1e65ac52e10750830ae312285982559a9e0f1
          labels:
            app: myapp-inference
            app.kubernetes.io/name: myapp
        spec:
          affinity:
            requiredDuringSchedulingIgnoredDuringExecution:
              - labelSelector:
                  matchExpressions:
                    - key: app
                      operator: In
                      values:
                        - myapp
                topologyKey: kubernetes.io/hostname
          containers:
            - command:
                - /bin/sh
                - -c
                - |
                  export PYTHONPATH=/workspace:$PYTHONPATH &&  supervisord -c /workspace/supervisord.conf
              env:
                - name: POD_NAME
                  valueFrom:
                    fieldRef:
                      fieldPath: metadata.name
              image: test.image:v1
              imagePullPolicy: Never
              livenessProbe:
                failureThreshold: 8
                httpGet:
                  path: /alive
                  port: 8081
                initialDelaySeconds: 30
                periodSeconds: 15
              name: myapp-inference
              ports:
                - containerPort: 8081
                  protocol: TCP
              readinessProbe:
                failureThreshold: 30
                httpGet:
                  path: /health
                  port: 8081
                initialDelaySeconds: 30
                periodSeconds: 15
              resources:
                requests:
                  cpu: 500m
                  memory: 1Gi
              securityContext:
                readOnlyRootFilesystem: true
              volumeMounts:
                - mountPath: /workspace/config_models.py
                  name: config-models
                  subPath: config_models.py
                - mountPath: /workspace/config.py
                  name: config-volume
                  subPath: config.py
                - mountPath: /workspace/supervisord.conf
                  name: supervisord-volume
                  subPath: supervisord.conf
                - mountPath: /workspace/hf_models_cache
                  name: model-volume
              workingDir: /workspace
          initContainers:
            - command:
                - sh
                - -c
                - until nc -z myapp.eyelevel.svc.cluster.local 6377; do echo waiting for cache; sleep 2; done
              image: test.image:v1
              imagePullPolicy: Always
              name: wait-for-cache
            - args:
                - echo 'Running ldconfig_symlink.sh on this node'; /scripts/ldconfig_symlink.sh
              command:
                - /bin/sh
                - -c
                - --
              image: test.image:v1
              imagePullPolicy: Always
              name: create-symlink
              resources:
                requests:
                  cpu: 10m
                  memory: 50Mi
              securityContext:
                privileged: true
              volumeMounts:
                - mountPath: /scripts/ldconfig_symlink.sh
                  name: myapp-inference
                  subPath: ldconfig_symlink.sh
                - mountPath: /host-sbin
                  name: host-sbin
                - mountPath: /host-usr-sbin
                  name: host-usr-sbin
                - mountPath: /host-bin
                  name: host-bin
                - mountPath: /host-usr-bin
                  name: host-usr-bin
            - command:
                - /bin/sh
                - -c
                - |
                  download_and_extract_model() {
                    echo "Model downloading started..."

                    touch /workspace/hf_models_cache/downloading

                    echo "00 01 02 03 04" | tr ' ' '\n' | xargs -n 1 -P 5 -I {} sh -c \
                      'MAX_RETRIES=3; RETRIES=0; SUCCESS=0; PART={}; URL=https://upload.groundx.ai/myapp/model/current/g34b.tar.gz.part.$PART; \
                      while [ $RETRIES -lt $MAX_RETRIES ]; do \
                        echo "Download [attempt $RETRIES] myapp.tar.gz.part.$PART"; \
                        wget -q -O /workspace/hf_models_cache/myapp.tar.gz.part.$PART $URL && { echo "Downloaded myapp.tar.gz.part.$PART successfully."; SUCCESS=1; break; }; \
                        echo "Failed to download $URL. Retrying..."; RETRIES=$((RETRIES + 1)); sleep 3; \
                      done; \
                      [ $SUCCESS -eq 0 ] && { echo "Failed to download $URL after $MAX_RETRIES attempts. Exiting."; rm /workspace/hf_models_cache/downloading; exit 1; }; \
                      echo "Unzipping myapp.tar.gz.part.$PART..."; tar -xzf /workspace/hf_models_cache/myapp.tar.gz.part.$PART -C /workspace/hf_models_cache/; echo "Unzipping myapp.tar.gz.part.$PART complete...";'

                    rm /workspace/hf_models_cache/myapp.tar.*
                    rm /workspace/hf_models_cache/downloading
                    touch /workspace/hf_models_cache/complete.g34b
                  }
                  if [ ! -f /workspace/hf_models_cache/complete.g34b ]; then
                    if [ ! -f /workspace/hf_models_cache/downloading ]; then
                      download_and_extract_model
                    else
                      echo "Download in progress by another pod. Waiting..."
                      while [ -f /workspace/hf_models_cache/downloading ] || [ ! -f /workspace/hf_models_cache/complete.g34b ]; do
                        sleep $((3 + RANDOM % 2))
                      done

                      if [ ! -f /workspace/hf_models_cache/complete.g34b ]; then
                        download_and_extract_model
                      else
                        echo "Model cache ready."
                      fi
                    fi
                  else
                    echo "Model cache already exists. Skipping download."
                  fi

                  echo "Model load done."
              image: test.image:v1
              imagePullPolicy: Always
              name: download-model
              securityContext:
                readOnlyRootFilesystem: true
              volumeMounts:
                - mountPath: /workspace/hf_models_cache
                  name: model-volume
          runtimeClassName: abc
          securityContext:
            fsGroup: 2000
          volumes:
            - configMap:
                name: config-models-map
              name: config-models
            - configMap:
                name: myapp-config-py-map
              name: config-volume
            - configMap:
                name: myapp-inference-supervisord-conf-map
              name: supervisord-volume
            - configMap:
                defaultMode: 365
                name: ldconfig-symlink-map
              name: myapp-inference
            - hostPath:
                path: /sbin
                type: Directory
              name: host-sbin
            - hostPath:
                path: /usr/sbin
                type: Directory
              name: host-usr-sbin
            - hostPath:
                path: /bin
                type: Directory
              name: host-bin
            - hostPath:
                path: /usr/bin
                type: Directory
              name: host-usr-bin
            - name: model-volume
              persistentVolumeClaim:
                claimName: test-pvc
  5: |
    apiVersion: v1
    kind: PersistentVolumeClaim
    metadata:
      labels:
        app: myapp-inference
      name: test-pvc
      namespace: eyelevel
    spec:
      accessModes:
        - ReadOnce
      resources:
        requests:
          storage: 20Gi
      storageClassName: test-pv
'minikube: inference':
  1: |
    apiVersion: apps/v1
    kind: Deployment
    metadata:
      labels:
        app: layout-inference
        appVersion: 0.1.0
        chart: groundx-0.1.0
        heritage: Helm
        version: 0.1.0
      name: layout-inference
      namespace: eyelevel
    spec:
      replicas: 1
      selector:
        matchLabels:
          app: layout-inference
      template:
        metadata:
          annotations:
            config-hash: ac70a23921bbd948745293be79d474cb3687af3882748951e056c20a584278a5
            config-models-hash: 529542d6881ddf622683f3bc8516205a5707660e0a921243b32fd51fd3573f4f
            supervisord-hash: 389d025411e33663295cbafcb9d7241d27e1d8736153cd1d14fa9c1b056107fe
          labels:
            app: layout-inference
        spec:
          containers:
            - command:
                - /bin/sh
                - -c
                - |
                  export PYTHONPATH=/app:$PYTHONPATH && python /app/init-layout.py && supervisord -c /app/supervisord.conf
              env:
                - name: POD_NAME
                  valueFrom:
                    fieldRef:
                      fieldPath: metadata.name
              image: public.ecr.aws/c9r4x6y5/eyelevel/layout-inference:0.1.0
              imagePullPolicy: IfNotPresent
              livenessProbe:
                failureThreshold: 8
                httpGet:
                  path: /alive
                  port: 8080
                initialDelaySeconds: 30
                periodSeconds: 15
              name: layout-inference
              ports:
                - containerPort: 8080
                  protocol: TCP
              readinessProbe:
                failureThreshold: 30
                httpGet:
                  path: /health
                  port: 8080
                initialDelaySeconds: 30
                periodSeconds: 15
              resources:
                limits:
                  nvidia.com/gpu: 1
                requests:
                  cpu: 500m
                  memory: 2Gi
                  nvidia.com/gpu: 1
              securityContext:
                allowPrivilegeEscalation: false
                capabilities:
                  drop:
                    - ALL
                runAsGroup: 1001
                runAsNonRoot: true
                runAsUser: 1001
                seccompProfile:
                  type: RuntimeDefault
              volumeMounts:
                - mountPath: /app/config_models.py
                  name: config-models
                  subPath: config_models.py
                - mountPath: /app/config.py
                  name: config-volume
                  subPath: config.py
                - mountPath: /app/supervisord.conf
                  name: supervisord-volume
                  subPath: supervisord.conf
              workingDir: /app
          initContainers:
            - command:
                - sh
                - -c
                - until nc -z cache.eyelevel.svc.cluster.local 6379; do echo waiting for cache; sleep 2; done
              image: public.ecr.aws/c9r4x6y5/eyelevel/busybox:1.0.0
              imagePullPolicy: IfNotPresent
              name: wait-for-cache
            - command:
                - sh
                - -c
                - until nc -z minio-tenant-hl.eyelevel.svc.cluster.local 9000; do echo waiting for file storage; sleep 2; done
              image: public.ecr.aws/c9r4x6y5/eyelevel/busybox:1.0.0
              imagePullPolicy: IfNotPresent
              name: wait-for-file-storage
          nodeSelector:
            node: eyelevel-gpu-layout
          securityContext:
            fsGroup: 1001
            fsGroupChangePolicy: OnRootMismatch
            runAsGroup: 1001
            runAsNonRoot: true
            runAsUser: 1001
            seccompProfile:
              type: RuntimeDefault
          tolerations:
            - effect: NoSchedule
              key: node
              value: eyelevel-gpu-layout
          volumes:
            - configMap:
                name: config-models-map
              name: config-models
            - configMap:
                name: layout-config-py-map
              name: config-volume
            - configMap:
                name: layout-inference-supervisord-conf-map
              name: supervisord-volume
  2: |
    apiVersion: apps/v1
    kind: Deployment
    metadata:
      labels:
        app: ranker-inference
        appVersion: 0.1.0
        chart: groundx-0.1.0
        heritage: Helm
        version: 0.1.0
      name: ranker-inference
      namespace: eyelevel
    spec:
      replicas: 1
      selector:
        matchLabels:
          app: ranker-inference
      template:
        metadata:
          annotations:
            config-hash: 8de2baea042228f54db256891d5da302316aab7828362929c3145cbfcfa75146
            config-models-hash: 529542d6881ddf622683f3bc8516205a5707660e0a921243b32fd51fd3573f4f
            supervisord-hash: c3de8d835a18146d0f59120a18513f20056efbb1cda896213ca789277d88a71b
          labels:
            app: ranker-inference
        spec:
          containers:
            - command:
                - /bin/sh
                - -c
                - |
                  export PYTHONPATH=/workspace:$PYTHONPATH &&  supervisord -c /workspace/supervisord.conf
              env:
                - name: POD_NAME
                  valueFrom:
                    fieldRef:
                      fieldPath: metadata.name
              image: public.ecr.aws/c9r4x6y5/eyelevel/ranker-inference:0.1.0
              imagePullPolicy: IfNotPresent
              livenessProbe:
                exec:
                  command:
                    - /bin/sh
                    - -c
                    - ps aux | grep 'ranker.celery.appSearch' | grep -v grep || exit 1
                failureThreshold: 10
                initialDelaySeconds: 60
                periodSeconds: 30
              name: ranker-inference
              readinessProbe:
                exec:
                  command:
                    - /bin/sh
                    - -c
                    - ps aux | grep 'ranker.celery.appSearch' | grep -v grep || exit 1
                initialDelaySeconds: 60
                periodSeconds: 30
              resources:
                limits:
                  nvidia.com/gpu: 1
                requests:
                  cpu: 1.5
                  memory: 1Gi
                  nvidia.com/gpu: 1
              securityContext:
                allowPrivilegeEscalation: false
                capabilities:
                  drop:
                    - ALL
                runAsGroup: 1001
                runAsNonRoot: true
                runAsUser: 1001
                seccompProfile:
                  type: RuntimeDefault
              volumeMounts:
                - mountPath: /workspace/config_models.py
                  name: config-models
                  subPath: config_models.py
                - mountPath: /workspace/config.py
                  name: config-volume
                  subPath: config.py
                - mountPath: /workspace/supervisord.conf
                  name: supervisord-volume
                  subPath: supervisord.conf
                - mountPath: /workspace/hf_models_cache
                  name: model-volume
              workingDir: /workspace
          initContainers:
            - command:
                - sh
                - -c
                - until nc -z cache.eyelevel.svc.cluster.local 6379; do echo waiting for cache; sleep 2; done
              image: public.ecr.aws/c9r4x6y5/eyelevel/busybox:1.0.0
              imagePullPolicy: IfNotPresent
              name: wait-for-cache
            - command:
                - /bin/sh
                - -c
                - |
                  download_and_extract_model() {
                    echo "Model downloading started..."

                    touch /workspace/hf_models_cache/downloading

                    echo "00 01 02" | tr ' ' '\n' | xargs -n 1 -P 5 -I {} sh -c \
                      'MAX_RETRIES=3; RETRIES=0; SUCCESS=0; PART={}; URL=https://upload.groundx.ai/ranker/model/current/model.tar.gz.part.$PART; \
                      while [ $RETRIES -lt $MAX_RETRIES ]; do \
                        echo "Download [attempt $RETRIES] ranker.tar.gz.part.$PART"; \
                        wget -q -O /workspace/hf_models_cache/ranker.tar.gz.part.$PART $URL && { echo "Downloaded ranker.tar.gz.part.$PART successfully."; SUCCESS=1; break; }; \
                        echo "Failed to download $URL. Retrying..."; RETRIES=$((RETRIES + 1)); sleep 3; \
                      done; \
                      [ $SUCCESS -eq 0 ] && { echo "Failed to download $URL after $MAX_RETRIES attempts. Exiting."; rm /workspace/hf_models_cache/downloading; exit 1; }; \
                      echo "Unzipping ranker.tar.gz.part.$PART..."; tar -xzf /workspace/hf_models_cache/ranker.tar.gz.part.$PART -C /workspace/hf_models_cache/; echo "Unzipping ranker.tar.gz.part.$PART complete...";'

                    rm /workspace/hf_models_cache/ranker.tar.*
                    rm /workspace/hf_models_cache/downloading
                    touch /workspace/hf_models_cache/complete.model
                  }
                  if [ ! -f /workspace/hf_models_cache/complete.model ]; then
                    if [ ! -f /workspace/hf_models_cache/downloading ]; then
                      download_and_extract_model
                    else
                      echo "Download in progress by another pod. Waiting..."
                      while [ -f /workspace/hf_models_cache/downloading ] || [ ! -f /workspace/hf_models_cache/complete.model ]; do
                        sleep $((3 + RANDOM % 2))
                      done

                      if [ ! -f /workspace/hf_models_cache/complete.model ]; then
                        download_and_extract_model
                      else
                        echo "Model cache ready."
                      fi
                    fi
                  else
                    echo "Model cache already exists. Skipping download."
                  fi

                  echo "Model load done."
              image: public.ecr.aws/c9r4x6y5/eyelevel/busybox:1.0.0
              imagePullPolicy: IfNotPresent
              name: download-model
              securityContext:
                allowPrivilegeEscalation: false
                capabilities:
                  drop:
                    - ALL
                runAsGroup: 1001
                runAsNonRoot: true
                runAsUser: 1001
                seccompProfile:
                  type: RuntimeDefault
              volumeMounts:
                - mountPath: /workspace/hf_models_cache
                  name: model-volume
          nodeSelector:
            node: eyelevel-gpu-ranker
          securityContext:
            fsGroup: 1001
            fsGroupChangePolicy: OnRootMismatch
            runAsGroup: 1001
            runAsNonRoot: true
            runAsUser: 1001
            seccompProfile:
              type: RuntimeDefault
          tolerations:
            - effect: NoSchedule
              key: node
              value: eyelevel-gpu-ranker
          volumes:
            - configMap:
                name: config-models-map
              name: config-models
            - configMap:
                name: ranker-config-py-map
              name: config-volume
            - configMap:
                name: ranker-inference-supervisord-conf-map
              name: supervisord-volume
            - name: model-volume
              persistentVolumeClaim:
                claimName: ranker-model
  3: |
    apiVersion: v1
    kind: PersistentVolumeClaim
    metadata:
      labels:
        app: ranker-inference
      name: ranker-model
      namespace: eyelevel
    spec:
      accessModes:
        - ReadWriteOnce
      resources:
        requests:
          storage: 10Gi
      storageClassName: eyelevel-pv
  4: |
    apiVersion: apps/v1
    kind: Deployment
    metadata:
      labels:
        app: summary-inference
        appVersion: 0.1.0
        chart: groundx-0.1.0
        heritage: Helm
        version: 0.1.0
      name: summary-inference
      namespace: eyelevel
    spec:
      replicas: 2
      selector:
        matchLabels:
          app: summary-inference
      template:
        metadata:
          annotations:
            config-hash: 51b3f74b62e64c36d06ea7360481e2bce39d6048899f71f252e65339efe9ee25
            config-models-hash: 529542d6881ddf622683f3bc8516205a5707660e0a921243b32fd51fd3573f4f
            supervisord-hash: a48af0c98c4a6d0aafa9d919d204e9d8b1c51e416a36f766644a6c8d11e48a90
          labels:
            app: summary-inference
        spec:
          containers:
            - command:
                - /bin/sh
                - -c
                - |
                  export PYTHONPATH=/workspace:$PYTHONPATH &&  supervisord -c /workspace/supervisord.conf
              env:
                - name: POD_NAME
                  valueFrom:
                    fieldRef:
                      fieldPath: metadata.name
              image: public.ecr.aws/c9r4x6y5/eyelevel/summary-inference:0.1.0
              imagePullPolicy: IfNotPresent
              livenessProbe:
                failureThreshold: 8
                httpGet:
                  path: /alive
                  port: 8080
                initialDelaySeconds: 30
                periodSeconds: 15
              name: summary-inference
              ports:
                - containerPort: 8080
                  protocol: TCP
              readinessProbe:
                failureThreshold: 30
                httpGet:
                  path: /health
                  port: 8080
                initialDelaySeconds: 30
                periodSeconds: 15
              resources:
                requests:
                  cpu: 500m
                  memory: 1Gi
              securityContext:
                allowPrivilegeEscalation: false
                capabilities:
                  drop:
                    - ALL
                runAsGroup: 1001
                runAsNonRoot: true
                runAsUser: 1001
                seccompProfile:
                  type: RuntimeDefault
              volumeMounts:
                - mountPath: /workspace/config_models.py
                  name: config-models
                  subPath: config_models.py
                - mountPath: /workspace/config.py
                  name: config-volume
                  subPath: config.py
                - mountPath: /workspace/supervisord.conf
                  name: supervisord-volume
                  subPath: supervisord.conf
                - mountPath: /workspace/hf_models_cache
                  name: model-volume
              workingDir: /workspace
          initContainers:
            - command:
                - sh
                - -c
                - until nc -z cache.eyelevel.svc.cluster.local 6379; do echo waiting for cache; sleep 2; done
              image: public.ecr.aws/c9r4x6y5/eyelevel/busybox:1.0.0
              imagePullPolicy: IfNotPresent
              name: wait-for-cache
            - command:
                - /bin/sh
                - -c
                - |
                  download_and_extract_model() {
                    echo "Model downloading started..."

                    touch /workspace/hf_models_cache/downloading

                    echo "00 01 02 03 04" | tr ' ' '\n' | xargs -n 1 -P 5 -I {} sh -c \
                      'MAX_RETRIES=3; RETRIES=0; SUCCESS=0; PART={}; URL=https://upload.groundx.ai/summary/model/current/g34b.tar.gz.part.$PART; \
                      while [ $RETRIES -lt $MAX_RETRIES ]; do \
                        echo "Download [attempt $RETRIES] summary.tar.gz.part.$PART"; \
                        wget -q -O /workspace/hf_models_cache/summary.tar.gz.part.$PART $URL && { echo "Downloaded summary.tar.gz.part.$PART successfully."; SUCCESS=1; break; }; \
                        echo "Failed to download $URL. Retrying..."; RETRIES=$((RETRIES + 1)); sleep 3; \
                      done; \
                      [ $SUCCESS -eq 0 ] && { echo "Failed to download $URL after $MAX_RETRIES attempts. Exiting."; rm /workspace/hf_models_cache/downloading; exit 1; }; \
                      echo "Unzipping summary.tar.gz.part.$PART..."; tar -xzf /workspace/hf_models_cache/summary.tar.gz.part.$PART -C /workspace/hf_models_cache/; echo "Unzipping summary.tar.gz.part.$PART complete...";'

                    rm /workspace/hf_models_cache/summary.tar.*
                    rm /workspace/hf_models_cache/downloading
                    touch /workspace/hf_models_cache/complete.g34b
                  }
                  if [ ! -f /workspace/hf_models_cache/complete.g34b ]; then
                    if [ ! -f /workspace/hf_models_cache/downloading ]; then
                      download_and_extract_model
                    else
                      echo "Download in progress by another pod. Waiting..."
                      while [ -f /workspace/hf_models_cache/downloading ] || [ ! -f /workspace/hf_models_cache/complete.g34b ]; do
                        sleep $((3 + RANDOM % 2))
                      done

                      if [ ! -f /workspace/hf_models_cache/complete.g34b ]; then
                        download_and_extract_model
                      else
                        echo "Model cache ready."
                      fi
                    fi
                  else
                    echo "Model cache already exists. Skipping download."
                  fi

                  echo "Model load done."
              image: public.ecr.aws/c9r4x6y5/eyelevel/busybox:1.0.0
              imagePullPolicy: IfNotPresent
              name: download-model
              securityContext:
                allowPrivilegeEscalation: false
                capabilities:
                  drop:
                    - ALL
                runAsGroup: 1001
                runAsNonRoot: true
                runAsUser: 1001
                seccompProfile:
                  type: RuntimeDefault
              volumeMounts:
                - mountPath: /workspace/hf_models_cache
                  name: model-volume
          nodeSelector:
            node: eyelevel-gpu-summary
          securityContext:
            fsGroup: 1001
            fsGroupChangePolicy: OnRootMismatch
            runAsGroup: 1001
            runAsNonRoot: true
            runAsUser: 1001
            seccompProfile:
              type: RuntimeDefault
          tolerations:
            - effect: NoSchedule
              key: node
              value: eyelevel-gpu-summary
          volumes:
            - configMap:
                name: config-models-map
              name: config-models
            - configMap:
                name: summary-config-py-map
              name: config-volume
            - configMap:
                name: summary-inference-supervisord-conf-map
              name: supervisord-volume
            - name: model-volume
              persistentVolumeClaim:
                claimName: summary-model
  5: |
    apiVersion: v1
    kind: PersistentVolumeClaim
    metadata:
      labels:
        app: summary-inference
      name: summary-model
      namespace: eyelevel
    spec:
      accessModes:
        - ReadWriteOnce
      resources:
        requests:
          storage: 20Gi
      storageClassName: eyelevel-pv
'openshift: inference':
  1: |
    apiVersion: apps/v1
    kind: Deployment
    metadata:
      labels:
        app: layout-inference
        appVersion: 0.1.0
        chart: groundx-0.1.0
        heritage: Helm
        version: 0.1.0
      name: layout-inference
      namespace: eyelevel
    spec:
      replicas: 1
      selector:
        matchLabels:
          app: layout-inference
      template:
        metadata:
          annotations:
            config-hash: ac70a23921bbd948745293be79d474cb3687af3882748951e056c20a584278a5
            config-models-hash: 529542d6881ddf622683f3bc8516205a5707660e0a921243b32fd51fd3573f4f
            supervisord-hash: 389d025411e33663295cbafcb9d7241d27e1d8736153cd1d14fa9c1b056107fe
          labels:
            app: layout-inference
        spec:
          containers:
            - command:
                - /bin/sh
                - -c
                - |
                  export PYTHONPATH=/app:$PYTHONPATH && python /app/init-layout.py && supervisord -c /app/supervisord.conf
              env:
                - name: POD_NAME
                  valueFrom:
                    fieldRef:
                      fieldPath: metadata.name
              image: public.ecr.aws/c9r4x6y5/eyelevel/layout-inference:0.1.0
              imagePullPolicy: IfNotPresent
              livenessProbe:
                failureThreshold: 8
                httpGet:
                  path: /alive
                  port: 8080
                initialDelaySeconds: 30
                periodSeconds: 15
              name: layout-inference
              ports:
                - containerPort: 8080
                  protocol: TCP
              readinessProbe:
                failureThreshold: 30
                httpGet:
                  path: /health
                  port: 8080
                initialDelaySeconds: 30
                periodSeconds: 15
              resources:
                limits:
                  nvidia.com/gpu: 1
                requests:
                  cpu: 500m
                  memory: 2Gi
                  nvidia.com/gpu: 1
              securityContext:
                allowPrivilegeEscalation: false
                capabilities:
                  drop:
                    - ALL
                runAsNonRoot: true
                seccompProfile:
                  type: RuntimeDefault
              volumeMounts:
                - mountPath: /app/config_models.py
                  name: config-models
                  subPath: config_models.py
                - mountPath: /app/config.py
                  name: config-volume
                  subPath: config.py
                - mountPath: /app/supervisord.conf
                  name: supervisord-volume
                  subPath: supervisord.conf
              workingDir: /app
          initContainers:
            - command:
                - sh
                - -c
                - until nc -z cache.eyelevel.svc.cluster.local 6379; do echo waiting for cache; sleep 2; done
              image: public.ecr.aws/c9r4x6y5/eyelevel/busybox:1.0.0
              imagePullPolicy: IfNotPresent
              name: wait-for-cache
            - command:
                - sh
                - -c
                - until nc -z minio-tenant-hl.eyelevel.svc.cluster.local 9000; do echo waiting for file storage; sleep 2; done
              image: public.ecr.aws/c9r4x6y5/eyelevel/busybox:1.0.0
              imagePullPolicy: IfNotPresent
              name: wait-for-file-storage
          nodeSelector:
            node: eyelevel-gpu-layout
          securityContext:
            runAsNonRoot: true
            seccompProfile:
              type: RuntimeDefault
          tolerations:
            - effect: NoSchedule
              key: node
              value: eyelevel-gpu-layout
          volumes:
            - configMap:
                name: config-models-map
              name: config-models
            - configMap:
                name: layout-config-py-map
              name: config-volume
            - configMap:
                name: layout-inference-supervisord-conf-map
              name: supervisord-volume
  2: |
    apiVersion: apps/v1
    kind: Deployment
    metadata:
      labels:
        app: ranker-inference
        appVersion: 0.1.0
        chart: groundx-0.1.0
        heritage: Helm
        version: 0.1.0
      name: ranker-inference
      namespace: eyelevel
    spec:
      replicas: 1
      selector:
        matchLabels:
          app: ranker-inference
      template:
        metadata:
          annotations:
            config-hash: 8de2baea042228f54db256891d5da302316aab7828362929c3145cbfcfa75146
            config-models-hash: 529542d6881ddf622683f3bc8516205a5707660e0a921243b32fd51fd3573f4f
            supervisord-hash: c3de8d835a18146d0f59120a18513f20056efbb1cda896213ca789277d88a71b
          labels:
            app: ranker-inference
        spec:
          containers:
            - command:
                - /bin/sh
                - -c
                - |
                  export PYTHONPATH=/workspace:$PYTHONPATH &&  supervisord -c /workspace/supervisord.conf
              env:
                - name: POD_NAME
                  valueFrom:
                    fieldRef:
                      fieldPath: metadata.name
              image: public.ecr.aws/c9r4x6y5/eyelevel/ranker-inference:0.1.0
              imagePullPolicy: IfNotPresent
              livenessProbe:
                exec:
                  command:
                    - /bin/sh
                    - -c
                    - ps aux | grep 'ranker.celery.appSearch' | grep -v grep || exit 1
                failureThreshold: 10
                initialDelaySeconds: 60
                periodSeconds: 30
              name: ranker-inference
              readinessProbe:
                exec:
                  command:
                    - /bin/sh
                    - -c
                    - ps aux | grep 'ranker.celery.appSearch' | grep -v grep || exit 1
                initialDelaySeconds: 60
                periodSeconds: 30
              resources:
                limits:
                  nvidia.com/gpu: 1
                requests:
                  cpu: 1.5
                  memory: 1Gi
                  nvidia.com/gpu: 1
              securityContext:
                allowPrivilegeEscalation: false
                capabilities:
                  drop:
                    - ALL
                runAsNonRoot: true
                seccompProfile:
                  type: RuntimeDefault
              volumeMounts:
                - mountPath: /workspace/config_models.py
                  name: config-models
                  subPath: config_models.py
                - mountPath: /workspace/config.py
                  name: config-volume
                  subPath: config.py
                - mountPath: /workspace/supervisord.conf
                  name: supervisord-volume
                  subPath: supervisord.conf
                - mountPath: /workspace/hf_models_cache
                  name: model-volume
              workingDir: /workspace
          initContainers:
            - command:
                - sh
                - -c
                - until nc -z cache.eyelevel.svc.cluster.local 6379; do echo waiting for cache; sleep 2; done
              image: public.ecr.aws/c9r4x6y5/eyelevel/busybox:1.0.0
              imagePullPolicy: IfNotPresent
              name: wait-for-cache
            - command:
                - /bin/sh
                - -c
                - |
                  download_and_extract_model() {
                    echo "Model downloading started..."

                    touch /workspace/hf_models_cache/downloading

                    echo "00 01 02" | tr ' ' '\n' | xargs -n 1 -P 5 -I {} sh -c \
                      'MAX_RETRIES=3; RETRIES=0; SUCCESS=0; PART={}; URL=https://upload.groundx.ai/ranker/model/current/model.tar.gz.part.$PART; \
                      while [ $RETRIES -lt $MAX_RETRIES ]; do \
                        echo "Download [attempt $RETRIES] ranker.tar.gz.part.$PART"; \
                        wget -q -O /workspace/hf_models_cache/ranker.tar.gz.part.$PART $URL && { echo "Downloaded ranker.tar.gz.part.$PART successfully."; SUCCESS=1; break; }; \
                        echo "Failed to download $URL. Retrying..."; RETRIES=$((RETRIES + 1)); sleep 3; \
                      done; \
                      [ $SUCCESS -eq 0 ] && { echo "Failed to download $URL after $MAX_RETRIES attempts. Exiting."; rm /workspace/hf_models_cache/downloading; exit 1; }; \
                      echo "Unzipping ranker.tar.gz.part.$PART..."; tar -xzf /workspace/hf_models_cache/ranker.tar.gz.part.$PART -C /workspace/hf_models_cache/; echo "Unzipping ranker.tar.gz.part.$PART complete...";'

                    rm /workspace/hf_models_cache/ranker.tar.*
                    rm /workspace/hf_models_cache/downloading
                    touch /workspace/hf_models_cache/complete.model
                  }
                  if [ ! -f /workspace/hf_models_cache/complete.model ]; then
                    if [ ! -f /workspace/hf_models_cache/downloading ]; then
                      download_and_extract_model
                    else
                      echo "Download in progress by another pod. Waiting..."
                      while [ -f /workspace/hf_models_cache/downloading ] || [ ! -f /workspace/hf_models_cache/complete.model ]; do
                        sleep $((3 + RANDOM % 2))
                      done

                      if [ ! -f /workspace/hf_models_cache/complete.model ]; then
                        download_and_extract_model
                      else
                        echo "Model cache ready."
                      fi
                    fi
                  else
                    echo "Model cache already exists. Skipping download."
                  fi

                  echo "Model load done."
              image: public.ecr.aws/c9r4x6y5/eyelevel/busybox:1.0.0
              imagePullPolicy: IfNotPresent
              name: download-model
              securityContext:
                allowPrivilegeEscalation: false
                capabilities:
                  drop:
                    - ALL
                runAsNonRoot: true
                seccompProfile:
                  type: RuntimeDefault
              volumeMounts:
                - mountPath: /workspace/hf_models_cache
                  name: model-volume
          nodeSelector:
            node: eyelevel-gpu-ranker
          securityContext:
            runAsNonRoot: true
            seccompProfile:
              type: RuntimeDefault
          tolerations:
            - effect: NoSchedule
              key: node
              value: eyelevel-gpu-ranker
          volumes:
            - configMap:
                name: config-models-map
              name: config-models
            - configMap:
                name: ranker-config-py-map
              name: config-volume
            - configMap:
                name: ranker-inference-supervisord-conf-map
              name: supervisord-volume
            - name: model-volume
              persistentVolumeClaim:
                claimName: ranker-model
  3: |
    apiVersion: v1
    kind: PersistentVolumeClaim
    metadata:
      labels:
        app: ranker-inference
      name: ranker-model
      namespace: eyelevel
    spec:
      accessModes:
        - ReadWriteOnce
      resources:
        requests:
          storage: 10Gi
      storageClassName: eyelevel-pv
  4: |
    apiVersion: apps/v1
    kind: Deployment
    metadata:
      labels:
        app: summary-inference
        appVersion: 0.1.0
        chart: groundx-0.1.0
        heritage: Helm
        version: 0.1.0
      name: summary-inference
      namespace: eyelevel
    spec:
      replicas: 2
      selector:
        matchLabels:
          app: summary-inference
      template:
        metadata:
          annotations:
            config-hash: 51b3f74b62e64c36d06ea7360481e2bce39d6048899f71f252e65339efe9ee25
            config-models-hash: 529542d6881ddf622683f3bc8516205a5707660e0a921243b32fd51fd3573f4f
            supervisord-hash: a48af0c98c4a6d0aafa9d919d204e9d8b1c51e416a36f766644a6c8d11e48a90
          labels:
            app: summary-inference
        spec:
          containers:
            - command:
                - /bin/sh
                - -c
                - |
                  export PYTHONPATH=/workspace:$PYTHONPATH &&  supervisord -c /workspace/supervisord.conf
              env:
                - name: POD_NAME
                  valueFrom:
                    fieldRef:
                      fieldPath: metadata.name
              image: public.ecr.aws/c9r4x6y5/eyelevel/summary-inference:0.1.0
              imagePullPolicy: IfNotPresent
              livenessProbe:
                failureThreshold: 8
                httpGet:
                  path: /alive
                  port: 8080
                initialDelaySeconds: 30
                periodSeconds: 15
              name: summary-inference
              ports:
                - containerPort: 8080
                  protocol: TCP
              readinessProbe:
                failureThreshold: 30
                httpGet:
                  path: /health
                  port: 8080
                initialDelaySeconds: 30
                periodSeconds: 15
              resources:
                requests:
                  cpu: 500m
                  memory: 1Gi
              securityContext:
                allowPrivilegeEscalation: false
                capabilities:
                  drop:
                    - ALL
                runAsNonRoot: true
                seccompProfile:
                  type: RuntimeDefault
              volumeMounts:
                - mountPath: /workspace/config_models.py
                  name: config-models
                  subPath: config_models.py
                - mountPath: /workspace/config.py
                  name: config-volume
                  subPath: config.py
                - mountPath: /workspace/supervisord.conf
                  name: supervisord-volume
                  subPath: supervisord.conf
                - mountPath: /workspace/hf_models_cache
                  name: model-volume
              workingDir: /workspace
          initContainers:
            - command:
                - sh
                - -c
                - until nc -z cache.eyelevel.svc.cluster.local 6379; do echo waiting for cache; sleep 2; done
              image: public.ecr.aws/c9r4x6y5/eyelevel/busybox:1.0.0
              imagePullPolicy: IfNotPresent
              name: wait-for-cache
            - command:
                - /bin/sh
                - -c
                - |
                  download_and_extract_model() {
                    echo "Model downloading started..."

                    touch /workspace/hf_models_cache/downloading

                    echo "00 01 02 03 04" | tr ' ' '\n' | xargs -n 1 -P 5 -I {} sh -c \
                      'MAX_RETRIES=3; RETRIES=0; SUCCESS=0; PART={}; URL=https://upload.groundx.ai/summary/model/current/g34b.tar.gz.part.$PART; \
                      while [ $RETRIES -lt $MAX_RETRIES ]; do \
                        echo "Download [attempt $RETRIES] summary.tar.gz.part.$PART"; \
                        wget -q -O /workspace/hf_models_cache/summary.tar.gz.part.$PART $URL && { echo "Downloaded summary.tar.gz.part.$PART successfully."; SUCCESS=1; break; }; \
                        echo "Failed to download $URL. Retrying..."; RETRIES=$((RETRIES + 1)); sleep 3; \
                      done; \
                      [ $SUCCESS -eq 0 ] && { echo "Failed to download $URL after $MAX_RETRIES attempts. Exiting."; rm /workspace/hf_models_cache/downloading; exit 1; }; \
                      echo "Unzipping summary.tar.gz.part.$PART..."; tar -xzf /workspace/hf_models_cache/summary.tar.gz.part.$PART -C /workspace/hf_models_cache/; echo "Unzipping summary.tar.gz.part.$PART complete...";'

                    rm /workspace/hf_models_cache/summary.tar.*
                    rm /workspace/hf_models_cache/downloading
                    touch /workspace/hf_models_cache/complete.g34b
                  }
                  if [ ! -f /workspace/hf_models_cache/complete.g34b ]; then
                    if [ ! -f /workspace/hf_models_cache/downloading ]; then
                      download_and_extract_model
                    else
                      echo "Download in progress by another pod. Waiting..."
                      while [ -f /workspace/hf_models_cache/downloading ] || [ ! -f /workspace/hf_models_cache/complete.g34b ]; do
                        sleep $((3 + RANDOM % 2))
                      done

                      if [ ! -f /workspace/hf_models_cache/complete.g34b ]; then
                        download_and_extract_model
                      else
                        echo "Model cache ready."
                      fi
                    fi
                  else
                    echo "Model cache already exists. Skipping download."
                  fi

                  echo "Model load done."
              image: public.ecr.aws/c9r4x6y5/eyelevel/busybox:1.0.0
              imagePullPolicy: IfNotPresent
              name: download-model
              securityContext:
                allowPrivilegeEscalation: false
                capabilities:
                  drop:
                    - ALL
                runAsNonRoot: true
                seccompProfile:
                  type: RuntimeDefault
              volumeMounts:
                - mountPath: /workspace/hf_models_cache
                  name: model-volume
          nodeSelector:
            node: eyelevel-gpu-summary
          securityContext:
            runAsNonRoot: true
            seccompProfile:
              type: RuntimeDefault
          tolerations:
            - effect: NoSchedule
              key: node
              value: eyelevel-gpu-summary
          volumes:
            - configMap:
                name: config-models-map
              name: config-models
            - configMap:
                name: summary-config-py-map
              name: config-volume
            - configMap:
                name: summary-inference-supervisord-conf-map
              name: supervisord-volume
            - name: model-volume
              persistentVolumeClaim:
                claimName: summary-model
  5: |
    apiVersion: v1
    kind: PersistentVolumeClaim
    metadata:
      labels:
        app: summary-inference
      name: summary-model
      namespace: eyelevel
    spec:
      accessModes:
        - ReadWriteOnce
      resources:
        requests:
          storage: 20Gi
      storageClassName: eyelevel-pv
