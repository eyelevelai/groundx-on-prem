'aws: inference':
  1: |
    apiVersion: apps/v1
    kind: Deployment
    metadata:
      labels:
        app: layout-inference
        appVersion: 0.1.0
        chart: groundx-0.1.0
        heritage: Helm
        version: 0.1.0
      name: layout-inference
      namespace: eyelevel
    spec:
      replicas: 1
      selector:
        matchLabels:
          app: layout-inference
      template:
        metadata:
          annotations:
            config-hash: 0e62c00d3b122115c882493823cdaa38d82aed94891faac8b29b80d6b1a32960
            config-models-hash: 529542d6881ddf622683f3bc8516205a5707660e0a921243b32fd51fd3573f4f
            ldconfig-symlink-hash: 9958a113394211878ece8f9030f4c08a1860e77aa75b5852bfa0691fc3faf32f
            supervisord-hash: 389d025411e33663295cbafcb9d7241d27e1d8736153cd1d14fa9c1b056107fe
          labels:
            app: layout-inference
        spec:
          affinity:
            nodeAffinity:
              requiredDuringSchedulingIgnoredDuringExecution:
                nodeSelectorTerms:
                  - matchExpressions:
                      - key: node
                        operator: In
                        values:
                          - eyelevel-gpu-layout
                  - matchExpressions:
                      - key: eyelevel_node
                        operator: In
                        values:
                          - eyelevel-gpu-layout
          containers:
            - command:
                - /bin/sh
                - -c
                - |
                  export PYTHONPATH=/app:$PYTHONPATH && python /app/init-layout.py && supervisord -c /app/supervisord.conf
              env:
                - name: POD_NAME
                  valueFrom:
                    fieldRef:
                      fieldPath: metadata.name
              image: public.ecr.aws/c9r4x6y5/eyelevel/layout-inference:0.1.0
              imagePullPolicy: IfNotPresent
              livenessProbe:
                failureThreshold: 8
                httpGet:
                  path: /alive
                  port: 8080
                initialDelaySeconds: 30
                periodSeconds: 15
              name: layout-inference
              ports:
                - containerPort: 8080
                  protocol: TCP
              readinessProbe:
                failureThreshold: 30
                httpGet:
                  path: /health
                  port: 8080
                initialDelaySeconds: 30
                periodSeconds: 15
              resources:
                limits:
                  memory: 12Gi
                  nvidia.com/gpu: 1
                requests:
                  cpu: 500m
                  memory: 2Gi
                  nvidia.com/gpu: 1
              securityContext:
                allowPrivilegeEscalation: false
                capabilities:
                  drop:
                    - ALL
                runAsGroup: 1001
                runAsNonRoot: true
                runAsUser: 1001
                seccompProfile:
                  type: RuntimeDefault
              volumeMounts:
                - mountPath: /app/config_models.py
                  name: config-models
                  subPath: config_models.py
                - mountPath: /app/config.py
                  name: config-volume
                  subPath: config.py
                - mountPath: /app/supervisord.conf
                  name: supervisord-volume
                  subPath: supervisord.conf
              workingDir: /app
          initContainers:
            - command:
                - sh
                - -c
                - until nc -z X.X.X.use2.cache.amazonaws.com 6379; do echo waiting for cache; sleep 2; done
              image: public.ecr.aws/c9r4x6y5/eyelevel/busybox:1.0.0
              imagePullPolicy: IfNotPresent
              name: wait-for-cache
            - command:
                - sh
                - -c
                - until nc -z X.s3.us-west-2.amazonaws.com 443; do echo waiting for file storage; sleep 2; done
              image: public.ecr.aws/c9r4x6y5/eyelevel/busybox:1.0.0
              imagePullPolicy: IfNotPresent
              name: wait-for-file-storage
            - args:
                - echo 'Running ldconfig_symlink.sh on this node'; /scripts/ldconfig_symlink.sh
              command:
                - /bin/sh
                - -c
                - --
              image: public.ecr.aws/c9r4x6y5/eyelevel/busybox:1.0.0
              imagePullPolicy: IfNotPresent
              name: create-symlink
              resources:
                requests:
                  cpu: 10m
                  memory: 50Mi
              securityContext:
                privileged: true
              volumeMounts:
                - mountPath: /scripts/ldconfig_symlink.sh
                  name: layout-inference
                  subPath: ldconfig_symlink.sh
                - mountPath: /host-sbin
                  name: host-sbin
                - mountPath: /host-usr-sbin
                  name: host-usr-sbin
                - mountPath: /host-bin
                  name: host-bin
                - mountPath: /host-usr-bin
                  name: host-usr-bin
          securityContext:
            fsGroup: 1001
            fsGroupChangePolicy: OnRootMismatch
            runAsGroup: 1001
            runAsNonRoot: true
            runAsUser: 1001
            seccompProfile:
              type: RuntimeDefault
          serviceAccountName: existing-service-account
          tolerations:
            - effect: NoSchedule
              key: node
              value: eyelevel-gpu-layout
            - effect: NoSchedule
              key: eyelevel_node
              value: eyelevel-gpu-layout
          volumes:
            - configMap:
                name: config-models-map
              name: config-models
            - configMap:
                name: layout-config-py-map
              name: config-volume
            - configMap:
                name: layout-inference-supervisord-conf-map
              name: supervisord-volume
            - configMap:
                defaultMode: 365
                name: ldconfig-symlink-map
              name: layout-inference
            - hostPath:
                path: /sbin
                type: Directory
              name: host-sbin
            - hostPath:
                path: /usr/sbin
                type: Directory
              name: host-usr-sbin
            - hostPath:
                path: /bin
                type: Directory
              name: host-bin
            - hostPath:
                path: /usr/bin
                type: Directory
              name: host-usr-bin
  2: |
    apiVersion: apps/v1
    kind: Deployment
    metadata:
      labels:
        app: ranker-inference
        appVersion: 0.1.0
        chart: groundx-0.1.0
        heritage: Helm
        version: 0.1.0
      name: ranker-inference
      namespace: eyelevel
    spec:
      replicas: 1
      selector:
        matchLabels:
          app: ranker-inference
      template:
        metadata:
          annotations:
            config-hash: b0c8193aca6eccd6282f680fa67313a44dd0ac24a73ea84906276482bde9c15e
            config-models-hash: 529542d6881ddf622683f3bc8516205a5707660e0a921243b32fd51fd3573f4f
            ldconfig-symlink-hash: 9958a113394211878ece8f9030f4c08a1860e77aa75b5852bfa0691fc3faf32f
            supervisord-hash: c3de8d835a18146d0f59120a18513f20056efbb1cda896213ca789277d88a71b
          labels:
            app: ranker-inference
        spec:
          affinity:
            nodeAffinity:
              requiredDuringSchedulingIgnoredDuringExecution:
                nodeSelectorTerms:
                  - matchExpressions:
                      - key: node
                        operator: In
                        values:
                          - eyelevel-gpu-ranker
                  - matchExpressions:
                      - key: eyelevel_node
                        operator: In
                        values:
                          - eyelevel-gpu-ranker
          containers:
            - command:
                - /bin/sh
                - -c
                - |
                  export PYTHONPATH=/workspace:$PYTHONPATH &&  supervisord -c /workspace/supervisord.conf
              env:
                - name: POD_NAME
                  valueFrom:
                    fieldRef:
                      fieldPath: metadata.name
              image: public.ecr.aws/c9r4x6y5/eyelevel/ranker-inference:0.1.0
              imagePullPolicy: IfNotPresent
              livenessProbe:
                exec:
                  command:
                    - /bin/sh
                    - -c
                    - ps aux | grep 'ranker.celery.appSearch' | grep -v grep || exit 1
                failureThreshold: 10
                initialDelaySeconds: 60
                periodSeconds: 30
              name: ranker-inference
              readinessProbe:
                exec:
                  command:
                    - /bin/sh
                    - -c
                    - ps aux | grep 'ranker.celery.appSearch' | grep -v grep || exit 1
                initialDelaySeconds: 60
                periodSeconds: 30
              resources:
                limits:
                  nvidia.com/gpu: 1
                requests:
                  cpu: 1.5
                  memory: 1Gi
                  nvidia.com/gpu: 1
              securityContext:
                allowPrivilegeEscalation: false
                capabilities:
                  drop:
                    - ALL
                runAsGroup: 1001
                runAsNonRoot: true
                runAsUser: 1001
                seccompProfile:
                  type: RuntimeDefault
              volumeMounts:
                - mountPath: /workspace/config_models.py
                  name: config-models
                  subPath: config_models.py
                - mountPath: /workspace/config.py
                  name: config-volume
                  subPath: config.py
                - mountPath: /workspace/supervisord.conf
                  name: supervisord-volume
                  subPath: supervisord.conf
                - mountPath: /workspace/hf_models_cache
                  name: model-volume
              workingDir: /workspace
          initContainers:
            - command:
                - sh
                - -c
                - until nc -z X.X.X.use2.cache.amazonaws.com 6379; do echo waiting for cache; sleep 2; done
              image: public.ecr.aws/c9r4x6y5/eyelevel/busybox:1.0.0
              imagePullPolicy: IfNotPresent
              name: wait-for-cache
            - args:
                - echo 'Running ldconfig_symlink.sh on this node'; /scripts/ldconfig_symlink.sh
              command:
                - /bin/sh
                - -c
                - --
              image: public.ecr.aws/c9r4x6y5/eyelevel/busybox:1.0.0
              imagePullPolicy: IfNotPresent
              name: create-symlink
              resources:
                requests:
                  cpu: 10m
                  memory: 50Mi
              securityContext:
                privileged: true
              volumeMounts:
                - mountPath: /scripts/ldconfig_symlink.sh
                  name: ranker-inference
                  subPath: ldconfig_symlink.sh
                - mountPath: /host-sbin
                  name: host-sbin
                - mountPath: /host-usr-sbin
                  name: host-usr-sbin
                - mountPath: /host-bin
                  name: host-bin
                - mountPath: /host-usr-bin
                  name: host-usr-bin
            - command:
                - /bin/sh
                - -c
                - |
                  download_and_extract_model() {
                    echo "Model downloading started..."

                    touch /workspace/hf_models_cache/downloading

                    echo "00 01 02" | tr ' ' '\n' | xargs -n 1 -P 5 -I {} sh -c \
                      'MAX_RETRIES=3; RETRIES=0; SUCCESS=0; PART={}; URL=https://upload.groundx.ai/ranker/model/current/model.tar.gz.part.$PART; \
                      while [ $RETRIES -lt $MAX_RETRIES ]; do \
                        echo "Download [attempt $RETRIES] ranker.tar.gz.part.$PART"; \
                        wget -q -O /workspace/hf_models_cache/ranker.tar.gz.part.$PART $URL && { echo "Downloaded ranker.tar.gz.part.$PART successfully."; SUCCESS=1; break; }; \
                        echo "Failed to download $URL. Retrying..."; RETRIES=$((RETRIES + 1)); sleep 3; \
                      done; \
                      [ $SUCCESS -eq 0 ] && { echo "Failed to download $URL after $MAX_RETRIES attempts. Exiting."; rm /workspace/hf_models_cache/downloading; exit 1; }; \
                      echo "Unzipping ranker.tar.gz.part.$PART..."; tar -xzf /workspace/hf_models_cache/ranker.tar.gz.part.$PART -C /workspace/hf_models_cache/; echo "Unzipping ranker.tar.gz.part.$PART complete...";'

                    rm /workspace/hf_models_cache/ranker.tar.*
                    rm /workspace/hf_models_cache/downloading
                    touch /workspace/hf_models_cache/complete.model
                  }
                  if [ ! -f /workspace/hf_models_cache/complete.model ]; then
                    if [ ! -f /workspace/hf_models_cache/downloading ]; then
                      download_and_extract_model
                    else
                      echo "Download in progress by another pod. Waiting..."
                      while [ -f /workspace/hf_models_cache/downloading ] || [ ! -f /workspace/hf_models_cache/complete.model ]; do
                        sleep $((3 + RANDOM % 2))
                      done

                      if [ ! -f /workspace/hf_models_cache/complete.model ]; then
                        download_and_extract_model
                      else
                        echo "Model cache ready."
                      fi
                    fi
                  else
                    echo "Model cache already exists. Skipping download."
                  fi

                  echo "Model load done."
              image: public.ecr.aws/c9r4x6y5/eyelevel/busybox:1.0.0
              imagePullPolicy: IfNotPresent
              name: download-model
              securityContext:
                allowPrivilegeEscalation: false
                capabilities:
                  drop:
                    - ALL
                runAsGroup: 1001
                runAsNonRoot: true
                runAsUser: 1001
                seccompProfile:
                  type: RuntimeDefault
              volumeMounts:
                - mountPath: /workspace/hf_models_cache
                  name: model-volume
          securityContext:
            fsGroup: 1001
            fsGroupChangePolicy: OnRootMismatch
            runAsGroup: 1001
            runAsNonRoot: true
            runAsUser: 1001
            seccompProfile:
              type: RuntimeDefault
          serviceAccountName: existing-service-account
          tolerations:
            - effect: NoSchedule
              key: node
              value: eyelevel-gpu-ranker
            - effect: NoSchedule
              key: eyelevel_node
              value: eyelevel-gpu-ranker
          volumes:
            - configMap:
                name: config-models-map
              name: config-models
            - configMap:
                name: ranker-config-py-map
              name: config-volume
            - configMap:
                name: ranker-inference-supervisord-conf-map
              name: supervisord-volume
            - configMap:
                defaultMode: 365
                name: ldconfig-symlink-map
              name: ranker-inference
            - hostPath:
                path: /sbin
                type: Directory
              name: host-sbin
            - hostPath:
                path: /usr/sbin
                type: Directory
              name: host-usr-sbin
            - hostPath:
                path: /bin
                type: Directory
              name: host-bin
            - hostPath:
                path: /usr/bin
                type: Directory
              name: host-usr-bin
            - name: model-volume
              persistentVolumeClaim:
                claimName: ranker-model
  3: |
    apiVersion: v1
    kind: PersistentVolumeClaim
    metadata:
      labels:
        app: ranker-inference
      name: ranker-model
      namespace: eyelevel
    spec:
      accessModes:
        - ReadWriteOnce
      resources:
        requests:
          storage: 10Gi
      storageClassName: eyelevel-pv
  4: |
    apiVersion: apps/v1
    kind: Deployment
    metadata:
      labels:
        app: summary-inference
        appVersion: 0.1.0
        chart: groundx-0.1.0
        heritage: Helm
        version: 0.1.0
      name: summary-inference
      namespace: eyelevel
    spec:
      replicas: 2
      selector:
        matchLabels:
          app: summary-inference
      template:
        metadata:
          annotations:
            config-hash: 17ef124814867fcbb6212c1851edc76e6acdb7802e42c7fef134a2fb6f3ec938
            config-models-hash: 529542d6881ddf622683f3bc8516205a5707660e0a921243b32fd51fd3573f4f
            ldconfig-symlink-hash: 9958a113394211878ece8f9030f4c08a1860e77aa75b5852bfa0691fc3faf32f
            supervisord-hash: a48af0c98c4a6d0aafa9d919d204e9d8b1c51e416a36f766644a6c8d11e48a90
          labels:
            app: summary-inference
        spec:
          affinity:
            nodeAffinity:
              requiredDuringSchedulingIgnoredDuringExecution:
                nodeSelectorTerms:
                  - matchExpressions:
                      - key: node
                        operator: In
                        values:
                          - eyelevel-gpu-summary
                  - matchExpressions:
                      - key: eyelevel_node
                        operator: In
                        values:
                          - eyelevel-gpu-summary
          containers:
            - command:
                - /bin/sh
                - -c
                - |
                  export PYTHONPATH=/workspace:$PYTHONPATH &&  supervisord -c /workspace/supervisord.conf
              env:
                - name: POD_NAME
                  valueFrom:
                    fieldRef:
                      fieldPath: metadata.name
              image: public.ecr.aws/c9r4x6y5/eyelevel/summary-inference:0.1.0
              imagePullPolicy: IfNotPresent
              livenessProbe:
                failureThreshold: 8
                httpGet:
                  path: /alive
                  port: 8080
                initialDelaySeconds: 30
                periodSeconds: 15
              name: summary-inference
              ports:
                - containerPort: 8080
                  protocol: TCP
              readinessProbe:
                failureThreshold: 30
                httpGet:
                  path: /health
                  port: 8080
                initialDelaySeconds: 30
                periodSeconds: 15
              resources:
                requests:
                  cpu: 500m
                  memory: 1Gi
              securityContext:
                allowPrivilegeEscalation: false
                capabilities:
                  drop:
                    - ALL
                runAsGroup: 1001
                runAsNonRoot: true
                runAsUser: 1001
                seccompProfile:
                  type: RuntimeDefault
              volumeMounts:
                - mountPath: /workspace/config_models.py
                  name: config-models
                  subPath: config_models.py
                - mountPath: /workspace/config.py
                  name: config-volume
                  subPath: config.py
                - mountPath: /workspace/supervisord.conf
                  name: supervisord-volume
                  subPath: supervisord.conf
                - mountPath: /workspace/hf_models_cache
                  name: model-volume
              workingDir: /workspace
          initContainers:
            - command:
                - sh
                - -c
                - until nc -z X.X.X.use2.cache.amazonaws.com 6379; do echo waiting for cache; sleep 2; done
              image: public.ecr.aws/c9r4x6y5/eyelevel/busybox:1.0.0
              imagePullPolicy: IfNotPresent
              name: wait-for-cache
            - args:
                - echo 'Running ldconfig_symlink.sh on this node'; /scripts/ldconfig_symlink.sh
              command:
                - /bin/sh
                - -c
                - --
              image: public.ecr.aws/c9r4x6y5/eyelevel/busybox:1.0.0
              imagePullPolicy: IfNotPresent
              name: create-symlink
              resources:
                requests:
                  cpu: 10m
                  memory: 50Mi
              securityContext:
                privileged: true
              volumeMounts:
                - mountPath: /scripts/ldconfig_symlink.sh
                  name: summary-inference
                  subPath: ldconfig_symlink.sh
                - mountPath: /host-sbin
                  name: host-sbin
                - mountPath: /host-usr-sbin
                  name: host-usr-sbin
                - mountPath: /host-bin
                  name: host-bin
                - mountPath: /host-usr-bin
                  name: host-usr-bin
            - command:
                - /bin/sh
                - -c
                - |
                  download_and_extract_model() {
                    echo "Model downloading started..."

                    touch /workspace/hf_models_cache/downloading

                    echo "00 01 02 03 04" | tr ' ' '\n' | xargs -n 1 -P 5 -I {} sh -c \
                      'MAX_RETRIES=3; RETRIES=0; SUCCESS=0; PART={}; URL=https://upload.groundx.ai/summary/model/current/g34b.tar.gz.part.$PART; \
                      while [ $RETRIES -lt $MAX_RETRIES ]; do \
                        echo "Download [attempt $RETRIES] summary.tar.gz.part.$PART"; \
                        wget -q -O /workspace/hf_models_cache/summary.tar.gz.part.$PART $URL && { echo "Downloaded summary.tar.gz.part.$PART successfully."; SUCCESS=1; break; }; \
                        echo "Failed to download $URL. Retrying..."; RETRIES=$((RETRIES + 1)); sleep 3; \
                      done; \
                      [ $SUCCESS -eq 0 ] && { echo "Failed to download $URL after $MAX_RETRIES attempts. Exiting."; rm /workspace/hf_models_cache/downloading; exit 1; }; \
                      echo "Unzipping summary.tar.gz.part.$PART..."; tar -xzf /workspace/hf_models_cache/summary.tar.gz.part.$PART -C /workspace/hf_models_cache/; echo "Unzipping summary.tar.gz.part.$PART complete...";'

                    rm /workspace/hf_models_cache/summary.tar.*
                    rm /workspace/hf_models_cache/downloading
                    touch /workspace/hf_models_cache/complete.g34b
                  }
                  if [ ! -f /workspace/hf_models_cache/complete.g34b ]; then
                    if [ ! -f /workspace/hf_models_cache/downloading ]; then
                      download_and_extract_model
                    else
                      echo "Download in progress by another pod. Waiting..."
                      while [ -f /workspace/hf_models_cache/downloading ] || [ ! -f /workspace/hf_models_cache/complete.g34b ]; do
                        sleep $((3 + RANDOM % 2))
                      done

                      if [ ! -f /workspace/hf_models_cache/complete.g34b ]; then
                        download_and_extract_model
                      else
                        echo "Model cache ready."
                      fi
                    fi
                  else
                    echo "Model cache already exists. Skipping download."
                  fi

                  echo "Model load done."
              image: public.ecr.aws/c9r4x6y5/eyelevel/busybox:1.0.0
              imagePullPolicy: IfNotPresent
              name: download-model
              securityContext:
                allowPrivilegeEscalation: false
                capabilities:
                  drop:
                    - ALL
                runAsGroup: 1001
                runAsNonRoot: true
                runAsUser: 1001
                seccompProfile:
                  type: RuntimeDefault
              volumeMounts:
                - mountPath: /workspace/hf_models_cache
                  name: model-volume
          securityContext:
            fsGroup: 1001
            fsGroupChangePolicy: OnRootMismatch
            runAsGroup: 1001
            runAsNonRoot: true
            runAsUser: 1001
            seccompProfile:
              type: RuntimeDefault
          serviceAccountName: existing-service-account
          tolerations:
            - effect: NoSchedule
              key: node
              value: eyelevel-gpu-summary
            - effect: NoSchedule
              key: eyelevel_node
              value: eyelevel-gpu-summary
          volumes:
            - configMap:
                name: config-models-map
              name: config-models
            - configMap:
                name: summary-config-py-map
              name: config-volume
            - configMap:
                name: summary-inference-supervisord-conf-map
              name: supervisord-volume
            - configMap:
                defaultMode: 365
                name: ldconfig-symlink-map
              name: summary-inference
            - hostPath:
                path: /sbin
                type: Directory
              name: host-sbin
            - hostPath:
                path: /usr/sbin
                type: Directory
              name: host-usr-sbin
            - hostPath:
                path: /bin
                type: Directory
              name: host-bin
            - hostPath:
                path: /usr/bin
                type: Directory
              name: host-usr-bin
            - name: model-volume
              persistentVolumeClaim:
                claimName: summary-model
  5: |
    apiVersion: v1
    kind: PersistentVolumeClaim
    metadata:
      labels:
        app: summary-inference
      name: summary-model
      namespace: eyelevel
    spec:
      accessModes:
        - ReadWriteOnce
      resources:
        requests:
          storage: 20Gi
      storageClassName: eyelevel-pv
'cloud: inference':
  1: |
    apiVersion: apps/v1
    kind: Deployment
    metadata:
      labels:
        app: layout-inference
        appVersion: 0.1.0
        chart: groundx-0.1.0
        heritage: Helm
        version: 0.1.0
      name: layout-inference
      namespace: eyelevel
    spec:
      replicas: 1
      selector:
        matchLabels:
          app: layout-inference
      template:
        metadata:
          annotations:
            config-hash: 049c37fdbe18201176cad7589519f0abedd3f900a382056ce812fbb34445447f
            config-models-hash: 529542d6881ddf622683f3bc8516205a5707660e0a921243b32fd51fd3573f4f
            ldconfig-symlink-hash: 9958a113394211878ece8f9030f4c08a1860e77aa75b5852bfa0691fc3faf32f
            supervisord-hash: 389d025411e33663295cbafcb9d7241d27e1d8736153cd1d14fa9c1b056107fe
          labels:
            app: layout-inference
        spec:
          affinity:
            nodeAffinity:
              requiredDuringSchedulingIgnoredDuringExecution:
                nodeSelectorTerms:
                  - matchExpressions:
                      - key: node
                        operator: In
                        values:
                          - eyelevel-gpu-layout
                  - matchExpressions:
                      - key: eyelevel_node
                        operator: In
                        values:
                          - eyelevel-gpu-layout
          containers:
            - command:
                - /bin/sh
                - -c
                - |
                  export PYTHONPATH=/app:$PYTHONPATH && python /app/init-layout.py && supervisord -c /app/supervisord.conf
              env:
                - name: POD_NAME
                  valueFrom:
                    fieldRef:
                      fieldPath: metadata.name
              image: public.ecr.aws/c9r4x6y5/eyelevel/layout-inference:0.1.0
              imagePullPolicy: IfNotPresent
              livenessProbe:
                failureThreshold: 8
                httpGet:
                  path: /alive
                  port: 8080
                initialDelaySeconds: 30
                periodSeconds: 15
              name: layout-inference
              ports:
                - containerPort: 8080
                  protocol: TCP
              readinessProbe:
                failureThreshold: 30
                httpGet:
                  path: /health
                  port: 8080
                initialDelaySeconds: 30
                periodSeconds: 15
              resources:
                limits:
                  memory: 12Gi
                  nvidia.com/gpu: 1
                requests:
                  cpu: 500m
                  memory: 2Gi
                  nvidia.com/gpu: 1
              securityContext:
                allowPrivilegeEscalation: false
                capabilities:
                  drop:
                    - ALL
                runAsGroup: 1001
                runAsNonRoot: true
                runAsUser: 1001
                seccompProfile:
                  type: RuntimeDefault
              volumeMounts:
                - mountPath: /app/config_models.py
                  name: config-models
                  subPath: config_models.py
                - mountPath: /app/config.py
                  name: config-volume
                  subPath: config.py
                - mountPath: /app/supervisord.conf
                  name: supervisord-volume
                  subPath: supervisord.conf
              workingDir: /app
          initContainers:
            - command:
                - sh
                - -c
                - until nc -z cache.eyelevel.svc.cluster.local 6379; do echo waiting for cache; sleep 2; done
              image: public.ecr.aws/c9r4x6y5/eyelevel/busybox:1.0.0
              imagePullPolicy: IfNotPresent
              name: wait-for-cache
            - command:
                - sh
                - -c
                - until nc -z X.s3.us-west-2.amazonaws.com 443; do echo waiting for file storage; sleep 2; done
              image: public.ecr.aws/c9r4x6y5/eyelevel/busybox:1.0.0
              imagePullPolicy: IfNotPresent
              name: wait-for-file-storage
            - args:
                - echo 'Running ldconfig_symlink.sh on this node'; /scripts/ldconfig_symlink.sh
              command:
                - /bin/sh
                - -c
                - --
              image: public.ecr.aws/c9r4x6y5/eyelevel/busybox:1.0.0
              imagePullPolicy: IfNotPresent
              name: create-symlink
              resources:
                requests:
                  cpu: 10m
                  memory: 50Mi
              securityContext:
                privileged: true
              volumeMounts:
                - mountPath: /scripts/ldconfig_symlink.sh
                  name: layout-inference
                  subPath: ldconfig_symlink.sh
                - mountPath: /host-sbin
                  name: host-sbin
                - mountPath: /host-usr-sbin
                  name: host-usr-sbin
                - mountPath: /host-bin
                  name: host-bin
                - mountPath: /host-usr-bin
                  name: host-usr-bin
          securityContext:
            fsGroup: 1001
            fsGroupChangePolicy: OnRootMismatch
            runAsGroup: 1001
            runAsNonRoot: true
            runAsUser: 1001
            seccompProfile:
              type: RuntimeDefault
          tolerations:
            - effect: NoSchedule
              key: node
              value: eyelevel-gpu-layout
            - effect: NoSchedule
              key: eyelevel_node
              value: eyelevel-gpu-layout
          volumes:
            - configMap:
                name: config-models-map
              name: config-models
            - configMap:
                name: layout-config-py-map
              name: config-volume
            - configMap:
                name: layout-inference-supervisord-conf-map
              name: supervisord-volume
            - configMap:
                defaultMode: 365
                name: ldconfig-symlink-map
              name: layout-inference
            - hostPath:
                path: /sbin
                type: Directory
              name: host-sbin
            - hostPath:
                path: /usr/sbin
                type: Directory
              name: host-usr-sbin
            - hostPath:
                path: /bin
                type: Directory
              name: host-bin
            - hostPath:
                path: /usr/bin
                type: Directory
              name: host-usr-bin
  2: |
    apiVersion: apps/v1
    kind: Deployment
    metadata:
      labels:
        app: ranker-inference
        appVersion: 0.1.0
        chart: groundx-0.1.0
        heritage: Helm
        version: 0.1.0
      name: ranker-inference
      namespace: eyelevel
    spec:
      replicas: 1
      selector:
        matchLabels:
          app: ranker-inference
      template:
        metadata:
          annotations:
            config-hash: 10a2c3714245d327a2110a7f94d5a48581c81788dfb36f046ef6276be59e0061
            config-models-hash: 529542d6881ddf622683f3bc8516205a5707660e0a921243b32fd51fd3573f4f
            ldconfig-symlink-hash: 9958a113394211878ece8f9030f4c08a1860e77aa75b5852bfa0691fc3faf32f
            supervisord-hash: c3de8d835a18146d0f59120a18513f20056efbb1cda896213ca789277d88a71b
          labels:
            app: ranker-inference
        spec:
          affinity:
            nodeAffinity:
              requiredDuringSchedulingIgnoredDuringExecution:
                nodeSelectorTerms:
                  - matchExpressions:
                      - key: node
                        operator: In
                        values:
                          - eyelevel-gpu-ranker
                  - matchExpressions:
                      - key: eyelevel_node
                        operator: In
                        values:
                          - eyelevel-gpu-ranker
          containers:
            - command:
                - /bin/sh
                - -c
                - |
                  export PYTHONPATH=/workspace:$PYTHONPATH &&  supervisord -c /workspace/supervisord.conf
              env:
                - name: POD_NAME
                  valueFrom:
                    fieldRef:
                      fieldPath: metadata.name
              image: public.ecr.aws/c9r4x6y5/eyelevel/ranker-inference:0.1.0
              imagePullPolicy: IfNotPresent
              livenessProbe:
                exec:
                  command:
                    - /bin/sh
                    - -c
                    - ps aux | grep 'ranker.celery.appSearch' | grep -v grep || exit 1
                failureThreshold: 10
                initialDelaySeconds: 60
                periodSeconds: 30
              name: ranker-inference
              readinessProbe:
                exec:
                  command:
                    - /bin/sh
                    - -c
                    - ps aux | grep 'ranker.celery.appSearch' | grep -v grep || exit 1
                initialDelaySeconds: 60
                periodSeconds: 30
              resources:
                limits:
                  nvidia.com/gpu: 1
                requests:
                  cpu: 1.5
                  memory: 1Gi
                  nvidia.com/gpu: 1
              securityContext:
                allowPrivilegeEscalation: false
                capabilities:
                  drop:
                    - ALL
                runAsGroup: 1001
                runAsNonRoot: true
                runAsUser: 1001
                seccompProfile:
                  type: RuntimeDefault
              volumeMounts:
                - mountPath: /workspace/config_models.py
                  name: config-models
                  subPath: config_models.py
                - mountPath: /workspace/config.py
                  name: config-volume
                  subPath: config.py
                - mountPath: /workspace/supervisord.conf
                  name: supervisord-volume
                  subPath: supervisord.conf
                - mountPath: /workspace/hf_models_cache
                  name: model-volume
              workingDir: /workspace
          initContainers:
            - command:
                - sh
                - -c
                - until nc -z cache.eyelevel.svc.cluster.local 6379; do echo waiting for cache; sleep 2; done
              image: public.ecr.aws/c9r4x6y5/eyelevel/busybox:1.0.0
              imagePullPolicy: IfNotPresent
              name: wait-for-cache
            - args:
                - echo 'Running ldconfig_symlink.sh on this node'; /scripts/ldconfig_symlink.sh
              command:
                - /bin/sh
                - -c
                - --
              image: public.ecr.aws/c9r4x6y5/eyelevel/busybox:1.0.0
              imagePullPolicy: IfNotPresent
              name: create-symlink
              resources:
                requests:
                  cpu: 10m
                  memory: 50Mi
              securityContext:
                privileged: true
              volumeMounts:
                - mountPath: /scripts/ldconfig_symlink.sh
                  name: ranker-inference
                  subPath: ldconfig_symlink.sh
                - mountPath: /host-sbin
                  name: host-sbin
                - mountPath: /host-usr-sbin
                  name: host-usr-sbin
                - mountPath: /host-bin
                  name: host-bin
                - mountPath: /host-usr-bin
                  name: host-usr-bin
            - command:
                - /bin/sh
                - -c
                - |
                  download_and_extract_model() {
                    echo "Model downloading started..."

                    touch /workspace/hf_models_cache/downloading

                    echo "00 01 02" | tr ' ' '\n' | xargs -n 1 -P 5 -I {} sh -c \
                      'MAX_RETRIES=3; RETRIES=0; SUCCESS=0; PART={}; URL=https://upload.groundx.ai/ranker/model/current/model.tar.gz.part.$PART; \
                      while [ $RETRIES -lt $MAX_RETRIES ]; do \
                        echo "Download [attempt $RETRIES] ranker.tar.gz.part.$PART"; \
                        wget -q -O /workspace/hf_models_cache/ranker.tar.gz.part.$PART $URL && { echo "Downloaded ranker.tar.gz.part.$PART successfully."; SUCCESS=1; break; }; \
                        echo "Failed to download $URL. Retrying..."; RETRIES=$((RETRIES + 1)); sleep 3; \
                      done; \
                      [ $SUCCESS -eq 0 ] && { echo "Failed to download $URL after $MAX_RETRIES attempts. Exiting."; rm /workspace/hf_models_cache/downloading; exit 1; }; \
                      echo "Unzipping ranker.tar.gz.part.$PART..."; tar -xzf /workspace/hf_models_cache/ranker.tar.gz.part.$PART -C /workspace/hf_models_cache/; echo "Unzipping ranker.tar.gz.part.$PART complete...";'

                    rm /workspace/hf_models_cache/ranker.tar.*
                    rm /workspace/hf_models_cache/downloading
                    touch /workspace/hf_models_cache/complete.model
                  }
                  if [ ! -f /workspace/hf_models_cache/complete.model ]; then
                    if [ ! -f /workspace/hf_models_cache/downloading ]; then
                      download_and_extract_model
                    else
                      echo "Download in progress by another pod. Waiting..."
                      while [ -f /workspace/hf_models_cache/downloading ] || [ ! -f /workspace/hf_models_cache/complete.model ]; do
                        sleep $((3 + RANDOM % 2))
                      done

                      if [ ! -f /workspace/hf_models_cache/complete.model ]; then
                        download_and_extract_model
                      else
                        echo "Model cache ready."
                      fi
                    fi
                  else
                    echo "Model cache already exists. Skipping download."
                  fi

                  echo "Model load done."
              image: public.ecr.aws/c9r4x6y5/eyelevel/busybox:1.0.0
              imagePullPolicy: IfNotPresent
              name: download-model
              securityContext:
                allowPrivilegeEscalation: false
                capabilities:
                  drop:
                    - ALL
                runAsGroup: 1001
                runAsNonRoot: true
                runAsUser: 1001
                seccompProfile:
                  type: RuntimeDefault
              volumeMounts:
                - mountPath: /workspace/hf_models_cache
                  name: model-volume
          securityContext:
            fsGroup: 1001
            fsGroupChangePolicy: OnRootMismatch
            runAsGroup: 1001
            runAsNonRoot: true
            runAsUser: 1001
            seccompProfile:
              type: RuntimeDefault
          tolerations:
            - effect: NoSchedule
              key: node
              value: eyelevel-gpu-ranker
            - effect: NoSchedule
              key: eyelevel_node
              value: eyelevel-gpu-ranker
          volumes:
            - configMap:
                name: config-models-map
              name: config-models
            - configMap:
                name: ranker-config-py-map
              name: config-volume
            - configMap:
                name: ranker-inference-supervisord-conf-map
              name: supervisord-volume
            - configMap:
                defaultMode: 365
                name: ldconfig-symlink-map
              name: ranker-inference
            - hostPath:
                path: /sbin
                type: Directory
              name: host-sbin
            - hostPath:
                path: /usr/sbin
                type: Directory
              name: host-usr-sbin
            - hostPath:
                path: /bin
                type: Directory
              name: host-bin
            - hostPath:
                path: /usr/bin
                type: Directory
              name: host-usr-bin
            - name: model-volume
              persistentVolumeClaim:
                claimName: ranker-model
  3: |
    apiVersion: v1
    kind: PersistentVolumeClaim
    metadata:
      labels:
        app: ranker-inference
      name: ranker-model
      namespace: eyelevel
    spec:
      accessModes:
        - ReadWriteOnce
      resources:
        requests:
          storage: 10Gi
      storageClassName: eyelevel-pv
  4: |
    apiVersion: apps/v1
    kind: Deployment
    metadata:
      labels:
        app: summary-inference
        appVersion: 0.1.0
        chart: groundx-0.1.0
        heritage: Helm
        version: 0.1.0
      name: summary-inference
      namespace: eyelevel
    spec:
      replicas: 2
      selector:
        matchLabels:
          app: summary-inference
      template:
        metadata:
          annotations:
            config-hash: 9b550f83fe615008fd7a3bd4fb324f3a3b8607943a72f3da1da21a0b31921ebc
            config-models-hash: 529542d6881ddf622683f3bc8516205a5707660e0a921243b32fd51fd3573f4f
            ldconfig-symlink-hash: 9958a113394211878ece8f9030f4c08a1860e77aa75b5852bfa0691fc3faf32f
            supervisord-hash: a48af0c98c4a6d0aafa9d919d204e9d8b1c51e416a36f766644a6c8d11e48a90
          labels:
            app: summary-inference
        spec:
          affinity:
            nodeAffinity:
              requiredDuringSchedulingIgnoredDuringExecution:
                nodeSelectorTerms:
                  - matchExpressions:
                      - key: node
                        operator: In
                        values:
                          - eyelevel-gpu-summary
                  - matchExpressions:
                      - key: eyelevel_node
                        operator: In
                        values:
                          - eyelevel-gpu-summary
          containers:
            - command:
                - /bin/sh
                - -c
                - |
                  export PYTHONPATH=/workspace:$PYTHONPATH &&  supervisord -c /workspace/supervisord.conf
              env:
                - name: POD_NAME
                  valueFrom:
                    fieldRef:
                      fieldPath: metadata.name
              image: public.ecr.aws/c9r4x6y5/eyelevel/summary-inference:0.1.0
              imagePullPolicy: IfNotPresent
              livenessProbe:
                failureThreshold: 8
                httpGet:
                  path: /alive
                  port: 8080
                initialDelaySeconds: 30
                periodSeconds: 15
              name: summary-inference
              ports:
                - containerPort: 8080
                  protocol: TCP
              readinessProbe:
                failureThreshold: 30
                httpGet:
                  path: /health
                  port: 8080
                initialDelaySeconds: 30
                periodSeconds: 15
              resources:
                requests:
                  cpu: 500m
                  memory: 1Gi
              securityContext:
                allowPrivilegeEscalation: false
                capabilities:
                  drop:
                    - ALL
                runAsGroup: 1001
                runAsNonRoot: true
                runAsUser: 1001
                seccompProfile:
                  type: RuntimeDefault
              volumeMounts:
                - mountPath: /workspace/config_models.py
                  name: config-models
                  subPath: config_models.py
                - mountPath: /workspace/config.py
                  name: config-volume
                  subPath: config.py
                - mountPath: /workspace/supervisord.conf
                  name: supervisord-volume
                  subPath: supervisord.conf
                - mountPath: /workspace/hf_models_cache
                  name: model-volume
              workingDir: /workspace
          initContainers:
            - command:
                - sh
                - -c
                - until nc -z cache.eyelevel.svc.cluster.local 6379; do echo waiting for cache; sleep 2; done
              image: public.ecr.aws/c9r4x6y5/eyelevel/busybox:1.0.0
              imagePullPolicy: IfNotPresent
              name: wait-for-cache
            - args:
                - echo 'Running ldconfig_symlink.sh on this node'; /scripts/ldconfig_symlink.sh
              command:
                - /bin/sh
                - -c
                - --
              image: public.ecr.aws/c9r4x6y5/eyelevel/busybox:1.0.0
              imagePullPolicy: IfNotPresent
              name: create-symlink
              resources:
                requests:
                  cpu: 10m
                  memory: 50Mi
              securityContext:
                privileged: true
              volumeMounts:
                - mountPath: /scripts/ldconfig_symlink.sh
                  name: summary-inference
                  subPath: ldconfig_symlink.sh
                - mountPath: /host-sbin
                  name: host-sbin
                - mountPath: /host-usr-sbin
                  name: host-usr-sbin
                - mountPath: /host-bin
                  name: host-bin
                - mountPath: /host-usr-bin
                  name: host-usr-bin
            - command:
                - /bin/sh
                - -c
                - |
                  download_and_extract_model() {
                    echo "Model downloading started..."

                    touch /workspace/hf_models_cache/downloading

                    echo "00 01 02 03 04" | tr ' ' '\n' | xargs -n 1 -P 5 -I {} sh -c \
                      'MAX_RETRIES=3; RETRIES=0; SUCCESS=0; PART={}; URL=https://upload.groundx.ai/summary/model/current/g34b.tar.gz.part.$PART; \
                      while [ $RETRIES -lt $MAX_RETRIES ]; do \
                        echo "Download [attempt $RETRIES] summary.tar.gz.part.$PART"; \
                        wget -q -O /workspace/hf_models_cache/summary.tar.gz.part.$PART $URL && { echo "Downloaded summary.tar.gz.part.$PART successfully."; SUCCESS=1; break; }; \
                        echo "Failed to download $URL. Retrying..."; RETRIES=$((RETRIES + 1)); sleep 3; \
                      done; \
                      [ $SUCCESS -eq 0 ] && { echo "Failed to download $URL after $MAX_RETRIES attempts. Exiting."; rm /workspace/hf_models_cache/downloading; exit 1; }; \
                      echo "Unzipping summary.tar.gz.part.$PART..."; tar -xzf /workspace/hf_models_cache/summary.tar.gz.part.$PART -C /workspace/hf_models_cache/; echo "Unzipping summary.tar.gz.part.$PART complete...";'

                    rm /workspace/hf_models_cache/summary.tar.*
                    rm /workspace/hf_models_cache/downloading
                    touch /workspace/hf_models_cache/complete.g34b
                  }
                  if [ ! -f /workspace/hf_models_cache/complete.g34b ]; then
                    if [ ! -f /workspace/hf_models_cache/downloading ]; then
                      download_and_extract_model
                    else
                      echo "Download in progress by another pod. Waiting..."
                      while [ -f /workspace/hf_models_cache/downloading ] || [ ! -f /workspace/hf_models_cache/complete.g34b ]; do
                        sleep $((3 + RANDOM % 2))
                      done

                      if [ ! -f /workspace/hf_models_cache/complete.g34b ]; then
                        download_and_extract_model
                      else
                        echo "Model cache ready."
                      fi
                    fi
                  else
                    echo "Model cache already exists. Skipping download."
                  fi

                  echo "Model load done."
              image: public.ecr.aws/c9r4x6y5/eyelevel/busybox:1.0.0
              imagePullPolicy: IfNotPresent
              name: download-model
              securityContext:
                allowPrivilegeEscalation: false
                capabilities:
                  drop:
                    - ALL
                runAsGroup: 1001
                runAsNonRoot: true
                runAsUser: 1001
                seccompProfile:
                  type: RuntimeDefault
              volumeMounts:
                - mountPath: /workspace/hf_models_cache
                  name: model-volume
          securityContext:
            fsGroup: 1001
            fsGroupChangePolicy: OnRootMismatch
            runAsGroup: 1001
            runAsNonRoot: true
            runAsUser: 1001
            seccompProfile:
              type: RuntimeDefault
          tolerations:
            - effect: NoSchedule
              key: node
              value: eyelevel-gpu-summary
            - effect: NoSchedule
              key: eyelevel_node
              value: eyelevel-gpu-summary
          volumes:
            - configMap:
                name: config-models-map
              name: config-models
            - configMap:
                name: summary-config-py-map
              name: config-volume
            - configMap:
                name: summary-inference-supervisord-conf-map
              name: supervisord-volume
            - configMap:
                defaultMode: 365
                name: ldconfig-symlink-map
              name: summary-inference
            - hostPath:
                path: /sbin
                type: Directory
              name: host-sbin
            - hostPath:
                path: /usr/sbin
                type: Directory
              name: host-usr-sbin
            - hostPath:
                path: /bin
                type: Directory
              name: host-bin
            - hostPath:
                path: /usr/bin
                type: Directory
              name: host-usr-bin
            - name: model-volume
              persistentVolumeClaim:
                claimName: summary-model
  5: |
    apiVersion: v1
    kind: PersistentVolumeClaim
    metadata:
      labels:
        app: summary-inference
      name: summary-model
      namespace: eyelevel
    spec:
      accessModes:
        - ReadWriteOnce
      resources:
        requests:
          storage: 20Gi
      storageClassName: eyelevel-pv
'default: inference':
  1: |
    apiVersion: apps/v1
    kind: Deployment
    metadata:
      labels:
        app: layout-inference
        appVersion: 0.1.0
        chart: groundx-0.1.0
        heritage: Helm
        version: 0.1.0
      name: layout-inference
      namespace: eyelevel
    spec:
      replicas: 1
      selector:
        matchLabels:
          app: layout-inference
      template:
        metadata:
          annotations:
            config-hash: d2f8a61a500bc77e4c1e128cb58c29295ae9d683661b44342c038609ac387352
            config-models-hash: 529542d6881ddf622683f3bc8516205a5707660e0a921243b32fd51fd3573f4f
            ldconfig-symlink-hash: 9958a113394211878ece8f9030f4c08a1860e77aa75b5852bfa0691fc3faf32f
            supervisord-hash: 389d025411e33663295cbafcb9d7241d27e1d8736153cd1d14fa9c1b056107fe
          labels:
            app: layout-inference
        spec:
          affinity:
            nodeAffinity:
              requiredDuringSchedulingIgnoredDuringExecution:
                nodeSelectorTerms:
                  - matchExpressions:
                      - key: node
                        operator: In
                        values:
                          - eyelevel-gpu-layout
                  - matchExpressions:
                      - key: eyelevel_node
                        operator: In
                        values:
                          - eyelevel-gpu-layout
          containers:
            - command:
                - /bin/sh
                - -c
                - |
                  export PYTHONPATH=/app:$PYTHONPATH && python /app/init-layout.py && supervisord -c /app/supervisord.conf
              env:
                - name: POD_NAME
                  valueFrom:
                    fieldRef:
                      fieldPath: metadata.name
              image: public.ecr.aws/c9r4x6y5/eyelevel/layout-inference:0.1.0
              imagePullPolicy: IfNotPresent
              livenessProbe:
                failureThreshold: 8
                httpGet:
                  path: /alive
                  port: 8080
                initialDelaySeconds: 30
                periodSeconds: 15
              name: layout-inference
              ports:
                - containerPort: 8080
                  protocol: TCP
              readinessProbe:
                failureThreshold: 30
                httpGet:
                  path: /health
                  port: 8080
                initialDelaySeconds: 30
                periodSeconds: 15
              resources:
                limits:
                  memory: 12Gi
                  nvidia.com/gpu: 1
                requests:
                  cpu: 500m
                  memory: 2Gi
                  nvidia.com/gpu: 1
              securityContext:
                allowPrivilegeEscalation: false
                capabilities:
                  drop:
                    - ALL
                runAsGroup: 1001
                runAsNonRoot: true
                runAsUser: 1001
                seccompProfile:
                  type: RuntimeDefault
              volumeMounts:
                - mountPath: /app/config_models.py
                  name: config-models
                  subPath: config_models.py
                - mountPath: /app/config.py
                  name: config-volume
                  subPath: config.py
                - mountPath: /app/supervisord.conf
                  name: supervisord-volume
                  subPath: supervisord.conf
              workingDir: /app
          initContainers:
            - command:
                - sh
                - -c
                - until nc -z cache.eyelevel.svc.cluster.local 6379; do echo waiting for cache; sleep 2; done
              image: public.ecr.aws/c9r4x6y5/eyelevel/busybox:1.0.0
              imagePullPolicy: IfNotPresent
              name: wait-for-cache
            - command:
                - sh
                - -c
                - until nc -z minio-tenant-hl.eyelevel.svc.cluster.local 9000; do echo waiting for file storage; sleep 2; done
              image: public.ecr.aws/c9r4x6y5/eyelevel/busybox:1.0.0
              imagePullPolicy: IfNotPresent
              name: wait-for-file-storage
            - args:
                - echo 'Running ldconfig_symlink.sh on this node'; /scripts/ldconfig_symlink.sh
              command:
                - /bin/sh
                - -c
                - --
              image: public.ecr.aws/c9r4x6y5/eyelevel/busybox:1.0.0
              imagePullPolicy: IfNotPresent
              name: create-symlink
              resources:
                requests:
                  cpu: 10m
                  memory: 50Mi
              securityContext:
                privileged: true
              volumeMounts:
                - mountPath: /scripts/ldconfig_symlink.sh
                  name: layout-inference
                  subPath: ldconfig_symlink.sh
                - mountPath: /host-sbin
                  name: host-sbin
                - mountPath: /host-usr-sbin
                  name: host-usr-sbin
                - mountPath: /host-bin
                  name: host-bin
                - mountPath: /host-usr-bin
                  name: host-usr-bin
          securityContext:
            fsGroup: 1001
            fsGroupChangePolicy: OnRootMismatch
            runAsGroup: 1001
            runAsNonRoot: true
            runAsUser: 1001
            seccompProfile:
              type: RuntimeDefault
          tolerations:
            - effect: NoSchedule
              key: node
              value: eyelevel-gpu-layout
            - effect: NoSchedule
              key: eyelevel_node
              value: eyelevel-gpu-layout
          volumes:
            - configMap:
                name: config-models-map
              name: config-models
            - configMap:
                name: layout-config-py-map
              name: config-volume
            - configMap:
                name: layout-inference-supervisord-conf-map
              name: supervisord-volume
            - configMap:
                defaultMode: 365
                name: ldconfig-symlink-map
              name: layout-inference
            - hostPath:
                path: /sbin
                type: Directory
              name: host-sbin
            - hostPath:
                path: /usr/sbin
                type: Directory
              name: host-usr-sbin
            - hostPath:
                path: /bin
                type: Directory
              name: host-bin
            - hostPath:
                path: /usr/bin
                type: Directory
              name: host-usr-bin
  2: |
    apiVersion: apps/v1
    kind: Deployment
    metadata:
      labels:
        app: ranker-inference
        appVersion: 0.1.0
        chart: groundx-0.1.0
        heritage: Helm
        version: 0.1.0
      name: ranker-inference
      namespace: eyelevel
    spec:
      replicas: 1
      selector:
        matchLabels:
          app: ranker-inference
      template:
        metadata:
          annotations:
            config-hash: d09038b15d81b45a3c91b675dba9421905acbd940eca1349b6af31098c98c043
            config-models-hash: 529542d6881ddf622683f3bc8516205a5707660e0a921243b32fd51fd3573f4f
            ldconfig-symlink-hash: 9958a113394211878ece8f9030f4c08a1860e77aa75b5852bfa0691fc3faf32f
            supervisord-hash: c3de8d835a18146d0f59120a18513f20056efbb1cda896213ca789277d88a71b
          labels:
            app: ranker-inference
        spec:
          affinity:
            nodeAffinity:
              requiredDuringSchedulingIgnoredDuringExecution:
                nodeSelectorTerms:
                  - matchExpressions:
                      - key: node
                        operator: In
                        values:
                          - eyelevel-gpu-ranker
                  - matchExpressions:
                      - key: eyelevel_node
                        operator: In
                        values:
                          - eyelevel-gpu-ranker
          containers:
            - command:
                - /bin/sh
                - -c
                - |
                  export PYTHONPATH=/workspace:$PYTHONPATH &&  supervisord -c /workspace/supervisord.conf
              env:
                - name: POD_NAME
                  valueFrom:
                    fieldRef:
                      fieldPath: metadata.name
              image: public.ecr.aws/c9r4x6y5/eyelevel/ranker-inference:0.1.0
              imagePullPolicy: IfNotPresent
              livenessProbe:
                exec:
                  command:
                    - /bin/sh
                    - -c
                    - ps aux | grep 'ranker.celery.appSearch' | grep -v grep || exit 1
                failureThreshold: 10
                initialDelaySeconds: 60
                periodSeconds: 30
              name: ranker-inference
              readinessProbe:
                exec:
                  command:
                    - /bin/sh
                    - -c
                    - ps aux | grep 'ranker.celery.appSearch' | grep -v grep || exit 1
                initialDelaySeconds: 60
                periodSeconds: 30
              resources:
                limits:
                  nvidia.com/gpu: 1
                requests:
                  cpu: 1.5
                  memory: 1Gi
                  nvidia.com/gpu: 1
              securityContext:
                allowPrivilegeEscalation: false
                capabilities:
                  drop:
                    - ALL
                runAsGroup: 1001
                runAsNonRoot: true
                runAsUser: 1001
                seccompProfile:
                  type: RuntimeDefault
              volumeMounts:
                - mountPath: /workspace/config_models.py
                  name: config-models
                  subPath: config_models.py
                - mountPath: /workspace/config.py
                  name: config-volume
                  subPath: config.py
                - mountPath: /workspace/supervisord.conf
                  name: supervisord-volume
                  subPath: supervisord.conf
                - mountPath: /workspace/hf_models_cache
                  name: model-volume
              workingDir: /workspace
          initContainers:
            - command:
                - sh
                - -c
                - until nc -z cache.eyelevel.svc.cluster.local 6379; do echo waiting for cache; sleep 2; done
              image: public.ecr.aws/c9r4x6y5/eyelevel/busybox:1.0.0
              imagePullPolicy: IfNotPresent
              name: wait-for-cache
            - args:
                - echo 'Running ldconfig_symlink.sh on this node'; /scripts/ldconfig_symlink.sh
              command:
                - /bin/sh
                - -c
                - --
              image: public.ecr.aws/c9r4x6y5/eyelevel/busybox:1.0.0
              imagePullPolicy: IfNotPresent
              name: create-symlink
              resources:
                requests:
                  cpu: 10m
                  memory: 50Mi
              securityContext:
                privileged: true
              volumeMounts:
                - mountPath: /scripts/ldconfig_symlink.sh
                  name: ranker-inference
                  subPath: ldconfig_symlink.sh
                - mountPath: /host-sbin
                  name: host-sbin
                - mountPath: /host-usr-sbin
                  name: host-usr-sbin
                - mountPath: /host-bin
                  name: host-bin
                - mountPath: /host-usr-bin
                  name: host-usr-bin
            - command:
                - /bin/sh
                - -c
                - |
                  download_and_extract_model() {
                    echo "Model downloading started..."

                    touch /workspace/hf_models_cache/downloading

                    echo "00 01 02" | tr ' ' '\n' | xargs -n 1 -P 5 -I {} sh -c \
                      'MAX_RETRIES=3; RETRIES=0; SUCCESS=0; PART={}; URL=https://upload.groundx.ai/ranker/model/current/model.tar.gz.part.$PART; \
                      while [ $RETRIES -lt $MAX_RETRIES ]; do \
                        echo "Download [attempt $RETRIES] ranker.tar.gz.part.$PART"; \
                        wget -q -O /workspace/hf_models_cache/ranker.tar.gz.part.$PART $URL && { echo "Downloaded ranker.tar.gz.part.$PART successfully."; SUCCESS=1; break; }; \
                        echo "Failed to download $URL. Retrying..."; RETRIES=$((RETRIES + 1)); sleep 3; \
                      done; \
                      [ $SUCCESS -eq 0 ] && { echo "Failed to download $URL after $MAX_RETRIES attempts. Exiting."; rm /workspace/hf_models_cache/downloading; exit 1; }; \
                      echo "Unzipping ranker.tar.gz.part.$PART..."; tar -xzf /workspace/hf_models_cache/ranker.tar.gz.part.$PART -C /workspace/hf_models_cache/; echo "Unzipping ranker.tar.gz.part.$PART complete...";'

                    rm /workspace/hf_models_cache/ranker.tar.*
                    rm /workspace/hf_models_cache/downloading
                    touch /workspace/hf_models_cache/complete.model
                  }
                  if [ ! -f /workspace/hf_models_cache/complete.model ]; then
                    if [ ! -f /workspace/hf_models_cache/downloading ]; then
                      download_and_extract_model
                    else
                      echo "Download in progress by another pod. Waiting..."
                      while [ -f /workspace/hf_models_cache/downloading ] || [ ! -f /workspace/hf_models_cache/complete.model ]; do
                        sleep $((3 + RANDOM % 2))
                      done

                      if [ ! -f /workspace/hf_models_cache/complete.model ]; then
                        download_and_extract_model
                      else
                        echo "Model cache ready."
                      fi
                    fi
                  else
                    echo "Model cache already exists. Skipping download."
                  fi

                  echo "Model load done."
              image: public.ecr.aws/c9r4x6y5/eyelevel/busybox:1.0.0
              imagePullPolicy: IfNotPresent
              name: download-model
              securityContext:
                allowPrivilegeEscalation: false
                capabilities:
                  drop:
                    - ALL
                runAsGroup: 1001
                runAsNonRoot: true
                runAsUser: 1001
                seccompProfile:
                  type: RuntimeDefault
              volumeMounts:
                - mountPath: /workspace/hf_models_cache
                  name: model-volume
          securityContext:
            fsGroup: 1001
            fsGroupChangePolicy: OnRootMismatch
            runAsGroup: 1001
            runAsNonRoot: true
            runAsUser: 1001
            seccompProfile:
              type: RuntimeDefault
          tolerations:
            - effect: NoSchedule
              key: node
              value: eyelevel-gpu-ranker
            - effect: NoSchedule
              key: eyelevel_node
              value: eyelevel-gpu-ranker
          volumes:
            - configMap:
                name: config-models-map
              name: config-models
            - configMap:
                name: ranker-config-py-map
              name: config-volume
            - configMap:
                name: ranker-inference-supervisord-conf-map
              name: supervisord-volume
            - configMap:
                defaultMode: 365
                name: ldconfig-symlink-map
              name: ranker-inference
            - hostPath:
                path: /sbin
                type: Directory
              name: host-sbin
            - hostPath:
                path: /usr/sbin
                type: Directory
              name: host-usr-sbin
            - hostPath:
                path: /bin
                type: Directory
              name: host-bin
            - hostPath:
                path: /usr/bin
                type: Directory
              name: host-usr-bin
            - name: model-volume
              persistentVolumeClaim:
                claimName: ranker-model
  3: |
    apiVersion: v1
    kind: PersistentVolumeClaim
    metadata:
      labels:
        app: ranker-inference
      name: ranker-model
      namespace: eyelevel
    spec:
      accessModes:
        - ReadWriteOnce
      resources:
        requests:
          storage: 10Gi
      storageClassName: eyelevel-pv
  4: |
    apiVersion: apps/v1
    kind: Deployment
    metadata:
      labels:
        app: summary-inference
        appVersion: 0.1.0
        chart: groundx-0.1.0
        heritage: Helm
        version: 0.1.0
      name: summary-inference
      namespace: eyelevel
    spec:
      replicas: 2
      selector:
        matchLabels:
          app: summary-inference
      template:
        metadata:
          annotations:
            config-hash: 98ce5b024876419328628261ed1d43fb288560dba6cfc74a959b79cf197491ab
            config-models-hash: 529542d6881ddf622683f3bc8516205a5707660e0a921243b32fd51fd3573f4f
            ldconfig-symlink-hash: 9958a113394211878ece8f9030f4c08a1860e77aa75b5852bfa0691fc3faf32f
            supervisord-hash: a48af0c98c4a6d0aafa9d919d204e9d8b1c51e416a36f766644a6c8d11e48a90
          labels:
            app: summary-inference
        spec:
          affinity:
            nodeAffinity:
              requiredDuringSchedulingIgnoredDuringExecution:
                nodeSelectorTerms:
                  - matchExpressions:
                      - key: node
                        operator: In
                        values:
                          - eyelevel-gpu-summary
                  - matchExpressions:
                      - key: eyelevel_node
                        operator: In
                        values:
                          - eyelevel-gpu-summary
          containers:
            - command:
                - /bin/sh
                - -c
                - |
                  export PYTHONPATH=/workspace:$PYTHONPATH &&  supervisord -c /workspace/supervisord.conf
              env:
                - name: POD_NAME
                  valueFrom:
                    fieldRef:
                      fieldPath: metadata.name
              image: public.ecr.aws/c9r4x6y5/eyelevel/summary-inference:0.1.0
              imagePullPolicy: IfNotPresent
              livenessProbe:
                failureThreshold: 8
                httpGet:
                  path: /alive
                  port: 8080
                initialDelaySeconds: 30
                periodSeconds: 15
              name: summary-inference
              ports:
                - containerPort: 8080
                  protocol: TCP
              readinessProbe:
                failureThreshold: 30
                httpGet:
                  path: /health
                  port: 8080
                initialDelaySeconds: 30
                periodSeconds: 15
              resources:
                requests:
                  cpu: 500m
                  memory: 1Gi
              securityContext:
                allowPrivilegeEscalation: false
                capabilities:
                  drop:
                    - ALL
                runAsGroup: 1001
                runAsNonRoot: true
                runAsUser: 1001
                seccompProfile:
                  type: RuntimeDefault
              volumeMounts:
                - mountPath: /workspace/config_models.py
                  name: config-models
                  subPath: config_models.py
                - mountPath: /workspace/config.py
                  name: config-volume
                  subPath: config.py
                - mountPath: /workspace/supervisord.conf
                  name: supervisord-volume
                  subPath: supervisord.conf
                - mountPath: /workspace/hf_models_cache
                  name: model-volume
              workingDir: /workspace
          initContainers:
            - command:
                - sh
                - -c
                - until nc -z cache.eyelevel.svc.cluster.local 6379; do echo waiting for cache; sleep 2; done
              image: public.ecr.aws/c9r4x6y5/eyelevel/busybox:1.0.0
              imagePullPolicy: IfNotPresent
              name: wait-for-cache
            - args:
                - echo 'Running ldconfig_symlink.sh on this node'; /scripts/ldconfig_symlink.sh
              command:
                - /bin/sh
                - -c
                - --
              image: public.ecr.aws/c9r4x6y5/eyelevel/busybox:1.0.0
              imagePullPolicy: IfNotPresent
              name: create-symlink
              resources:
                requests:
                  cpu: 10m
                  memory: 50Mi
              securityContext:
                privileged: true
              volumeMounts:
                - mountPath: /scripts/ldconfig_symlink.sh
                  name: summary-inference
                  subPath: ldconfig_symlink.sh
                - mountPath: /host-sbin
                  name: host-sbin
                - mountPath: /host-usr-sbin
                  name: host-usr-sbin
                - mountPath: /host-bin
                  name: host-bin
                - mountPath: /host-usr-bin
                  name: host-usr-bin
            - command:
                - /bin/sh
                - -c
                - |
                  download_and_extract_model() {
                    echo "Model downloading started..."

                    touch /workspace/hf_models_cache/downloading

                    echo "00 01 02 03 04" | tr ' ' '\n' | xargs -n 1 -P 5 -I {} sh -c \
                      'MAX_RETRIES=3; RETRIES=0; SUCCESS=0; PART={}; URL=https://upload.groundx.ai/summary/model/current/g34b.tar.gz.part.$PART; \
                      while [ $RETRIES -lt $MAX_RETRIES ]; do \
                        echo "Download [attempt $RETRIES] summary.tar.gz.part.$PART"; \
                        wget -q -O /workspace/hf_models_cache/summary.tar.gz.part.$PART $URL && { echo "Downloaded summary.tar.gz.part.$PART successfully."; SUCCESS=1; break; }; \
                        echo "Failed to download $URL. Retrying..."; RETRIES=$((RETRIES + 1)); sleep 3; \
                      done; \
                      [ $SUCCESS -eq 0 ] && { echo "Failed to download $URL after $MAX_RETRIES attempts. Exiting."; rm /workspace/hf_models_cache/downloading; exit 1; }; \
                      echo "Unzipping summary.tar.gz.part.$PART..."; tar -xzf /workspace/hf_models_cache/summary.tar.gz.part.$PART -C /workspace/hf_models_cache/; echo "Unzipping summary.tar.gz.part.$PART complete...";'

                    rm /workspace/hf_models_cache/summary.tar.*
                    rm /workspace/hf_models_cache/downloading
                    touch /workspace/hf_models_cache/complete.g34b
                  }
                  if [ ! -f /workspace/hf_models_cache/complete.g34b ]; then
                    if [ ! -f /workspace/hf_models_cache/downloading ]; then
                      download_and_extract_model
                    else
                      echo "Download in progress by another pod. Waiting..."
                      while [ -f /workspace/hf_models_cache/downloading ] || [ ! -f /workspace/hf_models_cache/complete.g34b ]; do
                        sleep $((3 + RANDOM % 2))
                      done

                      if [ ! -f /workspace/hf_models_cache/complete.g34b ]; then
                        download_and_extract_model
                      else
                        echo "Model cache ready."
                      fi
                    fi
                  else
                    echo "Model cache already exists. Skipping download."
                  fi

                  echo "Model load done."
              image: public.ecr.aws/c9r4x6y5/eyelevel/busybox:1.0.0
              imagePullPolicy: IfNotPresent
              name: download-model
              securityContext:
                allowPrivilegeEscalation: false
                capabilities:
                  drop:
                    - ALL
                runAsGroup: 1001
                runAsNonRoot: true
                runAsUser: 1001
                seccompProfile:
                  type: RuntimeDefault
              volumeMounts:
                - mountPath: /workspace/hf_models_cache
                  name: model-volume
          securityContext:
            fsGroup: 1001
            fsGroupChangePolicy: OnRootMismatch
            runAsGroup: 1001
            runAsNonRoot: true
            runAsUser: 1001
            seccompProfile:
              type: RuntimeDefault
          tolerations:
            - effect: NoSchedule
              key: node
              value: eyelevel-gpu-summary
            - effect: NoSchedule
              key: eyelevel_node
              value: eyelevel-gpu-summary
          volumes:
            - configMap:
                name: config-models-map
              name: config-models
            - configMap:
                name: summary-config-py-map
              name: config-volume
            - configMap:
                name: summary-inference-supervisord-conf-map
              name: supervisord-volume
            - configMap:
                defaultMode: 365
                name: ldconfig-symlink-map
              name: summary-inference
            - hostPath:
                path: /sbin
                type: Directory
              name: host-sbin
            - hostPath:
                path: /usr/sbin
                type: Directory
              name: host-usr-sbin
            - hostPath:
                path: /bin
                type: Directory
              name: host-bin
            - hostPath:
                path: /usr/bin
                type: Directory
              name: host-usr-bin
            - name: model-volume
              persistentVolumeClaim:
                claimName: summary-model
  5: |
    apiVersion: v1
    kind: PersistentVolumeClaim
    metadata:
      labels:
        app: summary-inference
      name: summary-model
      namespace: eyelevel
    spec:
      accessModes:
        - ReadWriteOnce
      resources:
        requests:
          storage: 20Gi
      storageClassName: eyelevel-pv
'disabled: inference':
'empty: inference':
  1: |
    apiVersion: apps/v1
    kind: Deployment
    metadata:
      labels:
        app: layout-inference
        appVersion: 0.1.0
        chart: groundx-0.1.0
        heritage: Helm
        version: 0.1.0
      name: layout-inference
      namespace: eyelevel
    spec:
      replicas: 1
      selector:
        matchLabels:
          app: layout-inference
      template:
        metadata:
          annotations:
            config-hash: d2f8a61a500bc77e4c1e128cb58c29295ae9d683661b44342c038609ac387352
            config-models-hash: 529542d6881ddf622683f3bc8516205a5707660e0a921243b32fd51fd3573f4f
            ldconfig-symlink-hash: 9958a113394211878ece8f9030f4c08a1860e77aa75b5852bfa0691fc3faf32f
            supervisord-hash: 389d025411e33663295cbafcb9d7241d27e1d8736153cd1d14fa9c1b056107fe
          labels:
            app: layout-inference
        spec:
          affinity:
            nodeAffinity:
              requiredDuringSchedulingIgnoredDuringExecution:
                nodeSelectorTerms:
                  - matchExpressions:
                      - key: node
                        operator: In
                        values:
                          - eyelevel-gpu-layout
                  - matchExpressions:
                      - key: eyelevel_node
                        operator: In
                        values:
                          - eyelevel-gpu-layout
          containers:
            - command:
                - /bin/sh
                - -c
                - |
                  export PYTHONPATH=/app:$PYTHONPATH && python /app/init-layout.py && supervisord -c /app/supervisord.conf
              env:
                - name: POD_NAME
                  valueFrom:
                    fieldRef:
                      fieldPath: metadata.name
              image: public.ecr.aws/c9r4x6y5/eyelevel/layout-inference:0.1.0
              imagePullPolicy: IfNotPresent
              livenessProbe:
                failureThreshold: 8
                httpGet:
                  path: /alive
                  port: 8080
                initialDelaySeconds: 30
                periodSeconds: 15
              name: layout-inference
              ports:
                - containerPort: 8080
                  protocol: TCP
              readinessProbe:
                failureThreshold: 30
                httpGet:
                  path: /health
                  port: 8080
                initialDelaySeconds: 30
                periodSeconds: 15
              resources:
                limits:
                  memory: 12Gi
                  nvidia.com/gpu: 1
                requests:
                  cpu: 500m
                  memory: 2Gi
                  nvidia.com/gpu: 1
              securityContext:
                allowPrivilegeEscalation: false
                capabilities:
                  drop:
                    - ALL
                runAsGroup: 1001
                runAsNonRoot: true
                runAsUser: 1001
                seccompProfile:
                  type: RuntimeDefault
              volumeMounts:
                - mountPath: /app/config_models.py
                  name: config-models
                  subPath: config_models.py
                - mountPath: /app/config.py
                  name: config-volume
                  subPath: config.py
                - mountPath: /app/supervisord.conf
                  name: supervisord-volume
                  subPath: supervisord.conf
              workingDir: /app
          initContainers:
            - command:
                - sh
                - -c
                - until nc -z cache.eyelevel.svc.cluster.local 6379; do echo waiting for cache; sleep 2; done
              image: public.ecr.aws/c9r4x6y5/eyelevel/busybox:1.0.0
              imagePullPolicy: IfNotPresent
              name: wait-for-cache
            - command:
                - sh
                - -c
                - until nc -z minio-tenant-hl.eyelevel.svc.cluster.local 9000; do echo waiting for file storage; sleep 2; done
              image: public.ecr.aws/c9r4x6y5/eyelevel/busybox:1.0.0
              imagePullPolicy: IfNotPresent
              name: wait-for-file-storage
            - args:
                - echo 'Running ldconfig_symlink.sh on this node'; /scripts/ldconfig_symlink.sh
              command:
                - /bin/sh
                - -c
                - --
              image: public.ecr.aws/c9r4x6y5/eyelevel/busybox:1.0.0
              imagePullPolicy: IfNotPresent
              name: create-symlink
              resources:
                requests:
                  cpu: 10m
                  memory: 50Mi
              securityContext:
                privileged: true
              volumeMounts:
                - mountPath: /scripts/ldconfig_symlink.sh
                  name: layout-inference
                  subPath: ldconfig_symlink.sh
                - mountPath: /host-sbin
                  name: host-sbin
                - mountPath: /host-usr-sbin
                  name: host-usr-sbin
                - mountPath: /host-bin
                  name: host-bin
                - mountPath: /host-usr-bin
                  name: host-usr-bin
          securityContext:
            fsGroup: 1001
            fsGroupChangePolicy: OnRootMismatch
            runAsGroup: 1001
            runAsNonRoot: true
            runAsUser: 1001
            seccompProfile:
              type: RuntimeDefault
          tolerations:
            - effect: NoSchedule
              key: node
              value: eyelevel-gpu-layout
            - effect: NoSchedule
              key: eyelevel_node
              value: eyelevel-gpu-layout
          volumes:
            - configMap:
                name: config-models-map
              name: config-models
            - configMap:
                name: layout-config-py-map
              name: config-volume
            - configMap:
                name: layout-inference-supervisord-conf-map
              name: supervisord-volume
            - configMap:
                defaultMode: 365
                name: ldconfig-symlink-map
              name: layout-inference
            - hostPath:
                path: /sbin
                type: Directory
              name: host-sbin
            - hostPath:
                path: /usr/sbin
                type: Directory
              name: host-usr-sbin
            - hostPath:
                path: /bin
                type: Directory
              name: host-bin
            - hostPath:
                path: /usr/bin
                type: Directory
              name: host-usr-bin
  2: |
    apiVersion: apps/v1
    kind: Deployment
    metadata:
      labels:
        app: ranker-inference
        appVersion: 0.1.0
        chart: groundx-0.1.0
        heritage: Helm
        version: 0.1.0
      name: ranker-inference
      namespace: eyelevel
    spec:
      replicas: 1
      selector:
        matchLabels:
          app: ranker-inference
      template:
        metadata:
          annotations:
            config-hash: d09038b15d81b45a3c91b675dba9421905acbd940eca1349b6af31098c98c043
            config-models-hash: 529542d6881ddf622683f3bc8516205a5707660e0a921243b32fd51fd3573f4f
            ldconfig-symlink-hash: 9958a113394211878ece8f9030f4c08a1860e77aa75b5852bfa0691fc3faf32f
            supervisord-hash: c3de8d835a18146d0f59120a18513f20056efbb1cda896213ca789277d88a71b
          labels:
            app: ranker-inference
        spec:
          affinity:
            nodeAffinity:
              requiredDuringSchedulingIgnoredDuringExecution:
                nodeSelectorTerms:
                  - matchExpressions:
                      - key: node
                        operator: In
                        values:
                          - eyelevel-gpu-ranker
                  - matchExpressions:
                      - key: eyelevel_node
                        operator: In
                        values:
                          - eyelevel-gpu-ranker
          containers:
            - command:
                - /bin/sh
                - -c
                - |
                  export PYTHONPATH=/workspace:$PYTHONPATH &&  supervisord -c /workspace/supervisord.conf
              env:
                - name: POD_NAME
                  valueFrom:
                    fieldRef:
                      fieldPath: metadata.name
              image: public.ecr.aws/c9r4x6y5/eyelevel/ranker-inference:0.1.0
              imagePullPolicy: IfNotPresent
              livenessProbe:
                exec:
                  command:
                    - /bin/sh
                    - -c
                    - ps aux | grep 'ranker.celery.appSearch' | grep -v grep || exit 1
                failureThreshold: 10
                initialDelaySeconds: 60
                periodSeconds: 30
              name: ranker-inference
              readinessProbe:
                exec:
                  command:
                    - /bin/sh
                    - -c
                    - ps aux | grep 'ranker.celery.appSearch' | grep -v grep || exit 1
                initialDelaySeconds: 60
                periodSeconds: 30
              resources:
                limits:
                  nvidia.com/gpu: 1
                requests:
                  cpu: 1.5
                  memory: 1Gi
                  nvidia.com/gpu: 1
              securityContext:
                allowPrivilegeEscalation: false
                capabilities:
                  drop:
                    - ALL
                runAsGroup: 1001
                runAsNonRoot: true
                runAsUser: 1001
                seccompProfile:
                  type: RuntimeDefault
              volumeMounts:
                - mountPath: /workspace/config_models.py
                  name: config-models
                  subPath: config_models.py
                - mountPath: /workspace/config.py
                  name: config-volume
                  subPath: config.py
                - mountPath: /workspace/supervisord.conf
                  name: supervisord-volume
                  subPath: supervisord.conf
                - mountPath: /workspace/hf_models_cache
                  name: model-volume
              workingDir: /workspace
          initContainers:
            - command:
                - sh
                - -c
                - until nc -z cache.eyelevel.svc.cluster.local 6379; do echo waiting for cache; sleep 2; done
              image: public.ecr.aws/c9r4x6y5/eyelevel/busybox:1.0.0
              imagePullPolicy: IfNotPresent
              name: wait-for-cache
            - args:
                - echo 'Running ldconfig_symlink.sh on this node'; /scripts/ldconfig_symlink.sh
              command:
                - /bin/sh
                - -c
                - --
              image: public.ecr.aws/c9r4x6y5/eyelevel/busybox:1.0.0
              imagePullPolicy: IfNotPresent
              name: create-symlink
              resources:
                requests:
                  cpu: 10m
                  memory: 50Mi
              securityContext:
                privileged: true
              volumeMounts:
                - mountPath: /scripts/ldconfig_symlink.sh
                  name: ranker-inference
                  subPath: ldconfig_symlink.sh
                - mountPath: /host-sbin
                  name: host-sbin
                - mountPath: /host-usr-sbin
                  name: host-usr-sbin
                - mountPath: /host-bin
                  name: host-bin
                - mountPath: /host-usr-bin
                  name: host-usr-bin
            - command:
                - /bin/sh
                - -c
                - |
                  download_and_extract_model() {
                    echo "Model downloading started..."

                    touch /workspace/hf_models_cache/downloading

                    echo "00 01 02" | tr ' ' '\n' | xargs -n 1 -P 5 -I {} sh -c \
                      'MAX_RETRIES=3; RETRIES=0; SUCCESS=0; PART={}; URL=https://upload.groundx.ai/ranker/model/current/model.tar.gz.part.$PART; \
                      while [ $RETRIES -lt $MAX_RETRIES ]; do \
                        echo "Download [attempt $RETRIES] ranker.tar.gz.part.$PART"; \
                        wget -q -O /workspace/hf_models_cache/ranker.tar.gz.part.$PART $URL && { echo "Downloaded ranker.tar.gz.part.$PART successfully."; SUCCESS=1; break; }; \
                        echo "Failed to download $URL. Retrying..."; RETRIES=$((RETRIES + 1)); sleep 3; \
                      done; \
                      [ $SUCCESS -eq 0 ] && { echo "Failed to download $URL after $MAX_RETRIES attempts. Exiting."; rm /workspace/hf_models_cache/downloading; exit 1; }; \
                      echo "Unzipping ranker.tar.gz.part.$PART..."; tar -xzf /workspace/hf_models_cache/ranker.tar.gz.part.$PART -C /workspace/hf_models_cache/; echo "Unzipping ranker.tar.gz.part.$PART complete...";'

                    rm /workspace/hf_models_cache/ranker.tar.*
                    rm /workspace/hf_models_cache/downloading
                    touch /workspace/hf_models_cache/complete.model
                  }
                  if [ ! -f /workspace/hf_models_cache/complete.model ]; then
                    if [ ! -f /workspace/hf_models_cache/downloading ]; then
                      download_and_extract_model
                    else
                      echo "Download in progress by another pod. Waiting..."
                      while [ -f /workspace/hf_models_cache/downloading ] || [ ! -f /workspace/hf_models_cache/complete.model ]; do
                        sleep $((3 + RANDOM % 2))
                      done

                      if [ ! -f /workspace/hf_models_cache/complete.model ]; then
                        download_and_extract_model
                      else
                        echo "Model cache ready."
                      fi
                    fi
                  else
                    echo "Model cache already exists. Skipping download."
                  fi

                  echo "Model load done."
              image: public.ecr.aws/c9r4x6y5/eyelevel/busybox:1.0.0
              imagePullPolicy: IfNotPresent
              name: download-model
              securityContext:
                allowPrivilegeEscalation: false
                capabilities:
                  drop:
                    - ALL
                runAsGroup: 1001
                runAsNonRoot: true
                runAsUser: 1001
                seccompProfile:
                  type: RuntimeDefault
              volumeMounts:
                - mountPath: /workspace/hf_models_cache
                  name: model-volume
          securityContext:
            fsGroup: 1001
            fsGroupChangePolicy: OnRootMismatch
            runAsGroup: 1001
            runAsNonRoot: true
            runAsUser: 1001
            seccompProfile:
              type: RuntimeDefault
          tolerations:
            - effect: NoSchedule
              key: node
              value: eyelevel-gpu-ranker
            - effect: NoSchedule
              key: eyelevel_node
              value: eyelevel-gpu-ranker
          volumes:
            - configMap:
                name: config-models-map
              name: config-models
            - configMap:
                name: ranker-config-py-map
              name: config-volume
            - configMap:
                name: ranker-inference-supervisord-conf-map
              name: supervisord-volume
            - configMap:
                defaultMode: 365
                name: ldconfig-symlink-map
              name: ranker-inference
            - hostPath:
                path: /sbin
                type: Directory
              name: host-sbin
            - hostPath:
                path: /usr/sbin
                type: Directory
              name: host-usr-sbin
            - hostPath:
                path: /bin
                type: Directory
              name: host-bin
            - hostPath:
                path: /usr/bin
                type: Directory
              name: host-usr-bin
            - name: model-volume
              persistentVolumeClaim:
                claimName: ranker-model
  3: |
    apiVersion: v1
    kind: PersistentVolumeClaim
    metadata:
      labels:
        app: ranker-inference
      name: ranker-model
      namespace: eyelevel
    spec:
      accessModes:
        - ReadWriteOnce
      resources:
        requests:
          storage: 10Gi
      storageClassName: eyelevel-pv
  4: |
    apiVersion: apps/v1
    kind: Deployment
    metadata:
      labels:
        app: summary-inference
        appVersion: 0.1.0
        chart: groundx-0.1.0
        heritage: Helm
        version: 0.1.0
      name: summary-inference
      namespace: eyelevel
    spec:
      replicas: 2
      selector:
        matchLabels:
          app: summary-inference
      template:
        metadata:
          annotations:
            config-hash: 98ce5b024876419328628261ed1d43fb288560dba6cfc74a959b79cf197491ab
            config-models-hash: 529542d6881ddf622683f3bc8516205a5707660e0a921243b32fd51fd3573f4f
            ldconfig-symlink-hash: 9958a113394211878ece8f9030f4c08a1860e77aa75b5852bfa0691fc3faf32f
            supervisord-hash: a48af0c98c4a6d0aafa9d919d204e9d8b1c51e416a36f766644a6c8d11e48a90
          labels:
            app: summary-inference
        spec:
          affinity:
            nodeAffinity:
              requiredDuringSchedulingIgnoredDuringExecution:
                nodeSelectorTerms:
                  - matchExpressions:
                      - key: node
                        operator: In
                        values:
                          - eyelevel-gpu-summary
                  - matchExpressions:
                      - key: eyelevel_node
                        operator: In
                        values:
                          - eyelevel-gpu-summary
          containers:
            - command:
                - /bin/sh
                - -c
                - |
                  export PYTHONPATH=/workspace:$PYTHONPATH &&  supervisord -c /workspace/supervisord.conf
              env:
                - name: POD_NAME
                  valueFrom:
                    fieldRef:
                      fieldPath: metadata.name
              image: public.ecr.aws/c9r4x6y5/eyelevel/summary-inference:0.1.0
              imagePullPolicy: IfNotPresent
              livenessProbe:
                failureThreshold: 8
                httpGet:
                  path: /alive
                  port: 8080
                initialDelaySeconds: 30
                periodSeconds: 15
              name: summary-inference
              ports:
                - containerPort: 8080
                  protocol: TCP
              readinessProbe:
                failureThreshold: 30
                httpGet:
                  path: /health
                  port: 8080
                initialDelaySeconds: 30
                periodSeconds: 15
              resources:
                requests:
                  cpu: 500m
                  memory: 1Gi
              securityContext:
                allowPrivilegeEscalation: false
                capabilities:
                  drop:
                    - ALL
                runAsGroup: 1001
                runAsNonRoot: true
                runAsUser: 1001
                seccompProfile:
                  type: RuntimeDefault
              volumeMounts:
                - mountPath: /workspace/config_models.py
                  name: config-models
                  subPath: config_models.py
                - mountPath: /workspace/config.py
                  name: config-volume
                  subPath: config.py
                - mountPath: /workspace/supervisord.conf
                  name: supervisord-volume
                  subPath: supervisord.conf
                - mountPath: /workspace/hf_models_cache
                  name: model-volume
              workingDir: /workspace
          initContainers:
            - command:
                - sh
                - -c
                - until nc -z cache.eyelevel.svc.cluster.local 6379; do echo waiting for cache; sleep 2; done
              image: public.ecr.aws/c9r4x6y5/eyelevel/busybox:1.0.0
              imagePullPolicy: IfNotPresent
              name: wait-for-cache
            - args:
                - echo 'Running ldconfig_symlink.sh on this node'; /scripts/ldconfig_symlink.sh
              command:
                - /bin/sh
                - -c
                - --
              image: public.ecr.aws/c9r4x6y5/eyelevel/busybox:1.0.0
              imagePullPolicy: IfNotPresent
              name: create-symlink
              resources:
                requests:
                  cpu: 10m
                  memory: 50Mi
              securityContext:
                privileged: true
              volumeMounts:
                - mountPath: /scripts/ldconfig_symlink.sh
                  name: summary-inference
                  subPath: ldconfig_symlink.sh
                - mountPath: /host-sbin
                  name: host-sbin
                - mountPath: /host-usr-sbin
                  name: host-usr-sbin
                - mountPath: /host-bin
                  name: host-bin
                - mountPath: /host-usr-bin
                  name: host-usr-bin
            - command:
                - /bin/sh
                - -c
                - |
                  download_and_extract_model() {
                    echo "Model downloading started..."

                    touch /workspace/hf_models_cache/downloading

                    echo "00 01 02 03 04" | tr ' ' '\n' | xargs -n 1 -P 5 -I {} sh -c \
                      'MAX_RETRIES=3; RETRIES=0; SUCCESS=0; PART={}; URL=https://upload.groundx.ai/summary/model/current/g34b.tar.gz.part.$PART; \
                      while [ $RETRIES -lt $MAX_RETRIES ]; do \
                        echo "Download [attempt $RETRIES] summary.tar.gz.part.$PART"; \
                        wget -q -O /workspace/hf_models_cache/summary.tar.gz.part.$PART $URL && { echo "Downloaded summary.tar.gz.part.$PART successfully."; SUCCESS=1; break; }; \
                        echo "Failed to download $URL. Retrying..."; RETRIES=$((RETRIES + 1)); sleep 3; \
                      done; \
                      [ $SUCCESS -eq 0 ] && { echo "Failed to download $URL after $MAX_RETRIES attempts. Exiting."; rm /workspace/hf_models_cache/downloading; exit 1; }; \
                      echo "Unzipping summary.tar.gz.part.$PART..."; tar -xzf /workspace/hf_models_cache/summary.tar.gz.part.$PART -C /workspace/hf_models_cache/; echo "Unzipping summary.tar.gz.part.$PART complete...";'

                    rm /workspace/hf_models_cache/summary.tar.*
                    rm /workspace/hf_models_cache/downloading
                    touch /workspace/hf_models_cache/complete.g34b
                  }
                  if [ ! -f /workspace/hf_models_cache/complete.g34b ]; then
                    if [ ! -f /workspace/hf_models_cache/downloading ]; then
                      download_and_extract_model
                    else
                      echo "Download in progress by another pod. Waiting..."
                      while [ -f /workspace/hf_models_cache/downloading ] || [ ! -f /workspace/hf_models_cache/complete.g34b ]; do
                        sleep $((3 + RANDOM % 2))
                      done

                      if [ ! -f /workspace/hf_models_cache/complete.g34b ]; then
                        download_and_extract_model
                      else
                        echo "Model cache ready."
                      fi
                    fi
                  else
                    echo "Model cache already exists. Skipping download."
                  fi

                  echo "Model load done."
              image: public.ecr.aws/c9r4x6y5/eyelevel/busybox:1.0.0
              imagePullPolicy: IfNotPresent
              name: download-model
              securityContext:
                allowPrivilegeEscalation: false
                capabilities:
                  drop:
                    - ALL
                runAsGroup: 1001
                runAsNonRoot: true
                runAsUser: 1001
                seccompProfile:
                  type: RuntimeDefault
              volumeMounts:
                - mountPath: /workspace/hf_models_cache
                  name: model-volume
          securityContext:
            fsGroup: 1001
            fsGroupChangePolicy: OnRootMismatch
            runAsGroup: 1001
            runAsNonRoot: true
            runAsUser: 1001
            seccompProfile:
              type: RuntimeDefault
          tolerations:
            - effect: NoSchedule
              key: node
              value: eyelevel-gpu-summary
            - effect: NoSchedule
              key: eyelevel_node
              value: eyelevel-gpu-summary
          volumes:
            - configMap:
                name: config-models-map
              name: config-models
            - configMap:
                name: summary-config-py-map
              name: config-volume
            - configMap:
                name: summary-inference-supervisord-conf-map
              name: supervisord-volume
            - configMap:
                defaultMode: 365
                name: ldconfig-symlink-map
              name: summary-inference
            - hostPath:
                path: /sbin
                type: Directory
              name: host-sbin
            - hostPath:
                path: /usr/sbin
                type: Directory
              name: host-usr-sbin
            - hostPath:
                path: /bin
                type: Directory
              name: host-bin
            - hostPath:
                path: /usr/bin
                type: Directory
              name: host-usr-bin
            - name: model-volume
              persistentVolumeClaim:
                claimName: summary-model
  5: |
    apiVersion: v1
    kind: PersistentVolumeClaim
    metadata:
      labels:
        app: summary-inference
      name: summary-model
      namespace: eyelevel
    spec:
      accessModes:
        - ReadWriteOnce
      resources:
        requests:
          storage: 20Gi
      storageClassName: eyelevel-pv
'existing: inference':
  1: |
    apiVersion: apps/v1
    kind: Deployment
    metadata:
      labels:
        app: layout-inference
        appVersion: 0.1.0
        chart: groundx-0.1.0
        heritage: Helm
        version: 0.1.0
      name: layout-inference
      namespace: eyelevel
    spec:
      replicas: 1
      selector:
        matchLabels:
          app: layout-inference
      template:
        metadata:
          annotations:
            config-hash: b06b20f2d0b0544c43eca2ac371f76b5837528a388f92d53a07c20e32c9a9d5b
            config-models-hash: 529542d6881ddf622683f3bc8516205a5707660e0a921243b32fd51fd3573f4f
            ldconfig-symlink-hash: 9958a113394211878ece8f9030f4c08a1860e77aa75b5852bfa0691fc3faf32f
            supervisord-hash: 389d025411e33663295cbafcb9d7241d27e1d8736153cd1d14fa9c1b056107fe
          labels:
            app: layout-inference
        spec:
          affinity:
            nodeAffinity:
              requiredDuringSchedulingIgnoredDuringExecution:
                nodeSelectorTerms:
                  - matchExpressions:
                      - key: node
                        operator: In
                        values:
                          - eyelevel-gpu-layout
                  - matchExpressions:
                      - key: eyelevel_node
                        operator: In
                        values:
                          - eyelevel-gpu-layout
          containers:
            - command:
                - /bin/sh
                - -c
                - |
                  export PYTHONPATH=/app:$PYTHONPATH && python /app/init-layout.py && supervisord -c /app/supervisord.conf
              env:
                - name: POD_NAME
                  valueFrom:
                    fieldRef:
                      fieldPath: metadata.name
              image: public.ecr.aws/c9r4x6y5/eyelevel/layout-inference:0.1.0
              imagePullPolicy: IfNotPresent
              livenessProbe:
                failureThreshold: 8
                httpGet:
                  path: /alive
                  port: 8080
                initialDelaySeconds: 30
                periodSeconds: 15
              name: layout-inference
              ports:
                - containerPort: 8080
                  protocol: TCP
              readinessProbe:
                failureThreshold: 30
                httpGet:
                  path: /health
                  port: 8080
                initialDelaySeconds: 30
                periodSeconds: 15
              resources:
                limits:
                  memory: 12Gi
                  nvidia.com/gpu: 1
                requests:
                  cpu: 500m
                  memory: 2Gi
                  nvidia.com/gpu: 1
              securityContext:
                allowPrivilegeEscalation: false
                capabilities:
                  drop:
                    - ALL
                runAsGroup: 1001
                runAsNonRoot: true
                runAsUser: 1001
                seccompProfile:
                  type: RuntimeDefault
              volumeMounts:
                - mountPath: /app/config_models.py
                  name: config-models
                  subPath: config_models.py
                - mountPath: /app/config.py
                  name: config-volume
                  subPath: config.py
                - mountPath: /app/supervisord.conf
                  name: supervisord-volume
                  subPath: supervisord.conf
              workingDir: /app
          initContainers:
            - command:
                - sh
                - -c
                - until nc -z cache.existing.com 6379; do echo waiting for cache; sleep 2; done
              image: public.ecr.aws/c9r4x6y5/eyelevel/busybox:1.0.0
              imagePullPolicy: IfNotPresent
              name: wait-for-cache
            - command:
                - sh
                - -c
                - until nc -z file.existing.com 9000; do echo waiting for file storage; sleep 2; done
              image: public.ecr.aws/c9r4x6y5/eyelevel/busybox:1.0.0
              imagePullPolicy: IfNotPresent
              name: wait-for-file-storage
            - args:
                - echo 'Running ldconfig_symlink.sh on this node'; /scripts/ldconfig_symlink.sh
              command:
                - /bin/sh
                - -c
                - --
              image: public.ecr.aws/c9r4x6y5/eyelevel/busybox:1.0.0
              imagePullPolicy: IfNotPresent
              name: create-symlink
              resources:
                requests:
                  cpu: 10m
                  memory: 50Mi
              securityContext:
                privileged: true
              volumeMounts:
                - mountPath: /scripts/ldconfig_symlink.sh
                  name: layout-inference
                  subPath: ldconfig_symlink.sh
                - mountPath: /host-sbin
                  name: host-sbin
                - mountPath: /host-usr-sbin
                  name: host-usr-sbin
                - mountPath: /host-bin
                  name: host-bin
                - mountPath: /host-usr-bin
                  name: host-usr-bin
          securityContext:
            fsGroup: 1001
            fsGroupChangePolicy: OnRootMismatch
            runAsGroup: 1001
            runAsNonRoot: true
            runAsUser: 1001
            seccompProfile:
              type: RuntimeDefault
          tolerations:
            - effect: NoSchedule
              key: node
              value: eyelevel-gpu-layout
            - effect: NoSchedule
              key: eyelevel_node
              value: eyelevel-gpu-layout
          volumes:
            - configMap:
                name: config-models-map
              name: config-models
            - configMap:
                name: layout-config-py-map
              name: config-volume
            - configMap:
                name: layout-inference-supervisord-conf-map
              name: supervisord-volume
            - configMap:
                defaultMode: 365
                name: ldconfig-symlink-map
              name: layout-inference
            - hostPath:
                path: /sbin
                type: Directory
              name: host-sbin
            - hostPath:
                path: /usr/sbin
                type: Directory
              name: host-usr-sbin
            - hostPath:
                path: /bin
                type: Directory
              name: host-bin
            - hostPath:
                path: /usr/bin
                type: Directory
              name: host-usr-bin
  2: |
    apiVersion: apps/v1
    kind: Deployment
    metadata:
      labels:
        app: ranker-inference
        appVersion: 0.1.0
        chart: groundx-0.1.0
        heritage: Helm
        version: 0.1.0
      name: ranker-inference
      namespace: eyelevel
    spec:
      replicas: 1
      selector:
        matchLabels:
          app: ranker-inference
      template:
        metadata:
          annotations:
            config-hash: 8e63ebfea1c0f60ac40bef43a8944a14369538ba8bb0421a10a4a0be5a804b9e
            config-models-hash: 529542d6881ddf622683f3bc8516205a5707660e0a921243b32fd51fd3573f4f
            ldconfig-symlink-hash: 9958a113394211878ece8f9030f4c08a1860e77aa75b5852bfa0691fc3faf32f
            supervisord-hash: c3de8d835a18146d0f59120a18513f20056efbb1cda896213ca789277d88a71b
          labels:
            app: ranker-inference
        spec:
          affinity:
            nodeAffinity:
              requiredDuringSchedulingIgnoredDuringExecution:
                nodeSelectorTerms:
                  - matchExpressions:
                      - key: node
                        operator: In
                        values:
                          - eyelevel-gpu-ranker
                  - matchExpressions:
                      - key: eyelevel_node
                        operator: In
                        values:
                          - eyelevel-gpu-ranker
          containers:
            - command:
                - /bin/sh
                - -c
                - |
                  export PYTHONPATH=/workspace:$PYTHONPATH &&  supervisord -c /workspace/supervisord.conf
              env:
                - name: POD_NAME
                  valueFrom:
                    fieldRef:
                      fieldPath: metadata.name
              image: public.ecr.aws/c9r4x6y5/eyelevel/ranker-inference:0.1.0
              imagePullPolicy: IfNotPresent
              livenessProbe:
                exec:
                  command:
                    - /bin/sh
                    - -c
                    - ps aux | grep 'ranker.celery.appSearch' | grep -v grep || exit 1
                failureThreshold: 10
                initialDelaySeconds: 60
                periodSeconds: 30
              name: ranker-inference
              readinessProbe:
                exec:
                  command:
                    - /bin/sh
                    - -c
                    - ps aux | grep 'ranker.celery.appSearch' | grep -v grep || exit 1
                initialDelaySeconds: 60
                periodSeconds: 30
              resources:
                limits:
                  nvidia.com/gpu: 1
                requests:
                  cpu: 1.5
                  memory: 1Gi
                  nvidia.com/gpu: 1
              securityContext:
                allowPrivilegeEscalation: false
                capabilities:
                  drop:
                    - ALL
                runAsGroup: 1001
                runAsNonRoot: true
                runAsUser: 1001
                seccompProfile:
                  type: RuntimeDefault
              volumeMounts:
                - mountPath: /workspace/config_models.py
                  name: config-models
                  subPath: config_models.py
                - mountPath: /workspace/config.py
                  name: config-volume
                  subPath: config.py
                - mountPath: /workspace/supervisord.conf
                  name: supervisord-volume
                  subPath: supervisord.conf
                - mountPath: /workspace/hf_models_cache
                  name: model-volume
              workingDir: /workspace
          initContainers:
            - command:
                - sh
                - -c
                - until nc -z cache.existing.com 6379; do echo waiting for cache; sleep 2; done
              image: public.ecr.aws/c9r4x6y5/eyelevel/busybox:1.0.0
              imagePullPolicy: IfNotPresent
              name: wait-for-cache
            - args:
                - echo 'Running ldconfig_symlink.sh on this node'; /scripts/ldconfig_symlink.sh
              command:
                - /bin/sh
                - -c
                - --
              image: public.ecr.aws/c9r4x6y5/eyelevel/busybox:1.0.0
              imagePullPolicy: IfNotPresent
              name: create-symlink
              resources:
                requests:
                  cpu: 10m
                  memory: 50Mi
              securityContext:
                privileged: true
              volumeMounts:
                - mountPath: /scripts/ldconfig_symlink.sh
                  name: ranker-inference
                  subPath: ldconfig_symlink.sh
                - mountPath: /host-sbin
                  name: host-sbin
                - mountPath: /host-usr-sbin
                  name: host-usr-sbin
                - mountPath: /host-bin
                  name: host-bin
                - mountPath: /host-usr-bin
                  name: host-usr-bin
            - command:
                - /bin/sh
                - -c
                - |
                  download_and_extract_model() {
                    echo "Model downloading started..."

                    touch /workspace/hf_models_cache/downloading

                    echo "00 01 02" | tr ' ' '\n' | xargs -n 1 -P 5 -I {} sh -c \
                      'MAX_RETRIES=3; RETRIES=0; SUCCESS=0; PART={}; URL=https://upload.groundx.ai/ranker/model/current/model.tar.gz.part.$PART; \
                      while [ $RETRIES -lt $MAX_RETRIES ]; do \
                        echo "Download [attempt $RETRIES] ranker.tar.gz.part.$PART"; \
                        wget -q -O /workspace/hf_models_cache/ranker.tar.gz.part.$PART $URL && { echo "Downloaded ranker.tar.gz.part.$PART successfully."; SUCCESS=1; break; }; \
                        echo "Failed to download $URL. Retrying..."; RETRIES=$((RETRIES + 1)); sleep 3; \
                      done; \
                      [ $SUCCESS -eq 0 ] && { echo "Failed to download $URL after $MAX_RETRIES attempts. Exiting."; rm /workspace/hf_models_cache/downloading; exit 1; }; \
                      echo "Unzipping ranker.tar.gz.part.$PART..."; tar -xzf /workspace/hf_models_cache/ranker.tar.gz.part.$PART -C /workspace/hf_models_cache/; echo "Unzipping ranker.tar.gz.part.$PART complete...";'

                    rm /workspace/hf_models_cache/ranker.tar.*
                    rm /workspace/hf_models_cache/downloading
                    touch /workspace/hf_models_cache/complete.model
                  }
                  if [ ! -f /workspace/hf_models_cache/complete.model ]; then
                    if [ ! -f /workspace/hf_models_cache/downloading ]; then
                      download_and_extract_model
                    else
                      echo "Download in progress by another pod. Waiting..."
                      while [ -f /workspace/hf_models_cache/downloading ] || [ ! -f /workspace/hf_models_cache/complete.model ]; do
                        sleep $((3 + RANDOM % 2))
                      done

                      if [ ! -f /workspace/hf_models_cache/complete.model ]; then
                        download_and_extract_model
                      else
                        echo "Model cache ready."
                      fi
                    fi
                  else
                    echo "Model cache already exists. Skipping download."
                  fi

                  echo "Model load done."
              image: public.ecr.aws/c9r4x6y5/eyelevel/busybox:1.0.0
              imagePullPolicy: IfNotPresent
              name: download-model
              securityContext:
                allowPrivilegeEscalation: false
                capabilities:
                  drop:
                    - ALL
                runAsGroup: 1001
                runAsNonRoot: true
                runAsUser: 1001
                seccompProfile:
                  type: RuntimeDefault
              volumeMounts:
                - mountPath: /workspace/hf_models_cache
                  name: model-volume
          securityContext:
            fsGroup: 1001
            fsGroupChangePolicy: OnRootMismatch
            runAsGroup: 1001
            runAsNonRoot: true
            runAsUser: 1001
            seccompProfile:
              type: RuntimeDefault
          tolerations:
            - effect: NoSchedule
              key: node
              value: eyelevel-gpu-ranker
            - effect: NoSchedule
              key: eyelevel_node
              value: eyelevel-gpu-ranker
          volumes:
            - configMap:
                name: config-models-map
              name: config-models
            - configMap:
                name: ranker-config-py-map
              name: config-volume
            - configMap:
                name: ranker-inference-supervisord-conf-map
              name: supervisord-volume
            - configMap:
                defaultMode: 365
                name: ldconfig-symlink-map
              name: ranker-inference
            - hostPath:
                path: /sbin
                type: Directory
              name: host-sbin
            - hostPath:
                path: /usr/sbin
                type: Directory
              name: host-usr-sbin
            - hostPath:
                path: /bin
                type: Directory
              name: host-bin
            - hostPath:
                path: /usr/bin
                type: Directory
              name: host-usr-bin
            - name: model-volume
              persistentVolumeClaim:
                claimName: ranker-model
  3: |
    apiVersion: v1
    kind: PersistentVolumeClaim
    metadata:
      labels:
        app: ranker-inference
      name: ranker-model
      namespace: eyelevel
    spec:
      accessModes:
        - ReadWriteOnce
      resources:
        requests:
          storage: 10Gi
      storageClassName: eyelevel-pv
'extract: inference':
  1: |
    apiVersion: apps/v1
    kind: Deployment
    metadata:
      labels:
        app: layout-inference
        appVersion: 0.1.0
        chart: groundx-0.1.0
        heritage: Helm
        version: 0.1.0
      name: layout-inference
      namespace: eyelevel
    spec:
      replicas: 1
      selector:
        matchLabels:
          app: layout-inference
      template:
        metadata:
          annotations:
            config-hash: cd27bb81927f5164f824cd11d7ddc53bf1ae2d7ca47d4608dfdd0eb9c5ad1637
            config-models-hash: 529542d6881ddf622683f3bc8516205a5707660e0a921243b32fd51fd3573f4f
            ldconfig-symlink-hash: 9958a113394211878ece8f9030f4c08a1860e77aa75b5852bfa0691fc3faf32f
            supervisord-hash: 389d025411e33663295cbafcb9d7241d27e1d8736153cd1d14fa9c1b056107fe
          labels:
            app: layout-inference
        spec:
          affinity:
            nodeAffinity:
              requiredDuringSchedulingIgnoredDuringExecution:
                nodeSelectorTerms:
                  - matchExpressions:
                      - key: node
                        operator: In
                        values:
                          - eyelevel-gpu-layout
                  - matchExpressions:
                      - key: eyelevel_node
                        operator: In
                        values:
                          - eyelevel-gpu-layout
          containers:
            - command:
                - /bin/sh
                - -c
                - |
                  export PYTHONPATH=/app:$PYTHONPATH && python /app/init-layout.py && supervisord -c /app/supervisord.conf
              env:
                - name: POD_NAME
                  valueFrom:
                    fieldRef:
                      fieldPath: metadata.name
              envFrom:
                - secretRef:
                    name: eyelevel-secret-credentials
              image: public.ecr.aws/c9r4x6y5/eyelevel/layout-inference:0.1.0
              imagePullPolicy: IfNotPresent
              livenessProbe:
                failureThreshold: 8
                httpGet:
                  path: /alive
                  port: 8080
                initialDelaySeconds: 30
                periodSeconds: 15
              name: layout-inference
              ports:
                - containerPort: 8080
                  protocol: TCP
              readinessProbe:
                failureThreshold: 30
                httpGet:
                  path: /health
                  port: 8080
                initialDelaySeconds: 30
                periodSeconds: 15
              resources:
                limits:
                  memory: 12Gi
                  nvidia.com/gpu: 1
                requests:
                  cpu: 500m
                  memory: 2Gi
                  nvidia.com/gpu: 1
              securityContext:
                allowPrivilegeEscalation: false
                capabilities:
                  drop:
                    - ALL
                runAsGroup: 1001
                runAsNonRoot: true
                runAsUser: 1001
                seccompProfile:
                  type: RuntimeDefault
              volumeMounts:
                - mountPath: /app/config_models.py
                  name: config-models
                  subPath: config_models.py
                - mountPath: /app/config.py
                  name: config-volume
                  subPath: config.py
                - mountPath: /app/supervisord.conf
                  name: supervisord-volume
                  subPath: supervisord.conf
              workingDir: /app
          initContainers:
            - command:
                - sh
                - -c
                - until nc -z X.X.X.use2.cache.amazonaws.com 6379; do echo waiting for cache; sleep 2; done
              image: public.ecr.aws/c9r4x6y5/eyelevel/busybox:1.0.0
              imagePullPolicy: IfNotPresent
              name: wait-for-cache
            - command:
                - sh
                - -c
                - until nc -z X.s3.us-west-2.amazonaws.com 443; do echo waiting for file storage; sleep 2; done
              image: public.ecr.aws/c9r4x6y5/eyelevel/busybox:1.0.0
              imagePullPolicy: IfNotPresent
              name: wait-for-file-storage
            - args:
                - echo 'Running ldconfig_symlink.sh on this node'; /scripts/ldconfig_symlink.sh
              command:
                - /bin/sh
                - -c
                - --
              image: public.ecr.aws/c9r4x6y5/eyelevel/busybox:1.0.0
              imagePullPolicy: IfNotPresent
              name: create-symlink
              resources:
                requests:
                  cpu: 10m
                  memory: 50Mi
              securityContext:
                privileged: true
              volumeMounts:
                - mountPath: /scripts/ldconfig_symlink.sh
                  name: layout-inference
                  subPath: ldconfig_symlink.sh
                - mountPath: /host-sbin
                  name: host-sbin
                - mountPath: /host-usr-sbin
                  name: host-usr-sbin
                - mountPath: /host-bin
                  name: host-bin
                - mountPath: /host-usr-bin
                  name: host-usr-bin
          securityContext:
            fsGroup: 1001
            fsGroupChangePolicy: OnRootMismatch
            runAsGroup: 1001
            runAsNonRoot: true
            runAsUser: 1001
            seccompProfile:
              type: RuntimeDefault
          serviceAccountName: existing-service-account
          tolerations:
            - effect: NoSchedule
              key: node
              value: eyelevel-gpu-layout
            - effect: NoSchedule
              key: eyelevel_node
              value: eyelevel-gpu-layout
          volumes:
            - configMap:
                name: config-models-map
              name: config-models
            - configMap:
                name: layout-config-py-map
              name: config-volume
            - configMap:
                name: layout-inference-supervisord-conf-map
              name: supervisord-volume
            - configMap:
                defaultMode: 365
                name: ldconfig-symlink-map
              name: layout-inference
            - hostPath:
                path: /sbin
                type: Directory
              name: host-sbin
            - hostPath:
                path: /usr/sbin
                type: Directory
              name: host-usr-sbin
            - hostPath:
                path: /bin
                type: Directory
              name: host-bin
            - hostPath:
                path: /usr/bin
                type: Directory
              name: host-usr-bin
  2: |
    apiVersion: apps/v1
    kind: Deployment
    metadata:
      labels:
        app: summary-inference
        appVersion: 0.1.0
        chart: groundx-0.1.0
        heritage: Helm
        version: 0.1.0
      name: summary-inference
      namespace: eyelevel
    spec:
      replicas: 2
      selector:
        matchLabels:
          app: summary-inference
      template:
        metadata:
          annotations:
            config-hash: 4219e04ff7ea14faa1eb8b710e1d62388ae5cc16d802bb65bd902a646bdcbcb4
            config-models-hash: 529542d6881ddf622683f3bc8516205a5707660e0a921243b32fd51fd3573f4f
            ldconfig-symlink-hash: 9958a113394211878ece8f9030f4c08a1860e77aa75b5852bfa0691fc3faf32f
            supervisord-hash: a48af0c98c4a6d0aafa9d919d204e9d8b1c51e416a36f766644a6c8d11e48a90
          labels:
            app: summary-inference
        spec:
          affinity:
            nodeAffinity:
              requiredDuringSchedulingIgnoredDuringExecution:
                nodeSelectorTerms:
                  - matchExpressions:
                      - key: node
                        operator: In
                        values:
                          - eyelevel-gpu-summary
                  - matchExpressions:
                      - key: eyelevel_node
                        operator: In
                        values:
                          - eyelevel-gpu-summary
          containers:
            - command:
                - /bin/sh
                - -c
                - |
                  export PYTHONPATH=/workspace:$PYTHONPATH &&  supervisord -c /workspace/supervisord.conf
              env:
                - name: POD_NAME
                  valueFrom:
                    fieldRef:
                      fieldPath: metadata.name
              envFrom:
                - secretRef:
                    name: eyelevel-secret-credentials
              image: public.ecr.aws/c9r4x6y5/eyelevel/summary-inference:0.1.0
              imagePullPolicy: IfNotPresent
              livenessProbe:
                failureThreshold: 8
                httpGet:
                  path: /alive
                  port: 8080
                initialDelaySeconds: 30
                periodSeconds: 15
              name: summary-inference
              ports:
                - containerPort: 8080
                  protocol: TCP
              readinessProbe:
                failureThreshold: 30
                httpGet:
                  path: /health
                  port: 8080
                initialDelaySeconds: 30
                periodSeconds: 15
              resources:
                requests:
                  cpu: 500m
                  memory: 1Gi
              securityContext:
                allowPrivilegeEscalation: false
                capabilities:
                  drop:
                    - ALL
                runAsGroup: 1001
                runAsNonRoot: true
                runAsUser: 1001
                seccompProfile:
                  type: RuntimeDefault
              volumeMounts:
                - mountPath: /workspace/config_models.py
                  name: config-models
                  subPath: config_models.py
                - mountPath: /workspace/config.py
                  name: config-volume
                  subPath: config.py
                - mountPath: /workspace/supervisord.conf
                  name: supervisord-volume
                  subPath: supervisord.conf
                - mountPath: /workspace/hf_models_cache
                  name: model-volume
              workingDir: /workspace
          initContainers:
            - command:
                - sh
                - -c
                - until nc -z X.X.X.use2.cache.amazonaws.com 6379; do echo waiting for cache; sleep 2; done
              image: public.ecr.aws/c9r4x6y5/eyelevel/busybox:1.0.0
              imagePullPolicy: IfNotPresent
              name: wait-for-cache
            - args:
                - echo 'Running ldconfig_symlink.sh on this node'; /scripts/ldconfig_symlink.sh
              command:
                - /bin/sh
                - -c
                - --
              image: public.ecr.aws/c9r4x6y5/eyelevel/busybox:1.0.0
              imagePullPolicy: IfNotPresent
              name: create-symlink
              resources:
                requests:
                  cpu: 10m
                  memory: 50Mi
              securityContext:
                privileged: true
              volumeMounts:
                - mountPath: /scripts/ldconfig_symlink.sh
                  name: summary-inference
                  subPath: ldconfig_symlink.sh
                - mountPath: /host-sbin
                  name: host-sbin
                - mountPath: /host-usr-sbin
                  name: host-usr-sbin
                - mountPath: /host-bin
                  name: host-bin
                - mountPath: /host-usr-bin
                  name: host-usr-bin
            - command:
                - /bin/sh
                - -c
                - |
                  download_and_extract_model() {
                    echo "Model downloading started..."

                    touch /workspace/hf_models_cache/downloading

                    echo "00 01 02 03 04" | tr ' ' '\n' | xargs -n 1 -P 5 -I {} sh -c \
                      'MAX_RETRIES=3; RETRIES=0; SUCCESS=0; PART={}; URL=https://upload.groundx.ai/summary/model/current/g34b.tar.gz.part.$PART; \
                      while [ $RETRIES -lt $MAX_RETRIES ]; do \
                        echo "Download [attempt $RETRIES] summary.tar.gz.part.$PART"; \
                        wget -q -O /workspace/hf_models_cache/summary.tar.gz.part.$PART $URL && { echo "Downloaded summary.tar.gz.part.$PART successfully."; SUCCESS=1; break; }; \
                        echo "Failed to download $URL. Retrying..."; RETRIES=$((RETRIES + 1)); sleep 3; \
                      done; \
                      [ $SUCCESS -eq 0 ] && { echo "Failed to download $URL after $MAX_RETRIES attempts. Exiting."; rm /workspace/hf_models_cache/downloading; exit 1; }; \
                      echo "Unzipping summary.tar.gz.part.$PART..."; tar -xzf /workspace/hf_models_cache/summary.tar.gz.part.$PART -C /workspace/hf_models_cache/; echo "Unzipping summary.tar.gz.part.$PART complete...";'

                    rm /workspace/hf_models_cache/summary.tar.*
                    rm /workspace/hf_models_cache/downloading
                    touch /workspace/hf_models_cache/complete.g34b
                  }
                  if [ ! -f /workspace/hf_models_cache/complete.g34b ]; then
                    if [ ! -f /workspace/hf_models_cache/downloading ]; then
                      download_and_extract_model
                    else
                      echo "Download in progress by another pod. Waiting..."
                      while [ -f /workspace/hf_models_cache/downloading ] || [ ! -f /workspace/hf_models_cache/complete.g34b ]; do
                        sleep $((3 + RANDOM % 2))
                      done

                      if [ ! -f /workspace/hf_models_cache/complete.g34b ]; then
                        download_and_extract_model
                      else
                        echo "Model cache ready."
                      fi
                    fi
                  else
                    echo "Model cache already exists. Skipping download."
                  fi

                  echo "Model load done."
              image: public.ecr.aws/c9r4x6y5/eyelevel/busybox:1.0.0
              imagePullPolicy: IfNotPresent
              name: download-model
              securityContext:
                allowPrivilegeEscalation: false
                capabilities:
                  drop:
                    - ALL
                runAsGroup: 1001
                runAsNonRoot: true
                runAsUser: 1001
                seccompProfile:
                  type: RuntimeDefault
              volumeMounts:
                - mountPath: /workspace/hf_models_cache
                  name: model-volume
          securityContext:
            fsGroup: 1001
            fsGroupChangePolicy: OnRootMismatch
            runAsGroup: 1001
            runAsNonRoot: true
            runAsUser: 1001
            seccompProfile:
              type: RuntimeDefault
          serviceAccountName: existing-service-account
          tolerations:
            - effect: NoSchedule
              key: node
              value: eyelevel-gpu-summary
            - effect: NoSchedule
              key: eyelevel_node
              value: eyelevel-gpu-summary
          volumes:
            - configMap:
                name: config-models-map
              name: config-models
            - configMap:
                name: summary-config-py-map
              name: config-volume
            - configMap:
                name: summary-inference-supervisord-conf-map
              name: supervisord-volume
            - configMap:
                defaultMode: 365
                name: ldconfig-symlink-map
              name: summary-inference
            - hostPath:
                path: /sbin
                type: Directory
              name: host-sbin
            - hostPath:
                path: /usr/sbin
                type: Directory
              name: host-usr-sbin
            - hostPath:
                path: /bin
                type: Directory
              name: host-bin
            - hostPath:
                path: /usr/bin
                type: Directory
              name: host-usr-bin
            - name: model-volume
              persistentVolumeClaim:
                claimName: summary-model
  3: |
    apiVersion: v1
    kind: PersistentVolumeClaim
    metadata:
      labels:
        app: summary-inference
      name: summary-model
      namespace: eyelevel
    spec:
      accessModes:
        - ReadWriteOnce
      resources:
        requests:
          storage: 20Gi
      storageClassName: eyelevel-pv
'extract.ingest: inference':
  1: |
    apiVersion: apps/v1
    kind: Deployment
    metadata:
      labels:
        app: layout-inference
        appVersion: 0.1.0
        chart: groundx-0.1.0
        heritage: Helm
        version: 0.1.0
      name: layout-inference
      namespace: eyelevel
    spec:
      replicas: 1
      selector:
        matchLabels:
          app: layout-inference
      template:
        metadata:
          annotations:
            config-hash: 5c76b67f2bc7e2de68d10d8d00ba8610e5397db2016a1ef5398f139b3f716062
            config-models-hash: 529542d6881ddf622683f3bc8516205a5707660e0a921243b32fd51fd3573f4f
            ldconfig-symlink-hash: 9958a113394211878ece8f9030f4c08a1860e77aa75b5852bfa0691fc3faf32f
            supervisord-hash: 389d025411e33663295cbafcb9d7241d27e1d8736153cd1d14fa9c1b056107fe
          labels:
            app: layout-inference
        spec:
          affinity:
            nodeAffinity:
              requiredDuringSchedulingIgnoredDuringExecution:
                nodeSelectorTerms:
                  - matchExpressions:
                      - key: node
                        operator: In
                        values:
                          - eyelevel-gpu-layout
                  - matchExpressions:
                      - key: eyelevel_node
                        operator: In
                        values:
                          - eyelevel-gpu-layout
          containers:
            - command:
                - /bin/sh
                - -c
                - |
                  export PYTHONPATH=/app:$PYTHONPATH && python /app/init-layout.py && supervisord -c /app/supervisord.conf
              env:
                - name: POD_NAME
                  valueFrom:
                    fieldRef:
                      fieldPath: metadata.name
              image: public.ecr.aws/c9r4x6y5/eyelevel/layout-inference:0.1.0
              imagePullPolicy: IfNotPresent
              livenessProbe:
                failureThreshold: 8
                httpGet:
                  path: /alive
                  port: 8080
                initialDelaySeconds: 30
                periodSeconds: 15
              name: layout-inference
              ports:
                - containerPort: 8080
                  protocol: TCP
              readinessProbe:
                failureThreshold: 30
                httpGet:
                  path: /health
                  port: 8080
                initialDelaySeconds: 30
                periodSeconds: 15
              resources:
                limits:
                  memory: 12Gi
                  nvidia.com/gpu: 1
                requests:
                  cpu: 500m
                  memory: 2Gi
                  nvidia.com/gpu: 1
              securityContext:
                allowPrivilegeEscalation: false
                capabilities:
                  drop:
                    - ALL
                runAsGroup: 1001
                runAsNonRoot: true
                runAsUser: 1001
                seccompProfile:
                  type: RuntimeDefault
              volumeMounts:
                - mountPath: /app/config_models.py
                  name: config-models
                  subPath: config_models.py
                - mountPath: /app/config.py
                  name: config-volume
                  subPath: config.py
                - mountPath: /app/supervisord.conf
                  name: supervisord-volume
                  subPath: supervisord.conf
              workingDir: /app
          initContainers:
            - command:
                - sh
                - -c
                - until nc -z X.X.X.use2.cache.amazonaws.com 6379; do echo waiting for cache; sleep 2; done
              image: public.ecr.aws/c9r4x6y5/eyelevel/busybox:1.0.0
              imagePullPolicy: IfNotPresent
              name: wait-for-cache
            - command:
                - sh
                - -c
                - until nc -z X.s3.us-west-2.amazonaws.com 443; do echo waiting for file storage; sleep 2; done
              image: public.ecr.aws/c9r4x6y5/eyelevel/busybox:1.0.0
              imagePullPolicy: IfNotPresent
              name: wait-for-file-storage
            - args:
                - echo 'Running ldconfig_symlink.sh on this node'; /scripts/ldconfig_symlink.sh
              command:
                - /bin/sh
                - -c
                - --
              image: public.ecr.aws/c9r4x6y5/eyelevel/busybox:1.0.0
              imagePullPolicy: IfNotPresent
              name: create-symlink
              resources:
                requests:
                  cpu: 10m
                  memory: 50Mi
              securityContext:
                privileged: true
              volumeMounts:
                - mountPath: /scripts/ldconfig_symlink.sh
                  name: layout-inference
                  subPath: ldconfig_symlink.sh
                - mountPath: /host-sbin
                  name: host-sbin
                - mountPath: /host-usr-sbin
                  name: host-usr-sbin
                - mountPath: /host-bin
                  name: host-bin
                - mountPath: /host-usr-bin
                  name: host-usr-bin
          securityContext:
            fsGroup: 1001
            fsGroupChangePolicy: OnRootMismatch
            runAsGroup: 1001
            runAsNonRoot: true
            runAsUser: 1001
            seccompProfile:
              type: RuntimeDefault
          tolerations:
            - effect: NoSchedule
              key: node
              value: eyelevel-gpu-layout
            - effect: NoSchedule
              key: eyelevel_node
              value: eyelevel-gpu-layout
          volumes:
            - configMap:
                name: config-models-map
              name: config-models
            - configMap:
                name: layout-config-py-map
              name: config-volume
            - configMap:
                name: layout-inference-supervisord-conf-map
              name: supervisord-volume
            - configMap:
                defaultMode: 365
                name: ldconfig-symlink-map
              name: layout-inference
            - hostPath:
                path: /sbin
                type: Directory
              name: host-sbin
            - hostPath:
                path: /usr/sbin
                type: Directory
              name: host-usr-sbin
            - hostPath:
                path: /bin
                type: Directory
              name: host-bin
            - hostPath:
                path: /usr/bin
                type: Directory
              name: host-usr-bin
  2: |
    apiVersion: apps/v1
    kind: Deployment
    metadata:
      labels:
        app: summary-inference
        appVersion: 0.1.0
        chart: groundx-0.1.0
        heritage: Helm
        version: 0.1.0
      name: summary-inference
      namespace: eyelevel
    spec:
      replicas: 2
      selector:
        matchLabels:
          app: summary-inference
      template:
        metadata:
          annotations:
            config-hash: e059715cac78edb91cf35e9d601b544d69549ff9efa79b4ca64efeb88b19f652
            config-models-hash: 529542d6881ddf622683f3bc8516205a5707660e0a921243b32fd51fd3573f4f
            ldconfig-symlink-hash: 9958a113394211878ece8f9030f4c08a1860e77aa75b5852bfa0691fc3faf32f
            supervisord-hash: a48af0c98c4a6d0aafa9d919d204e9d8b1c51e416a36f766644a6c8d11e48a90
          labels:
            app: summary-inference
        spec:
          affinity:
            nodeAffinity:
              requiredDuringSchedulingIgnoredDuringExecution:
                nodeSelectorTerms:
                  - matchExpressions:
                      - key: node
                        operator: In
                        values:
                          - eyelevel-gpu-summary
                  - matchExpressions:
                      - key: eyelevel_node
                        operator: In
                        values:
                          - eyelevel-gpu-summary
          containers:
            - command:
                - /bin/sh
                - -c
                - |
                  export PYTHONPATH=/workspace:$PYTHONPATH &&  supervisord -c /workspace/supervisord.conf
              env:
                - name: POD_NAME
                  valueFrom:
                    fieldRef:
                      fieldPath: metadata.name
              image: public.ecr.aws/c9r4x6y5/eyelevel/summary-inference:0.1.0
              imagePullPolicy: IfNotPresent
              livenessProbe:
                failureThreshold: 8
                httpGet:
                  path: /alive
                  port: 8080
                initialDelaySeconds: 30
                periodSeconds: 15
              name: summary-inference
              ports:
                - containerPort: 8080
                  protocol: TCP
              readinessProbe:
                failureThreshold: 30
                httpGet:
                  path: /health
                  port: 8080
                initialDelaySeconds: 30
                periodSeconds: 15
              resources:
                requests:
                  cpu: 500m
                  memory: 1Gi
              securityContext:
                allowPrivilegeEscalation: false
                capabilities:
                  drop:
                    - ALL
                runAsGroup: 1001
                runAsNonRoot: true
                runAsUser: 1001
                seccompProfile:
                  type: RuntimeDefault
              volumeMounts:
                - mountPath: /workspace/config_models.py
                  name: config-models
                  subPath: config_models.py
                - mountPath: /workspace/config.py
                  name: config-volume
                  subPath: config.py
                - mountPath: /workspace/supervisord.conf
                  name: supervisord-volume
                  subPath: supervisord.conf
                - mountPath: /workspace/hf_models_cache
                  name: model-volume
              workingDir: /workspace
          initContainers:
            - command:
                - sh
                - -c
                - until nc -z X.X.X.use2.cache.amazonaws.com 6379; do echo waiting for cache; sleep 2; done
              image: public.ecr.aws/c9r4x6y5/eyelevel/busybox:1.0.0
              imagePullPolicy: IfNotPresent
              name: wait-for-cache
            - args:
                - echo 'Running ldconfig_symlink.sh on this node'; /scripts/ldconfig_symlink.sh
              command:
                - /bin/sh
                - -c
                - --
              image: public.ecr.aws/c9r4x6y5/eyelevel/busybox:1.0.0
              imagePullPolicy: IfNotPresent
              name: create-symlink
              resources:
                requests:
                  cpu: 10m
                  memory: 50Mi
              securityContext:
                privileged: true
              volumeMounts:
                - mountPath: /scripts/ldconfig_symlink.sh
                  name: summary-inference
                  subPath: ldconfig_symlink.sh
                - mountPath: /host-sbin
                  name: host-sbin
                - mountPath: /host-usr-sbin
                  name: host-usr-sbin
                - mountPath: /host-bin
                  name: host-bin
                - mountPath: /host-usr-bin
                  name: host-usr-bin
            - command:
                - /bin/sh
                - -c
                - |
                  download_and_extract_model() {
                    echo "Model downloading started..."

                    touch /workspace/hf_models_cache/downloading

                    echo "00 01 02 03 04" | tr ' ' '\n' | xargs -n 1 -P 5 -I {} sh -c \
                      'MAX_RETRIES=3; RETRIES=0; SUCCESS=0; PART={}; URL=https://upload.groundx.ai/summary/model/current/g34b.tar.gz.part.$PART; \
                      while [ $RETRIES -lt $MAX_RETRIES ]; do \
                        echo "Download [attempt $RETRIES] summary.tar.gz.part.$PART"; \
                        wget -q -O /workspace/hf_models_cache/summary.tar.gz.part.$PART $URL && { echo "Downloaded summary.tar.gz.part.$PART successfully."; SUCCESS=1; break; }; \
                        echo "Failed to download $URL. Retrying..."; RETRIES=$((RETRIES + 1)); sleep 3; \
                      done; \
                      [ $SUCCESS -eq 0 ] && { echo "Failed to download $URL after $MAX_RETRIES attempts. Exiting."; rm /workspace/hf_models_cache/downloading; exit 1; }; \
                      echo "Unzipping summary.tar.gz.part.$PART..."; tar -xzf /workspace/hf_models_cache/summary.tar.gz.part.$PART -C /workspace/hf_models_cache/; echo "Unzipping summary.tar.gz.part.$PART complete...";'

                    rm /workspace/hf_models_cache/summary.tar.*
                    rm /workspace/hf_models_cache/downloading
                    touch /workspace/hf_models_cache/complete.g34b
                  }
                  if [ ! -f /workspace/hf_models_cache/complete.g34b ]; then
                    if [ ! -f /workspace/hf_models_cache/downloading ]; then
                      download_and_extract_model
                    else
                      echo "Download in progress by another pod. Waiting..."
                      while [ -f /workspace/hf_models_cache/downloading ] || [ ! -f /workspace/hf_models_cache/complete.g34b ]; do
                        sleep $((3 + RANDOM % 2))
                      done

                      if [ ! -f /workspace/hf_models_cache/complete.g34b ]; then
                        download_and_extract_model
                      else
                        echo "Model cache ready."
                      fi
                    fi
                  else
                    echo "Model cache already exists. Skipping download."
                  fi

                  echo "Model load done."
              image: public.ecr.aws/c9r4x6y5/eyelevel/busybox:1.0.0
              imagePullPolicy: IfNotPresent
              name: download-model
              securityContext:
                allowPrivilegeEscalation: false
                capabilities:
                  drop:
                    - ALL
                runAsGroup: 1001
                runAsNonRoot: true
                runAsUser: 1001
                seccompProfile:
                  type: RuntimeDefault
              volumeMounts:
                - mountPath: /workspace/hf_models_cache
                  name: model-volume
          securityContext:
            fsGroup: 1001
            fsGroupChangePolicy: OnRootMismatch
            runAsGroup: 1001
            runAsNonRoot: true
            runAsUser: 1001
            seccompProfile:
              type: RuntimeDefault
          tolerations:
            - effect: NoSchedule
              key: node
              value: eyelevel-gpu-summary
            - effect: NoSchedule
              key: eyelevel_node
              value: eyelevel-gpu-summary
          volumes:
            - configMap:
                name: config-models-map
              name: config-models
            - configMap:
                name: summary-config-py-map
              name: config-volume
            - configMap:
                name: summary-inference-supervisord-conf-map
              name: supervisord-volume
            - configMap:
                defaultMode: 365
                name: ldconfig-symlink-map
              name: summary-inference
            - hostPath:
                path: /sbin
                type: Directory
              name: host-sbin
            - hostPath:
                path: /usr/sbin
                type: Directory
              name: host-usr-sbin
            - hostPath:
                path: /bin
                type: Directory
              name: host-bin
            - hostPath:
                path: /usr/bin
                type: Directory
              name: host-usr-bin
            - name: model-volume
              persistentVolumeClaim:
                claimName: summary-model
  3: |
    apiVersion: v1
    kind: PersistentVolumeClaim
    metadata:
      labels:
        app: summary-inference
      name: summary-model
      namespace: eyelevel
    spec:
      accessModes:
        - ReadWriteOnce
      resources:
        requests:
          storage: 20Gi
      storageClassName: eyelevel-pv
'extract.oai: inference':
  1: |
    apiVersion: apps/v1
    kind: Deployment
    metadata:
      labels:
        app: layout-inference
        appVersion: 0.1.0
        chart: groundx-0.1.0
        heritage: Helm
        version: 0.1.0
      name: layout-inference
      namespace: eyelevel
    spec:
      replicas: 1
      selector:
        matchLabels:
          app: layout-inference
      template:
        metadata:
          annotations:
            config-hash: cd27bb81927f5164f824cd11d7ddc53bf1ae2d7ca47d4608dfdd0eb9c5ad1637
            config-models-hash: 529542d6881ddf622683f3bc8516205a5707660e0a921243b32fd51fd3573f4f
            ldconfig-symlink-hash: 9958a113394211878ece8f9030f4c08a1860e77aa75b5852bfa0691fc3faf32f
            supervisord-hash: 389d025411e33663295cbafcb9d7241d27e1d8736153cd1d14fa9c1b056107fe
          labels:
            app: layout-inference
        spec:
          affinity:
            nodeAffinity:
              requiredDuringSchedulingIgnoredDuringExecution:
                nodeSelectorTerms:
                  - matchExpressions:
                      - key: node
                        operator: In
                        values:
                          - eyelevel-gpu-layout
                  - matchExpressions:
                      - key: eyelevel_node
                        operator: In
                        values:
                          - eyelevel-gpu-layout
          containers:
            - command:
                - /bin/sh
                - -c
                - |
                  export PYTHONPATH=/app:$PYTHONPATH && python /app/init-layout.py && supervisord -c /app/supervisord.conf
              env:
                - name: POD_NAME
                  valueFrom:
                    fieldRef:
                      fieldPath: metadata.name
              envFrom:
                - secretRef:
                    name: eyelevel-secret-credentials
              image: public.ecr.aws/c9r4x6y5/eyelevel/layout-inference:0.1.0
              imagePullPolicy: IfNotPresent
              livenessProbe:
                failureThreshold: 8
                httpGet:
                  path: /alive
                  port: 8080
                initialDelaySeconds: 30
                periodSeconds: 15
              name: layout-inference
              ports:
                - containerPort: 8080
                  protocol: TCP
              readinessProbe:
                failureThreshold: 30
                httpGet:
                  path: /health
                  port: 8080
                initialDelaySeconds: 30
                periodSeconds: 15
              resources:
                limits:
                  memory: 12Gi
                  nvidia.com/gpu: 1
                requests:
                  cpu: 500m
                  memory: 2Gi
                  nvidia.com/gpu: 1
              securityContext:
                allowPrivilegeEscalation: false
                capabilities:
                  drop:
                    - ALL
                runAsGroup: 1001
                runAsNonRoot: true
                runAsUser: 1001
                seccompProfile:
                  type: RuntimeDefault
              volumeMounts:
                - mountPath: /app/config_models.py
                  name: config-models
                  subPath: config_models.py
                - mountPath: /app/config.py
                  name: config-volume
                  subPath: config.py
                - mountPath: /app/supervisord.conf
                  name: supervisord-volume
                  subPath: supervisord.conf
              workingDir: /app
          initContainers:
            - command:
                - sh
                - -c
                - until nc -z X.X.X.use2.cache.amazonaws.com 6379; do echo waiting for cache; sleep 2; done
              image: public.ecr.aws/c9r4x6y5/eyelevel/busybox:1.0.0
              imagePullPolicy: IfNotPresent
              name: wait-for-cache
            - command:
                - sh
                - -c
                - until nc -z X.s3.us-west-2.amazonaws.com 443; do echo waiting for file storage; sleep 2; done
              image: public.ecr.aws/c9r4x6y5/eyelevel/busybox:1.0.0
              imagePullPolicy: IfNotPresent
              name: wait-for-file-storage
            - args:
                - echo 'Running ldconfig_symlink.sh on this node'; /scripts/ldconfig_symlink.sh
              command:
                - /bin/sh
                - -c
                - --
              image: public.ecr.aws/c9r4x6y5/eyelevel/busybox:1.0.0
              imagePullPolicy: IfNotPresent
              name: create-symlink
              resources:
                requests:
                  cpu: 10m
                  memory: 50Mi
              securityContext:
                privileged: true
              volumeMounts:
                - mountPath: /scripts/ldconfig_symlink.sh
                  name: layout-inference
                  subPath: ldconfig_symlink.sh
                - mountPath: /host-sbin
                  name: host-sbin
                - mountPath: /host-usr-sbin
                  name: host-usr-sbin
                - mountPath: /host-bin
                  name: host-bin
                - mountPath: /host-usr-bin
                  name: host-usr-bin
          securityContext:
            fsGroup: 1001
            fsGroupChangePolicy: OnRootMismatch
            runAsGroup: 1001
            runAsNonRoot: true
            runAsUser: 1001
            seccompProfile:
              type: RuntimeDefault
          serviceAccountName: existing-service-account
          tolerations:
            - effect: NoSchedule
              key: node
              value: eyelevel-gpu-layout
            - effect: NoSchedule
              key: eyelevel_node
              value: eyelevel-gpu-layout
          volumes:
            - configMap:
                name: config-models-map
              name: config-models
            - configMap:
                name: layout-config-py-map
              name: config-volume
            - configMap:
                name: layout-inference-supervisord-conf-map
              name: supervisord-volume
            - configMap:
                defaultMode: 365
                name: ldconfig-symlink-map
              name: layout-inference
            - hostPath:
                path: /sbin
                type: Directory
              name: host-sbin
            - hostPath:
                path: /usr/sbin
                type: Directory
              name: host-usr-sbin
            - hostPath:
                path: /bin
                type: Directory
              name: host-bin
            - hostPath:
                path: /usr/bin
                type: Directory
              name: host-usr-bin
'metadata: inference':
  1: |
    apiVersion: apps/v1
    kind: Deployment
    metadata:
      labels:
        app: myapp-inference
        appVersion: 0.1.0
        chart: groundx-0.1.0
        heritage: Helm
        version: 0.1.0
      name: myapp-inference
      namespace: eyelevel
    spec:
      replicas: 1
      selector:
        matchLabels:
          app: myapp-inference
      template:
        metadata:
          annotations:
            config-hash: 24b8fbd2f36aa9f97623483c8c28954253e4d7a331f1ddf9bb0e9bd38d415521
            config-models-hash: 06ba464c30a765382364510ccee1e65088f7d2acbc11a746b7d14d84c220dd3b
            ldconfig-symlink-hash: 9958a113394211878ece8f9030f4c08a1860e77aa75b5852bfa0691fc3faf32f
            prometheus.io/port: "8081"
            supervisord-hash: b39bd7d75862c4a85780b4e3d76fe459b3beaa52f391376e7c95cb26ef6068ec
          labels:
            app: myapp-inference
            app.kubernetes.io/name: myapp
        spec:
          affinity:
            requiredDuringSchedulingIgnoredDuringExecution:
              - labelSelector:
                  matchExpressions:
                    - key: app
                      operator: In
                      values:
                        - myapp
                topologyKey: kubernetes.io/hostname
          containers:
            - command:
                - /bin/sh
                - -c
                - |
                  export PYTHONPATH=/app:$PYTHONPATH && python /app/init-layout.py && supervisord -c /app/supervisord.conf
              env:
                - name: POD_NAME
                  valueFrom:
                    fieldRef:
                      fieldPath: metadata.name
              image: test.image:v1
              imagePullPolicy: Never
              livenessProbe:
                failureThreshold: 8
                httpGet:
                  path: /alive
                  port: 8081
                initialDelaySeconds: 30
                periodSeconds: 15
              name: myapp-inference
              ports:
                - containerPort: 8081
                  protocol: TCP
              readinessProbe:
                failureThreshold: 30
                httpGet:
                  path: /health
                  port: 8081
                initialDelaySeconds: 30
                periodSeconds: 15
              resources:
                limits:
                  memory: 12Gi
                  nvidia.com/gpu: 1
                requests:
                  cpu: 500m
                  memory: 2Gi
                  nvidia.com/gpu: 1
              securityContext:
                readOnlyRootFilesystem: true
              volumeMounts:
                - mountPath: /app/config_models.py
                  name: config-models
                  subPath: config_models.py
                - mountPath: /app/config.py
                  name: config-volume
                  subPath: config.py
                - mountPath: /app/supervisord.conf
                  name: supervisord-volume
                  subPath: supervisord.conf
              workingDir: /app
          initContainers:
            - command:
                - sh
                - -c
                - until nc -z myapp.eyelevel.svc.cluster.local 8082; do echo waiting for cache; sleep 2; done
              image: test.image:v1
              imagePullPolicy: Always
              name: wait-for-cache
            - command:
                - sh
                - -c
                - until nc -z minio-tenant-hl.eyelevel.svc.cluster.local 9000; do echo waiting for file storage; sleep 2; done
              image: test.image:v1
              imagePullPolicy: Always
              name: wait-for-file-storage
            - args:
                - echo 'Running ldconfig_symlink.sh on this node'; /scripts/ldconfig_symlink.sh
              command:
                - /bin/sh
                - -c
                - --
              image: test.image:v1
              imagePullPolicy: Always
              name: create-symlink
              resources:
                requests:
                  cpu: 10m
                  memory: 50Mi
              securityContext:
                privileged: true
              volumeMounts:
                - mountPath: /scripts/ldconfig_symlink.sh
                  name: myapp-inference
                  subPath: ldconfig_symlink.sh
                - mountPath: /host-sbin
                  name: host-sbin
                - mountPath: /host-usr-sbin
                  name: host-usr-sbin
                - mountPath: /host-bin
                  name: host-bin
                - mountPath: /host-usr-bin
                  name: host-usr-bin
          nodeSelector:
            disktype: ssd
          securityContext:
            fsGroup: 2000
          serviceAccountName: other-service-account
          tolerations:
            - effect: NoSchedule
              key: node
              value: test-label-1
            - effect: NoSchedule
              key: eyelevel_node
              value: test-label-1
          volumes:
            - configMap:
                name: config-models-map
              name: config-models
            - configMap:
                name: myapp-config-py-map
              name: config-volume
            - configMap:
                name: myapp-inference-supervisord-conf-map
              name: supervisord-volume
            - configMap:
                defaultMode: 365
                name: ldconfig-symlink-map
              name: myapp-inference
            - hostPath:
                path: /sbin
                type: Directory
              name: host-sbin
            - hostPath:
                path: /usr/sbin
                type: Directory
              name: host-usr-sbin
            - hostPath:
                path: /bin
                type: Directory
              name: host-bin
            - hostPath:
                path: /usr/bin
                type: Directory
              name: host-usr-bin
  2: |
    apiVersion: apps/v1
    kind: Deployment
    metadata:
      labels:
        app: myapp-inference
        appVersion: 0.1.0
        chart: groundx-0.1.0
        heritage: Helm
        version: 0.1.0
      name: myapp-inference
      namespace: eyelevel
    spec:
      replicas: 1
      selector:
        matchLabels:
          app: myapp-inference
      template:
        metadata:
          annotations:
            config-hash: db12e6d22be007fc52ee601f6989646694bae2a985f615c39bcfef2d46258a3e
            config-models-hash: 06ba464c30a765382364510ccee1e65088f7d2acbc11a746b7d14d84c220dd3b
            ldconfig-symlink-hash: 9958a113394211878ece8f9030f4c08a1860e77aa75b5852bfa0691fc3faf32f
            supervisord-hash: a16c30167d8dc53d033246f4104113e03f8726f3a97dc8a7bb0af9a936a58c80
          labels:
            app: myapp-inference
        spec:
          affinity:
            nodeAffinity:
              requiredDuringSchedulingIgnoredDuringExecution:
                nodeSelectorTerms:
                  - matchExpressions:
                      - key: node
                        operator: In
                        values:
                          - test-label-1
                  - matchExpressions:
                      - key: eyelevel_node
                        operator: In
                        values:
                          - test-label-1
          containers:
            - command:
                - /bin/sh
                - -c
                - |
                  export PYTHONPATH=/workspace:$PYTHONPATH &&  supervisord -c /workspace/supervisord.conf
              env:
                - name: POD_NAME
                  valueFrom:
                    fieldRef:
                      fieldPath: metadata.name
              image: public.ecr.aws/c9r4x6y5/eyelevel/ranker-inference:0.1.0
              imagePullPolicy: IfNotPresent
              livenessProbe:
                exec:
                  command:
                    - /bin/sh
                    - -c
                    - ps aux | grep 'ranker.celery.appSearch' | grep -v grep || exit 1
                failureThreshold: 10
                initialDelaySeconds: 60
                periodSeconds: 30
              name: myapp-inference
              readinessProbe:
                exec:
                  command:
                    - /bin/sh
                    - -c
                    - ps aux | grep 'ranker.celery.appSearch' | grep -v grep || exit 1
                initialDelaySeconds: 60
                periodSeconds: 30
              resources:
                limits:
                  nvidia.com/gpu: 1
                requests:
                  cpu: 1.5
                  memory: 1Gi
                  nvidia.com/gpu: 1
              securityContext:
                allowPrivilegeEscalation: false
                capabilities:
                  drop:
                    - ALL
                runAsGroup: 1001
                runAsNonRoot: true
                runAsUser: 1001
                seccompProfile:
                  type: RuntimeDefault
              volumeMounts:
                - mountPath: /workspace/config_models.py
                  name: config-models
                  subPath: config_models.py
                - mountPath: /workspace/config.py
                  name: config-volume
                  subPath: config.py
                - mountPath: /workspace/supervisord.conf
                  name: supervisord-volume
                  subPath: supervisord.conf
                - mountPath: /workspace/hf_models_cache
                  name: model-volume
              workingDir: /workspace
          initContainers:
            - command:
                - sh
                - -c
                - until nc -z myapp.eyelevel.svc.cluster.local 8082; do echo waiting for cache; sleep 2; done
              image: test.image:v1
              imagePullPolicy: Always
              name: wait-for-cache
            - args:
                - echo 'Running ldconfig_symlink.sh on this node'; /scripts/ldconfig_symlink.sh
              command:
                - /bin/sh
                - -c
                - --
              image: test.image:v1
              imagePullPolicy: Always
              name: create-symlink
              resources:
                requests:
                  cpu: 10m
                  memory: 50Mi
              securityContext:
                privileged: true
              volumeMounts:
                - mountPath: /scripts/ldconfig_symlink.sh
                  name: myapp-inference
                  subPath: ldconfig_symlink.sh
                - mountPath: /host-sbin
                  name: host-sbin
                - mountPath: /host-usr-sbin
                  name: host-usr-sbin
                - mountPath: /host-bin
                  name: host-bin
                - mountPath: /host-usr-bin
                  name: host-usr-bin
            - command:
                - /bin/sh
                - -c
                - |
                  download_and_extract_model() {
                    echo "Model downloading started..."

                    touch /workspace/hf_models_cache/downloading

                    echo "00 01 02" | tr ' ' '\n' | xargs -n 1 -P 5 -I {} sh -c \
                      'MAX_RETRIES=3; RETRIES=0; SUCCESS=0; PART={}; URL=https://upload.groundx.ai/myapp/model/current/model.tar.gz.part.$PART; \
                      while [ $RETRIES -lt $MAX_RETRIES ]; do \
                        echo "Download [attempt $RETRIES] myapp.tar.gz.part.$PART"; \
                        wget -q -O /workspace/hf_models_cache/myapp.tar.gz.part.$PART $URL && { echo "Downloaded myapp.tar.gz.part.$PART successfully."; SUCCESS=1; break; }; \
                        echo "Failed to download $URL. Retrying..."; RETRIES=$((RETRIES + 1)); sleep 3; \
                      done; \
                      [ $SUCCESS -eq 0 ] && { echo "Failed to download $URL after $MAX_RETRIES attempts. Exiting."; rm /workspace/hf_models_cache/downloading; exit 1; }; \
                      echo "Unzipping myapp.tar.gz.part.$PART..."; tar -xzf /workspace/hf_models_cache/myapp.tar.gz.part.$PART -C /workspace/hf_models_cache/; echo "Unzipping myapp.tar.gz.part.$PART complete...";'

                    rm /workspace/hf_models_cache/myapp.tar.*
                    rm /workspace/hf_models_cache/downloading
                    touch /workspace/hf_models_cache/complete.model
                  }
                  if [ ! -f /workspace/hf_models_cache/complete.model ]; then
                    if [ ! -f /workspace/hf_models_cache/downloading ]; then
                      download_and_extract_model
                    else
                      echo "Download in progress by another pod. Waiting..."
                      while [ -f /workspace/hf_models_cache/downloading ] || [ ! -f /workspace/hf_models_cache/complete.model ]; do
                        sleep $((3 + RANDOM % 2))
                      done

                      if [ ! -f /workspace/hf_models_cache/complete.model ]; then
                        download_and_extract_model
                      else
                        echo "Model cache ready."
                      fi
                    fi
                  else
                    echo "Model cache already exists. Skipping download."
                  fi

                  echo "Model load done."
              image: test.image:v1
              imagePullPolicy: Always
              name: download-model
              securityContext:
                allowPrivilegeEscalation: false
                capabilities:
                  drop:
                    - ALL
                runAsGroup: 1001
                runAsNonRoot: true
                runAsUser: 1001
                seccompProfile:
                  type: RuntimeDefault
              volumeMounts:
                - mountPath: /workspace/hf_models_cache
                  name: model-volume
          securityContext:
            fsGroup: 1001
            fsGroupChangePolicy: OnRootMismatch
            runAsGroup: 1001
            runAsNonRoot: true
            runAsUser: 1001
            seccompProfile:
              type: RuntimeDefault
          serviceAccountName: other-service-account
          tolerations:
            - effect: NoSchedule
              key: workload-type
              operator: Equal
              value: batch
          volumes:
            - configMap:
                name: config-models-map
              name: config-models
            - configMap:
                name: myapp-config-py-map
              name: config-volume
            - configMap:
                name: myapp-inference-supervisord-conf-map
              name: supervisord-volume
            - configMap:
                defaultMode: 365
                name: ldconfig-symlink-map
              name: myapp-inference
            - hostPath:
                path: /sbin
                type: Directory
              name: host-sbin
            - hostPath:
                path: /usr/sbin
                type: Directory
              name: host-usr-sbin
            - hostPath:
                path: /bin
                type: Directory
              name: host-bin
            - hostPath:
                path: /usr/bin
                type: Directory
              name: host-usr-bin
            - name: model-volume
              persistentVolumeClaim:
                claimName: myapp-model
  3: |
    apiVersion: v1
    kind: PersistentVolumeClaim
    metadata:
      labels:
        app: myapp-inference
      name: myapp-model
      namespace: eyelevel
    spec:
      accessModes:
        - ReadWriteOnce
      resources:
        requests:
          storage: 1Gi
      storageClassName: eyelevel-pv
  4: |
    apiVersion: apps/v1
    kind: Deployment
    metadata:
      labels:
        app: myapp-inference
        appVersion: 0.1.0
        chart: groundx-0.1.0
        heritage: Helm
        version: 0.1.0
      name: myapp-inference
      namespace: eyelevel
    spec:
      replicas: 1
      selector:
        matchLabels:
          app: myapp-inference
      template:
        metadata:
          annotations:
            config-hash: 56c8f18fe0eff2755753436654dc07e20e637e6c2706f1c53014edcfd7ee498c
            config-models-hash: 06ba464c30a765382364510ccee1e65088f7d2acbc11a746b7d14d84c220dd3b
            ldconfig-symlink-hash: 9958a113394211878ece8f9030f4c08a1860e77aa75b5852bfa0691fc3faf32f
            prometheus.io/port: "8081"
            supervisord-hash: 2c08849e1942705d4ea6410c06e1e65ac52e10750830ae312285982559a9e0f1
          labels:
            app: myapp-inference
            app.kubernetes.io/name: myapp
        spec:
          affinity:
            requiredDuringSchedulingIgnoredDuringExecution:
              - labelSelector:
                  matchExpressions:
                    - key: app
                      operator: In
                      values:
                        - myapp
                topologyKey: kubernetes.io/hostname
          containers:
            - command:
                - /bin/sh
                - -c
                - |
                  export PYTHONPATH=/workspace:$PYTHONPATH &&  supervisord -c /workspace/supervisord.conf
              env:
                - name: POD_NAME
                  valueFrom:
                    fieldRef:
                      fieldPath: metadata.name
              image: test.image:v1
              imagePullPolicy: Never
              livenessProbe:
                failureThreshold: 8
                httpGet:
                  path: /alive
                  port: 8081
                initialDelaySeconds: 30
                periodSeconds: 15
              name: myapp-inference
              ports:
                - containerPort: 8081
                  protocol: TCP
              readinessProbe:
                failureThreshold: 30
                httpGet:
                  path: /health
                  port: 8081
                initialDelaySeconds: 30
                periodSeconds: 15
              resources:
                requests:
                  cpu: 500m
                  memory: 1Gi
              securityContext:
                readOnlyRootFilesystem: true
              volumeMounts:
                - mountPath: /workspace/config_models.py
                  name: config-models
                  subPath: config_models.py
                - mountPath: /workspace/config.py
                  name: config-volume
                  subPath: config.py
                - mountPath: /workspace/supervisord.conf
                  name: supervisord-volume
                  subPath: supervisord.conf
                - mountPath: /workspace/hf_models_cache
                  name: model-volume
              workingDir: /workspace
          initContainers:
            - command:
                - sh
                - -c
                - until nc -z myapp.eyelevel.svc.cluster.local 8082; do echo waiting for cache; sleep 2; done
              image: test.image:v1
              imagePullPolicy: Always
              name: wait-for-cache
            - args:
                - echo 'Running ldconfig_symlink.sh on this node'; /scripts/ldconfig_symlink.sh
              command:
                - /bin/sh
                - -c
                - --
              image: test.image:v1
              imagePullPolicy: Always
              name: create-symlink
              resources:
                requests:
                  cpu: 10m
                  memory: 50Mi
              securityContext:
                privileged: true
              volumeMounts:
                - mountPath: /scripts/ldconfig_symlink.sh
                  name: myapp-inference
                  subPath: ldconfig_symlink.sh
                - mountPath: /host-sbin
                  name: host-sbin
                - mountPath: /host-usr-sbin
                  name: host-usr-sbin
                - mountPath: /host-bin
                  name: host-bin
                - mountPath: /host-usr-bin
                  name: host-usr-bin
            - command:
                - /bin/sh
                - -c
                - |
                  download_and_extract_model() {
                    echo "Model downloading started..."

                    touch /workspace/hf_models_cache/downloading

                    echo "00 01 02 03 04" | tr ' ' '\n' | xargs -n 1 -P 5 -I {} sh -c \
                      'MAX_RETRIES=3; RETRIES=0; SUCCESS=0; PART={}; URL=https://upload.groundx.ai/myapp/model/current/g34b.tar.gz.part.$PART; \
                      while [ $RETRIES -lt $MAX_RETRIES ]; do \
                        echo "Download [attempt $RETRIES] myapp.tar.gz.part.$PART"; \
                        wget -q -O /workspace/hf_models_cache/myapp.tar.gz.part.$PART $URL && { echo "Downloaded myapp.tar.gz.part.$PART successfully."; SUCCESS=1; break; }; \
                        echo "Failed to download $URL. Retrying..."; RETRIES=$((RETRIES + 1)); sleep 3; \
                      done; \
                      [ $SUCCESS -eq 0 ] && { echo "Failed to download $URL after $MAX_RETRIES attempts. Exiting."; rm /workspace/hf_models_cache/downloading; exit 1; }; \
                      echo "Unzipping myapp.tar.gz.part.$PART..."; tar -xzf /workspace/hf_models_cache/myapp.tar.gz.part.$PART -C /workspace/hf_models_cache/; echo "Unzipping myapp.tar.gz.part.$PART complete...";'

                    rm /workspace/hf_models_cache/myapp.tar.*
                    rm /workspace/hf_models_cache/downloading
                    touch /workspace/hf_models_cache/complete.g34b
                  }
                  if [ ! -f /workspace/hf_models_cache/complete.g34b ]; then
                    if [ ! -f /workspace/hf_models_cache/downloading ]; then
                      download_and_extract_model
                    else
                      echo "Download in progress by another pod. Waiting..."
                      while [ -f /workspace/hf_models_cache/downloading ] || [ ! -f /workspace/hf_models_cache/complete.g34b ]; do
                        sleep $((3 + RANDOM % 2))
                      done

                      if [ ! -f /workspace/hf_models_cache/complete.g34b ]; then
                        download_and_extract_model
                      else
                        echo "Model cache ready."
                      fi
                    fi
                  else
                    echo "Model cache already exists. Skipping download."
                  fi

                  echo "Model load done."
              image: test.image:v1
              imagePullPolicy: Always
              name: download-model
              securityContext:
                readOnlyRootFilesystem: true
              volumeMounts:
                - mountPath: /workspace/hf_models_cache
                  name: model-volume
          runtimeClassName: abc
          securityContext:
            fsGroup: 2000
          serviceAccountName: other-service-account
          volumes:
            - configMap:
                name: config-models-map
              name: config-models
            - configMap:
                name: myapp-config-py-map
              name: config-volume
            - configMap:
                name: myapp-inference-supervisord-conf-map
              name: supervisord-volume
            - configMap:
                defaultMode: 365
                name: ldconfig-symlink-map
              name: myapp-inference
            - hostPath:
                path: /sbin
                type: Directory
              name: host-sbin
            - hostPath:
                path: /usr/sbin
                type: Directory
              name: host-usr-sbin
            - hostPath:
                path: /bin
                type: Directory
              name: host-bin
            - hostPath:
                path: /usr/bin
                type: Directory
              name: host-usr-bin
            - name: model-volume
              persistentVolumeClaim:
                claimName: test-pvc
  5: |
    apiVersion: v1
    kind: PersistentVolumeClaim
    metadata:
      labels:
        app: myapp-inference
      name: test-pvc
      namespace: eyelevel
    spec:
      accessModes:
        - ReadOnce
      resources:
        requests:
          storage: 20Gi
      storageClassName: test-pv
'minikube: inference':
  1: |
    apiVersion: apps/v1
    kind: Deployment
    metadata:
      labels:
        app: layout-inference
        appVersion: 0.1.0
        chart: groundx-0.1.0
        heritage: Helm
        version: 0.1.0
      name: layout-inference
      namespace: eyelevel
    spec:
      replicas: 1
      selector:
        matchLabels:
          app: layout-inference
      template:
        metadata:
          annotations:
            config-hash: ebaefc6af0f1c9c3731fb790ce2235c0a0ed6224f8265c625fc8bb28f856298a
            config-models-hash: 529542d6881ddf622683f3bc8516205a5707660e0a921243b32fd51fd3573f4f
            supervisord-hash: 389d025411e33663295cbafcb9d7241d27e1d8736153cd1d14fa9c1b056107fe
          labels:
            app: layout-inference
        spec:
          affinity:
            nodeAffinity:
              requiredDuringSchedulingIgnoredDuringExecution:
                nodeSelectorTerms:
                  - matchExpressions:
                      - key: node
                        operator: In
                        values:
                          - eyelevel-gpu-layout
                  - matchExpressions:
                      - key: eyelevel_node
                        operator: In
                        values:
                          - eyelevel-gpu-layout
          containers:
            - command:
                - /bin/sh
                - -c
                - |
                  export PYTHONPATH=/app:$PYTHONPATH && python /app/init-layout.py && supervisord -c /app/supervisord.conf
              env:
                - name: POD_NAME
                  valueFrom:
                    fieldRef:
                      fieldPath: metadata.name
              image: public.ecr.aws/c9r4x6y5/eyelevel/layout-inference:0.1.0
              imagePullPolicy: IfNotPresent
              livenessProbe:
                failureThreshold: 8
                httpGet:
                  path: /alive
                  port: 8080
                initialDelaySeconds: 30
                periodSeconds: 15
              name: layout-inference
              ports:
                - containerPort: 8080
                  protocol: TCP
              readinessProbe:
                failureThreshold: 30
                httpGet:
                  path: /health
                  port: 8080
                initialDelaySeconds: 30
                periodSeconds: 15
              resources:
                limits:
                  memory: 12Gi
                  nvidia.com/gpu: 1
                requests:
                  cpu: 500m
                  memory: 2Gi
                  nvidia.com/gpu: 1
              securityContext:
                allowPrivilegeEscalation: false
                capabilities:
                  drop:
                    - ALL
                runAsGroup: 1001
                runAsNonRoot: true
                runAsUser: 1001
                seccompProfile:
                  type: RuntimeDefault
              volumeMounts:
                - mountPath: /app/config_models.py
                  name: config-models
                  subPath: config_models.py
                - mountPath: /app/config.py
                  name: config-volume
                  subPath: config.py
                - mountPath: /app/supervisord.conf
                  name: supervisord-volume
                  subPath: supervisord.conf
              workingDir: /app
          initContainers:
            - command:
                - sh
                - -c
                - until nc -z cache.eyelevel.svc.cluster.local 6379; do echo waiting for cache; sleep 2; done
              image: public.ecr.aws/c9r4x6y5/eyelevel/busybox:1.0.0
              imagePullPolicy: IfNotPresent
              name: wait-for-cache
            - command:
                - sh
                - -c
                - until nc -z minio-tenant-hl.eyelevel.svc.cluster.local 9000; do echo waiting for file storage; sleep 2; done
              image: public.ecr.aws/c9r4x6y5/eyelevel/busybox:1.0.0
              imagePullPolicy: IfNotPresent
              name: wait-for-file-storage
          securityContext:
            fsGroup: 1001
            fsGroupChangePolicy: OnRootMismatch
            runAsGroup: 1001
            runAsNonRoot: true
            runAsUser: 1001
            seccompProfile:
              type: RuntimeDefault
          tolerations:
            - effect: NoSchedule
              key: node
              value: eyelevel-gpu-layout
            - effect: NoSchedule
              key: eyelevel_node
              value: eyelevel-gpu-layout
          volumes:
            - configMap:
                name: config-models-map
              name: config-models
            - configMap:
                name: layout-config-py-map
              name: config-volume
            - configMap:
                name: layout-inference-supervisord-conf-map
              name: supervisord-volume
  2: |
    apiVersion: apps/v1
    kind: Deployment
    metadata:
      labels:
        app: ranker-inference
        appVersion: 0.1.0
        chart: groundx-0.1.0
        heritage: Helm
        version: 0.1.0
      name: ranker-inference
      namespace: eyelevel
    spec:
      replicas: 1
      selector:
        matchLabels:
          app: ranker-inference
      template:
        metadata:
          annotations:
            config-hash: 10a2c3714245d327a2110a7f94d5a48581c81788dfb36f046ef6276be59e0061
            config-models-hash: 529542d6881ddf622683f3bc8516205a5707660e0a921243b32fd51fd3573f4f
            supervisord-hash: c3de8d835a18146d0f59120a18513f20056efbb1cda896213ca789277d88a71b
          labels:
            app: ranker-inference
        spec:
          affinity:
            nodeAffinity:
              requiredDuringSchedulingIgnoredDuringExecution:
                nodeSelectorTerms:
                  - matchExpressions:
                      - key: node
                        operator: In
                        values:
                          - eyelevel-gpu-ranker
                  - matchExpressions:
                      - key: eyelevel_node
                        operator: In
                        values:
                          - eyelevel-gpu-ranker
          containers:
            - command:
                - /bin/sh
                - -c
                - |
                  export PYTHONPATH=/workspace:$PYTHONPATH &&  supervisord -c /workspace/supervisord.conf
              env:
                - name: POD_NAME
                  valueFrom:
                    fieldRef:
                      fieldPath: metadata.name
              image: public.ecr.aws/c9r4x6y5/eyelevel/ranker-inference:0.1.0
              imagePullPolicy: IfNotPresent
              livenessProbe:
                exec:
                  command:
                    - /bin/sh
                    - -c
                    - ps aux | grep 'ranker.celery.appSearch' | grep -v grep || exit 1
                failureThreshold: 10
                initialDelaySeconds: 60
                periodSeconds: 30
              name: ranker-inference
              readinessProbe:
                exec:
                  command:
                    - /bin/sh
                    - -c
                    - ps aux | grep 'ranker.celery.appSearch' | grep -v grep || exit 1
                initialDelaySeconds: 60
                periodSeconds: 30
              resources:
                limits:
                  nvidia.com/gpu: 1
                requests:
                  cpu: 1.5
                  memory: 1Gi
                  nvidia.com/gpu: 1
              securityContext:
                allowPrivilegeEscalation: false
                capabilities:
                  drop:
                    - ALL
                runAsGroup: 1001
                runAsNonRoot: true
                runAsUser: 1001
                seccompProfile:
                  type: RuntimeDefault
              volumeMounts:
                - mountPath: /workspace/config_models.py
                  name: config-models
                  subPath: config_models.py
                - mountPath: /workspace/config.py
                  name: config-volume
                  subPath: config.py
                - mountPath: /workspace/supervisord.conf
                  name: supervisord-volume
                  subPath: supervisord.conf
                - mountPath: /workspace/hf_models_cache
                  name: model-volume
              workingDir: /workspace
          initContainers:
            - command:
                - sh
                - -c
                - until nc -z cache.eyelevel.svc.cluster.local 6379; do echo waiting for cache; sleep 2; done
              image: public.ecr.aws/c9r4x6y5/eyelevel/busybox:1.0.0
              imagePullPolicy: IfNotPresent
              name: wait-for-cache
            - command:
                - /bin/sh
                - -c
                - |
                  download_and_extract_model() {
                    echo "Model downloading started..."

                    touch /workspace/hf_models_cache/downloading

                    echo "00 01 02" | tr ' ' '\n' | xargs -n 1 -P 5 -I {} sh -c \
                      'MAX_RETRIES=3; RETRIES=0; SUCCESS=0; PART={}; URL=https://upload.groundx.ai/ranker/model/current/model.tar.gz.part.$PART; \
                      while [ $RETRIES -lt $MAX_RETRIES ]; do \
                        echo "Download [attempt $RETRIES] ranker.tar.gz.part.$PART"; \
                        wget -q -O /workspace/hf_models_cache/ranker.tar.gz.part.$PART $URL && { echo "Downloaded ranker.tar.gz.part.$PART successfully."; SUCCESS=1; break; }; \
                        echo "Failed to download $URL. Retrying..."; RETRIES=$((RETRIES + 1)); sleep 3; \
                      done; \
                      [ $SUCCESS -eq 0 ] && { echo "Failed to download $URL after $MAX_RETRIES attempts. Exiting."; rm /workspace/hf_models_cache/downloading; exit 1; }; \
                      echo "Unzipping ranker.tar.gz.part.$PART..."; tar -xzf /workspace/hf_models_cache/ranker.tar.gz.part.$PART -C /workspace/hf_models_cache/; echo "Unzipping ranker.tar.gz.part.$PART complete...";'

                    rm /workspace/hf_models_cache/ranker.tar.*
                    rm /workspace/hf_models_cache/downloading
                    touch /workspace/hf_models_cache/complete.model
                  }
                  if [ ! -f /workspace/hf_models_cache/complete.model ]; then
                    if [ ! -f /workspace/hf_models_cache/downloading ]; then
                      download_and_extract_model
                    else
                      echo "Download in progress by another pod. Waiting..."
                      while [ -f /workspace/hf_models_cache/downloading ] || [ ! -f /workspace/hf_models_cache/complete.model ]; do
                        sleep $((3 + RANDOM % 2))
                      done

                      if [ ! -f /workspace/hf_models_cache/complete.model ]; then
                        download_and_extract_model
                      else
                        echo "Model cache ready."
                      fi
                    fi
                  else
                    echo "Model cache already exists. Skipping download."
                  fi

                  echo "Model load done."
              image: public.ecr.aws/c9r4x6y5/eyelevel/busybox:1.0.0
              imagePullPolicy: IfNotPresent
              name: download-model
              securityContext:
                allowPrivilegeEscalation: false
                capabilities:
                  drop:
                    - ALL
                runAsGroup: 1001
                runAsNonRoot: true
                runAsUser: 1001
                seccompProfile:
                  type: RuntimeDefault
              volumeMounts:
                - mountPath: /workspace/hf_models_cache
                  name: model-volume
          securityContext:
            fsGroup: 1001
            fsGroupChangePolicy: OnRootMismatch
            runAsGroup: 1001
            runAsNonRoot: true
            runAsUser: 1001
            seccompProfile:
              type: RuntimeDefault
          tolerations:
            - effect: NoSchedule
              key: node
              value: eyelevel-gpu-ranker
            - effect: NoSchedule
              key: eyelevel_node
              value: eyelevel-gpu-ranker
          volumes:
            - configMap:
                name: config-models-map
              name: config-models
            - configMap:
                name: ranker-config-py-map
              name: config-volume
            - configMap:
                name: ranker-inference-supervisord-conf-map
              name: supervisord-volume
            - name: model-volume
              persistentVolumeClaim:
                claimName: ranker-model
  3: |
    apiVersion: v1
    kind: PersistentVolumeClaim
    metadata:
      labels:
        app: ranker-inference
      name: ranker-model
      namespace: eyelevel
    spec:
      accessModes:
        - ReadWriteOnce
      resources:
        requests:
          storage: 10Gi
      storageClassName: eyelevel-pv
  4: |
    apiVersion: apps/v1
    kind: Deployment
    metadata:
      labels:
        app: summary-inference
        appVersion: 0.1.0
        chart: groundx-0.1.0
        heritage: Helm
        version: 0.1.0
      name: summary-inference
      namespace: eyelevel
    spec:
      replicas: 2
      selector:
        matchLabels:
          app: summary-inference
      template:
        metadata:
          annotations:
            config-hash: 9b550f83fe615008fd7a3bd4fb324f3a3b8607943a72f3da1da21a0b31921ebc
            config-models-hash: 529542d6881ddf622683f3bc8516205a5707660e0a921243b32fd51fd3573f4f
            supervisord-hash: a48af0c98c4a6d0aafa9d919d204e9d8b1c51e416a36f766644a6c8d11e48a90
          labels:
            app: summary-inference
        spec:
          affinity:
            nodeAffinity:
              requiredDuringSchedulingIgnoredDuringExecution:
                nodeSelectorTerms:
                  - matchExpressions:
                      - key: node
                        operator: In
                        values:
                          - eyelevel-gpu-summary
                  - matchExpressions:
                      - key: eyelevel_node
                        operator: In
                        values:
                          - eyelevel-gpu-summary
          containers:
            - command:
                - /bin/sh
                - -c
                - |
                  export PYTHONPATH=/workspace:$PYTHONPATH &&  supervisord -c /workspace/supervisord.conf
              env:
                - name: POD_NAME
                  valueFrom:
                    fieldRef:
                      fieldPath: metadata.name
              image: public.ecr.aws/c9r4x6y5/eyelevel/summary-inference:0.1.0
              imagePullPolicy: IfNotPresent
              livenessProbe:
                failureThreshold: 8
                httpGet:
                  path: /alive
                  port: 8080
                initialDelaySeconds: 30
                periodSeconds: 15
              name: summary-inference
              ports:
                - containerPort: 8080
                  protocol: TCP
              readinessProbe:
                failureThreshold: 30
                httpGet:
                  path: /health
                  port: 8080
                initialDelaySeconds: 30
                periodSeconds: 15
              resources:
                requests:
                  cpu: 500m
                  memory: 1Gi
              securityContext:
                allowPrivilegeEscalation: false
                capabilities:
                  drop:
                    - ALL
                runAsGroup: 1001
                runAsNonRoot: true
                runAsUser: 1001
                seccompProfile:
                  type: RuntimeDefault
              volumeMounts:
                - mountPath: /workspace/config_models.py
                  name: config-models
                  subPath: config_models.py
                - mountPath: /workspace/config.py
                  name: config-volume
                  subPath: config.py
                - mountPath: /workspace/supervisord.conf
                  name: supervisord-volume
                  subPath: supervisord.conf
                - mountPath: /workspace/hf_models_cache
                  name: model-volume
              workingDir: /workspace
          initContainers:
            - command:
                - sh
                - -c
                - until nc -z cache.eyelevel.svc.cluster.local 6379; do echo waiting for cache; sleep 2; done
              image: public.ecr.aws/c9r4x6y5/eyelevel/busybox:1.0.0
              imagePullPolicy: IfNotPresent
              name: wait-for-cache
            - command:
                - /bin/sh
                - -c
                - |
                  download_and_extract_model() {
                    echo "Model downloading started..."

                    touch /workspace/hf_models_cache/downloading

                    echo "00 01 02 03 04" | tr ' ' '\n' | xargs -n 1 -P 5 -I {} sh -c \
                      'MAX_RETRIES=3; RETRIES=0; SUCCESS=0; PART={}; URL=https://upload.groundx.ai/summary/model/current/g34b.tar.gz.part.$PART; \
                      while [ $RETRIES -lt $MAX_RETRIES ]; do \
                        echo "Download [attempt $RETRIES] summary.tar.gz.part.$PART"; \
                        wget -q -O /workspace/hf_models_cache/summary.tar.gz.part.$PART $URL && { echo "Downloaded summary.tar.gz.part.$PART successfully."; SUCCESS=1; break; }; \
                        echo "Failed to download $URL. Retrying..."; RETRIES=$((RETRIES + 1)); sleep 3; \
                      done; \
                      [ $SUCCESS -eq 0 ] && { echo "Failed to download $URL after $MAX_RETRIES attempts. Exiting."; rm /workspace/hf_models_cache/downloading; exit 1; }; \
                      echo "Unzipping summary.tar.gz.part.$PART..."; tar -xzf /workspace/hf_models_cache/summary.tar.gz.part.$PART -C /workspace/hf_models_cache/; echo "Unzipping summary.tar.gz.part.$PART complete...";'

                    rm /workspace/hf_models_cache/summary.tar.*
                    rm /workspace/hf_models_cache/downloading
                    touch /workspace/hf_models_cache/complete.g34b
                  }
                  if [ ! -f /workspace/hf_models_cache/complete.g34b ]; then
                    if [ ! -f /workspace/hf_models_cache/downloading ]; then
                      download_and_extract_model
                    else
                      echo "Download in progress by another pod. Waiting..."
                      while [ -f /workspace/hf_models_cache/downloading ] || [ ! -f /workspace/hf_models_cache/complete.g34b ]; do
                        sleep $((3 + RANDOM % 2))
                      done

                      if [ ! -f /workspace/hf_models_cache/complete.g34b ]; then
                        download_and_extract_model
                      else
                        echo "Model cache ready."
                      fi
                    fi
                  else
                    echo "Model cache already exists. Skipping download."
                  fi

                  echo "Model load done."
              image: public.ecr.aws/c9r4x6y5/eyelevel/busybox:1.0.0
              imagePullPolicy: IfNotPresent
              name: download-model
              securityContext:
                allowPrivilegeEscalation: false
                capabilities:
                  drop:
                    - ALL
                runAsGroup: 1001
                runAsNonRoot: true
                runAsUser: 1001
                seccompProfile:
                  type: RuntimeDefault
              volumeMounts:
                - mountPath: /workspace/hf_models_cache
                  name: model-volume
          securityContext:
            fsGroup: 1001
            fsGroupChangePolicy: OnRootMismatch
            runAsGroup: 1001
            runAsNonRoot: true
            runAsUser: 1001
            seccompProfile:
              type: RuntimeDefault
          tolerations:
            - effect: NoSchedule
              key: node
              value: eyelevel-gpu-summary
            - effect: NoSchedule
              key: eyelevel_node
              value: eyelevel-gpu-summary
          volumes:
            - configMap:
                name: config-models-map
              name: config-models
            - configMap:
                name: summary-config-py-map
              name: config-volume
            - configMap:
                name: summary-inference-supervisord-conf-map
              name: supervisord-volume
            - name: model-volume
              persistentVolumeClaim:
                claimName: summary-model
  5: |
    apiVersion: v1
    kind: PersistentVolumeClaim
    metadata:
      labels:
        app: summary-inference
      name: summary-model
      namespace: eyelevel
    spec:
      accessModes:
        - ReadWriteOnce
      resources:
        requests:
          storage: 20Gi
      storageClassName: eyelevel-pv
'openshift: inference':
  1: |
    apiVersion: apps/v1
    kind: Deployment
    metadata:
      labels:
        app: layout-inference
        appVersion: 0.1.0
        chart: groundx-0.1.0
        heritage: Helm
        version: 0.1.0
      name: layout-inference
      namespace: eyelevel
    spec:
      replicas: 1
      selector:
        matchLabels:
          app: layout-inference
      template:
        metadata:
          annotations:
            config-hash: ebaefc6af0f1c9c3731fb790ce2235c0a0ed6224f8265c625fc8bb28f856298a
            config-models-hash: 529542d6881ddf622683f3bc8516205a5707660e0a921243b32fd51fd3573f4f
            supervisord-hash: 389d025411e33663295cbafcb9d7241d27e1d8736153cd1d14fa9c1b056107fe
          labels:
            app: layout-inference
        spec:
          affinity:
            nodeAffinity:
              requiredDuringSchedulingIgnoredDuringExecution:
                nodeSelectorTerms:
                  - matchExpressions:
                      - key: node
                        operator: In
                        values:
                          - eyelevel-gpu-layout
                  - matchExpressions:
                      - key: eyelevel_node
                        operator: In
                        values:
                          - eyelevel-gpu-layout
          containers:
            - command:
                - /bin/sh
                - -c
                - |
                  export PYTHONPATH=/app:$PYTHONPATH && python /app/init-layout.py && supervisord -c /app/supervisord.conf
              env:
                - name: POD_NAME
                  valueFrom:
                    fieldRef:
                      fieldPath: metadata.name
              image: public.ecr.aws/c9r4x6y5/eyelevel/layout-inference:0.1.0
              imagePullPolicy: IfNotPresent
              livenessProbe:
                failureThreshold: 8
                httpGet:
                  path: /alive
                  port: 8080
                initialDelaySeconds: 30
                periodSeconds: 15
              name: layout-inference
              ports:
                - containerPort: 8080
                  protocol: TCP
              readinessProbe:
                failureThreshold: 30
                httpGet:
                  path: /health
                  port: 8080
                initialDelaySeconds: 30
                periodSeconds: 15
              resources:
                limits:
                  memory: 12Gi
                  nvidia.com/gpu: 1
                requests:
                  cpu: 500m
                  memory: 2Gi
                  nvidia.com/gpu: 1
              securityContext:
                allowPrivilegeEscalation: false
                capabilities:
                  drop:
                    - ALL
                runAsNonRoot: true
                seccompProfile:
                  type: RuntimeDefault
              volumeMounts:
                - mountPath: /app/config_models.py
                  name: config-models
                  subPath: config_models.py
                - mountPath: /app/config.py
                  name: config-volume
                  subPath: config.py
                - mountPath: /app/supervisord.conf
                  name: supervisord-volume
                  subPath: supervisord.conf
              workingDir: /app
          initContainers:
            - command:
                - sh
                - -c
                - until nc -z cache.eyelevel.svc.cluster.local 6379; do echo waiting for cache; sleep 2; done
              image: public.ecr.aws/c9r4x6y5/eyelevel/busybox:1.0.0
              imagePullPolicy: IfNotPresent
              name: wait-for-cache
            - command:
                - sh
                - -c
                - until nc -z minio-tenant-hl.eyelevel.svc.cluster.local 9000; do echo waiting for file storage; sleep 2; done
              image: public.ecr.aws/c9r4x6y5/eyelevel/busybox:1.0.0
              imagePullPolicy: IfNotPresent
              name: wait-for-file-storage
          securityContext:
            runAsNonRoot: true
            seccompProfile:
              type: RuntimeDefault
          tolerations:
            - effect: NoSchedule
              key: node
              value: eyelevel-gpu-layout
            - effect: NoSchedule
              key: eyelevel_node
              value: eyelevel-gpu-layout
          volumes:
            - configMap:
                name: config-models-map
              name: config-models
            - configMap:
                name: layout-config-py-map
              name: config-volume
            - configMap:
                name: layout-inference-supervisord-conf-map
              name: supervisord-volume
  2: |
    apiVersion: apps/v1
    kind: Deployment
    metadata:
      labels:
        app: ranker-inference
        appVersion: 0.1.0
        chart: groundx-0.1.0
        heritage: Helm
        version: 0.1.0
      name: ranker-inference
      namespace: eyelevel
    spec:
      replicas: 1
      selector:
        matchLabels:
          app: ranker-inference
      template:
        metadata:
          annotations:
            config-hash: 10a2c3714245d327a2110a7f94d5a48581c81788dfb36f046ef6276be59e0061
            config-models-hash: 529542d6881ddf622683f3bc8516205a5707660e0a921243b32fd51fd3573f4f
            supervisord-hash: c3de8d835a18146d0f59120a18513f20056efbb1cda896213ca789277d88a71b
          labels:
            app: ranker-inference
        spec:
          affinity:
            nodeAffinity:
              requiredDuringSchedulingIgnoredDuringExecution:
                nodeSelectorTerms:
                  - matchExpressions:
                      - key: node
                        operator: In
                        values:
                          - eyelevel-gpu-ranker
                  - matchExpressions:
                      - key: eyelevel_node
                        operator: In
                        values:
                          - eyelevel-gpu-ranker
          containers:
            - command:
                - /bin/sh
                - -c
                - |
                  export PYTHONPATH=/workspace:$PYTHONPATH &&  supervisord -c /workspace/supervisord.conf
              env:
                - name: POD_NAME
                  valueFrom:
                    fieldRef:
                      fieldPath: metadata.name
              image: public.ecr.aws/c9r4x6y5/eyelevel/ranker-inference:0.1.0
              imagePullPolicy: IfNotPresent
              livenessProbe:
                exec:
                  command:
                    - /bin/sh
                    - -c
                    - ps aux | grep 'ranker.celery.appSearch' | grep -v grep || exit 1
                failureThreshold: 10
                initialDelaySeconds: 60
                periodSeconds: 30
              name: ranker-inference
              readinessProbe:
                exec:
                  command:
                    - /bin/sh
                    - -c
                    - ps aux | grep 'ranker.celery.appSearch' | grep -v grep || exit 1
                initialDelaySeconds: 60
                periodSeconds: 30
              resources:
                limits:
                  nvidia.com/gpu: 1
                requests:
                  cpu: 1.5
                  memory: 1Gi
                  nvidia.com/gpu: 1
              securityContext:
                allowPrivilegeEscalation: false
                capabilities:
                  drop:
                    - ALL
                runAsNonRoot: true
                seccompProfile:
                  type: RuntimeDefault
              volumeMounts:
                - mountPath: /workspace/config_models.py
                  name: config-models
                  subPath: config_models.py
                - mountPath: /workspace/config.py
                  name: config-volume
                  subPath: config.py
                - mountPath: /workspace/supervisord.conf
                  name: supervisord-volume
                  subPath: supervisord.conf
                - mountPath: /workspace/hf_models_cache
                  name: model-volume
              workingDir: /workspace
          initContainers:
            - command:
                - sh
                - -c
                - until nc -z cache.eyelevel.svc.cluster.local 6379; do echo waiting for cache; sleep 2; done
              image: public.ecr.aws/c9r4x6y5/eyelevel/busybox:1.0.0
              imagePullPolicy: IfNotPresent
              name: wait-for-cache
            - command:
                - /bin/sh
                - -c
                - |
                  download_and_extract_model() {
                    echo "Model downloading started..."

                    touch /workspace/hf_models_cache/downloading

                    echo "00 01 02" | tr ' ' '\n' | xargs -n 1 -P 5 -I {} sh -c \
                      'MAX_RETRIES=3; RETRIES=0; SUCCESS=0; PART={}; URL=https://upload.groundx.ai/ranker/model/current/model.tar.gz.part.$PART; \
                      while [ $RETRIES -lt $MAX_RETRIES ]; do \
                        echo "Download [attempt $RETRIES] ranker.tar.gz.part.$PART"; \
                        wget -q -O /workspace/hf_models_cache/ranker.tar.gz.part.$PART $URL && { echo "Downloaded ranker.tar.gz.part.$PART successfully."; SUCCESS=1; break; }; \
                        echo "Failed to download $URL. Retrying..."; RETRIES=$((RETRIES + 1)); sleep 3; \
                      done; \
                      [ $SUCCESS -eq 0 ] && { echo "Failed to download $URL after $MAX_RETRIES attempts. Exiting."; rm /workspace/hf_models_cache/downloading; exit 1; }; \
                      echo "Unzipping ranker.tar.gz.part.$PART..."; tar -xzf /workspace/hf_models_cache/ranker.tar.gz.part.$PART -C /workspace/hf_models_cache/; echo "Unzipping ranker.tar.gz.part.$PART complete...";'

                    rm /workspace/hf_models_cache/ranker.tar.*
                    rm /workspace/hf_models_cache/downloading
                    touch /workspace/hf_models_cache/complete.model
                  }
                  if [ ! -f /workspace/hf_models_cache/complete.model ]; then
                    if [ ! -f /workspace/hf_models_cache/downloading ]; then
                      download_and_extract_model
                    else
                      echo "Download in progress by another pod. Waiting..."
                      while [ -f /workspace/hf_models_cache/downloading ] || [ ! -f /workspace/hf_models_cache/complete.model ]; do
                        sleep $((3 + RANDOM % 2))
                      done

                      if [ ! -f /workspace/hf_models_cache/complete.model ]; then
                        download_and_extract_model
                      else
                        echo "Model cache ready."
                      fi
                    fi
                  else
                    echo "Model cache already exists. Skipping download."
                  fi

                  echo "Model load done."
              image: public.ecr.aws/c9r4x6y5/eyelevel/busybox:1.0.0
              imagePullPolicy: IfNotPresent
              name: download-model
              securityContext:
                allowPrivilegeEscalation: false
                capabilities:
                  drop:
                    - ALL
                runAsNonRoot: true
                seccompProfile:
                  type: RuntimeDefault
              volumeMounts:
                - mountPath: /workspace/hf_models_cache
                  name: model-volume
          securityContext:
            runAsNonRoot: true
            seccompProfile:
              type: RuntimeDefault
          tolerations:
            - effect: NoSchedule
              key: node
              value: eyelevel-gpu-ranker
            - effect: NoSchedule
              key: eyelevel_node
              value: eyelevel-gpu-ranker
          volumes:
            - configMap:
                name: config-models-map
              name: config-models
            - configMap:
                name: ranker-config-py-map
              name: config-volume
            - configMap:
                name: ranker-inference-supervisord-conf-map
              name: supervisord-volume
            - name: model-volume
              persistentVolumeClaim:
                claimName: ranker-model
  3: |
    apiVersion: v1
    kind: PersistentVolumeClaim
    metadata:
      labels:
        app: ranker-inference
      name: ranker-model
      namespace: eyelevel
    spec:
      accessModes:
        - ReadWriteOnce
      resources:
        requests:
          storage: 10Gi
      storageClassName: eyelevel-pv
  4: |
    apiVersion: apps/v1
    kind: Deployment
    metadata:
      labels:
        app: summary-inference
        appVersion: 0.1.0
        chart: groundx-0.1.0
        heritage: Helm
        version: 0.1.0
      name: summary-inference
      namespace: eyelevel
    spec:
      replicas: 2
      selector:
        matchLabels:
          app: summary-inference
      template:
        metadata:
          annotations:
            config-hash: 9b550f83fe615008fd7a3bd4fb324f3a3b8607943a72f3da1da21a0b31921ebc
            config-models-hash: 529542d6881ddf622683f3bc8516205a5707660e0a921243b32fd51fd3573f4f
            supervisord-hash: a48af0c98c4a6d0aafa9d919d204e9d8b1c51e416a36f766644a6c8d11e48a90
          labels:
            app: summary-inference
        spec:
          affinity:
            nodeAffinity:
              requiredDuringSchedulingIgnoredDuringExecution:
                nodeSelectorTerms:
                  - matchExpressions:
                      - key: node
                        operator: In
                        values:
                          - eyelevel-gpu-summary
                  - matchExpressions:
                      - key: eyelevel_node
                        operator: In
                        values:
                          - eyelevel-gpu-summary
          containers:
            - command:
                - /bin/sh
                - -c
                - |
                  export PYTHONPATH=/workspace:$PYTHONPATH &&  supervisord -c /workspace/supervisord.conf
              env:
                - name: POD_NAME
                  valueFrom:
                    fieldRef:
                      fieldPath: metadata.name
              image: public.ecr.aws/c9r4x6y5/eyelevel/summary-inference:0.1.0
              imagePullPolicy: IfNotPresent
              livenessProbe:
                failureThreshold: 8
                httpGet:
                  path: /alive
                  port: 8080
                initialDelaySeconds: 30
                periodSeconds: 15
              name: summary-inference
              ports:
                - containerPort: 8080
                  protocol: TCP
              readinessProbe:
                failureThreshold: 30
                httpGet:
                  path: /health
                  port: 8080
                initialDelaySeconds: 30
                periodSeconds: 15
              resources:
                requests:
                  cpu: 500m
                  memory: 1Gi
              securityContext:
                allowPrivilegeEscalation: false
                capabilities:
                  drop:
                    - ALL
                runAsNonRoot: true
                seccompProfile:
                  type: RuntimeDefault
              volumeMounts:
                - mountPath: /workspace/config_models.py
                  name: config-models
                  subPath: config_models.py
                - mountPath: /workspace/config.py
                  name: config-volume
                  subPath: config.py
                - mountPath: /workspace/supervisord.conf
                  name: supervisord-volume
                  subPath: supervisord.conf
                - mountPath: /workspace/hf_models_cache
                  name: model-volume
              workingDir: /workspace
          initContainers:
            - command:
                - sh
                - -c
                - until nc -z cache.eyelevel.svc.cluster.local 6379; do echo waiting for cache; sleep 2; done
              image: public.ecr.aws/c9r4x6y5/eyelevel/busybox:1.0.0
              imagePullPolicy: IfNotPresent
              name: wait-for-cache
            - command:
                - /bin/sh
                - -c
                - |
                  download_and_extract_model() {
                    echo "Model downloading started..."

                    touch /workspace/hf_models_cache/downloading

                    echo "00 01 02 03 04" | tr ' ' '\n' | xargs -n 1 -P 5 -I {} sh -c \
                      'MAX_RETRIES=3; RETRIES=0; SUCCESS=0; PART={}; URL=https://upload.groundx.ai/summary/model/current/g34b.tar.gz.part.$PART; \
                      while [ $RETRIES -lt $MAX_RETRIES ]; do \
                        echo "Download [attempt $RETRIES] summary.tar.gz.part.$PART"; \
                        wget -q -O /workspace/hf_models_cache/summary.tar.gz.part.$PART $URL && { echo "Downloaded summary.tar.gz.part.$PART successfully."; SUCCESS=1; break; }; \
                        echo "Failed to download $URL. Retrying..."; RETRIES=$((RETRIES + 1)); sleep 3; \
                      done; \
                      [ $SUCCESS -eq 0 ] && { echo "Failed to download $URL after $MAX_RETRIES attempts. Exiting."; rm /workspace/hf_models_cache/downloading; exit 1; }; \
                      echo "Unzipping summary.tar.gz.part.$PART..."; tar -xzf /workspace/hf_models_cache/summary.tar.gz.part.$PART -C /workspace/hf_models_cache/; echo "Unzipping summary.tar.gz.part.$PART complete...";'

                    rm /workspace/hf_models_cache/summary.tar.*
                    rm /workspace/hf_models_cache/downloading
                    touch /workspace/hf_models_cache/complete.g34b
                  }
                  if [ ! -f /workspace/hf_models_cache/complete.g34b ]; then
                    if [ ! -f /workspace/hf_models_cache/downloading ]; then
                      download_and_extract_model
                    else
                      echo "Download in progress by another pod. Waiting..."
                      while [ -f /workspace/hf_models_cache/downloading ] || [ ! -f /workspace/hf_models_cache/complete.g34b ]; do
                        sleep $((3 + RANDOM % 2))
                      done

                      if [ ! -f /workspace/hf_models_cache/complete.g34b ]; then
                        download_and_extract_model
                      else
                        echo "Model cache ready."
                      fi
                    fi
                  else
                    echo "Model cache already exists. Skipping download."
                  fi

                  echo "Model load done."
              image: public.ecr.aws/c9r4x6y5/eyelevel/busybox:1.0.0
              imagePullPolicy: IfNotPresent
              name: download-model
              securityContext:
                allowPrivilegeEscalation: false
                capabilities:
                  drop:
                    - ALL
                runAsNonRoot: true
                seccompProfile:
                  type: RuntimeDefault
              volumeMounts:
                - mountPath: /workspace/hf_models_cache
                  name: model-volume
          securityContext:
            runAsNonRoot: true
            seccompProfile:
              type: RuntimeDefault
          tolerations:
            - effect: NoSchedule
              key: node
              value: eyelevel-gpu-summary
            - effect: NoSchedule
              key: eyelevel_node
              value: eyelevel-gpu-summary
          volumes:
            - configMap:
                name: config-models-map
              name: config-models
            - configMap:
                name: summary-config-py-map
              name: config-volume
            - configMap:
                name: summary-inference-supervisord-conf-map
              name: supervisord-volume
            - name: model-volume
              persistentVolumeClaim:
                claimName: summary-model
  5: |
    apiVersion: v1
    kind: PersistentVolumeClaim
    metadata:
      labels:
        app: summary-inference
      name: summary-model
      namespace: eyelevel
    spec:
      accessModes:
        - ReadWriteOnce
      resources:
        requests:
          storage: 20Gi
      storageClassName: eyelevel-pv
'phoenix: inference':
  1: |
    apiVersion: apps/v1
    kind: Deployment
    metadata:
      labels:
        app: layout-inference
        appVersion: 0.1.0
        chart: groundx-0.1.0
        heritage: Helm
        version: 0.1.0
      name: layout-inference
      namespace: eyelevel
    spec:
      replicas: 2
      selector:
        matchLabels:
          app: layout-inference
      template:
        metadata:
          annotations:
            config-hash: 9cb086224bcbefcd195a92ba8c0903e63036900c20fb5797d656ce5dffe4bc0c
            config-models-hash: 529542d6881ddf622683f3bc8516205a5707660e0a921243b32fd51fd3573f4f
            supervisord-hash: 389d025411e33663295cbafcb9d7241d27e1d8736153cd1d14fa9c1b056107fe
          labels:
            app: layout-inference
        spec:
          affinity:
            nodeAffinity:
              requiredDuringSchedulingIgnoredDuringExecution:
                nodeSelectorTerms:
                  - matchExpressions:
                      - key: node
                        operator: In
                        values:
                          - eyelevel-gpu
                  - matchExpressions:
                      - key: eyelevel_node
                        operator: In
                        values:
                          - eyelevel-gpu
          containers:
            - command:
                - /bin/sh
                - -c
                - |
                  export PYTHONPATH=/app:$PYTHONPATH && python /app/init-layout.py && supervisord -c /app/supervisord.conf
              env:
                - name: POD_NAME
                  valueFrom:
                    fieldRef:
                      fieldPath: metadata.name
              image: public.ecr.aws/c9r4x6y5/eyelevel/layout-inference:0.1.0
              imagePullPolicy: Always
              livenessProbe:
                failureThreshold: 8
                httpGet:
                  path: /alive
                  port: 8080
                initialDelaySeconds: 30
                periodSeconds: 15
              name: layout-inference
              ports:
                - containerPort: 8080
                  protocol: TCP
              readinessProbe:
                failureThreshold: 30
                httpGet:
                  path: /health
                  port: 8080
                initialDelaySeconds: 30
                periodSeconds: 15
              resources:
                limits:
                  memory: 12Gi
                  nvidia.com/gpu: 1
                requests:
                  cpu: 500m
                  memory: 2Gi
                  nvidia.com/gpu: 1
              securityContext:
                allowPrivilegeEscalation: false
                capabilities:
                  drop:
                    - ALL
                runAsNonRoot: true
                seccompProfile:
                  type: RuntimeDefault
              volumeMounts:
                - mountPath: /app/config_models.py
                  name: config-models
                  subPath: config_models.py
                - mountPath: /app/config.py
                  name: config-volume
                  subPath: config.py
                - mountPath: /app/supervisord.conf
                  name: supervisord-volume
                  subPath: supervisord.conf
              workingDir: /app
          imagePullSecrets:
            - name: ecr-public-pull
          initContainers:
            - command:
                - sh
                - -c
                - until nc -z cache.eyelevel.svc.cluster.local 6379; do echo waiting for cache; sleep 2; done
              image: public.ecr.aws/c9r4x6y5/eyelevel/busybox:1.0.0
              imagePullPolicy: Always
              name: wait-for-cache
            - command:
                - sh
                - -c
                - until nc -z minio-tenant-hl.eyelevel.svc.cluster.local 9000; do echo waiting for file storage; sleep 2; done
              image: public.ecr.aws/c9r4x6y5/eyelevel/busybox:1.0.0
              imagePullPolicy: Always
              name: wait-for-file-storage
          securityContext:
            runAsNonRoot: true
            seccompProfile:
              type: RuntimeDefault
          tolerations:
            - effect: NoSchedule
              key: node
              value: eyelevel-gpu
            - effect: NoSchedule
              key: eyelevel_node
              value: eyelevel-gpu
          volumes:
            - configMap:
                name: config-models-map
              name: config-models
            - configMap:
                name: layout-config-py-map
              name: config-volume
            - configMap:
                name: layout-inference-supervisord-conf-map
              name: supervisord-volume
  2: |
    apiVersion: apps/v1
    kind: Deployment
    metadata:
      labels:
        app: ranker-inference
        appVersion: 0.1.0
        chart: groundx-0.1.0
        heritage: Helm
        version: 0.1.0
      name: ranker-inference
      namespace: eyelevel
    spec:
      replicas: 4
      selector:
        matchLabels:
          app: ranker-inference
      template:
        metadata:
          annotations:
            config-hash: 8c8d3d4f45d68a2a23457d8db11374d236b3e1b2f01730bbb2426421e92af4e5
            config-models-hash: 529542d6881ddf622683f3bc8516205a5707660e0a921243b32fd51fd3573f4f
            supervisord-hash: c3de8d835a18146d0f59120a18513f20056efbb1cda896213ca789277d88a71b
          labels:
            app: ranker-inference
        spec:
          affinity:
            nodeAffinity:
              requiredDuringSchedulingIgnoredDuringExecution:
                nodeSelectorTerms:
                  - matchExpressions:
                      - key: node
                        operator: In
                        values:
                          - eyelevel-gpu
                  - matchExpressions:
                      - key: eyelevel_node
                        operator: In
                        values:
                          - eyelevel-gpu
          containers:
            - command:
                - /bin/sh
                - -c
                - |
                  export PYTHONPATH=/workspace:$PYTHONPATH &&  supervisord -c /workspace/supervisord.conf
              env:
                - name: POD_NAME
                  valueFrom:
                    fieldRef:
                      fieldPath: metadata.name
              image: public.ecr.aws/c9r4x6y5/eyelevel/ranker-inference:0.1.0
              imagePullPolicy: Always
              livenessProbe:
                exec:
                  command:
                    - /bin/sh
                    - -c
                    - ps aux | grep 'ranker.celery.appSearch' | grep -v grep || exit 1
                failureThreshold: 10
                initialDelaySeconds: 60
                periodSeconds: 30
              name: ranker-inference
              readinessProbe:
                exec:
                  command:
                    - /bin/sh
                    - -c
                    - ps aux | grep 'ranker.celery.appSearch' | grep -v grep || exit 1
                initialDelaySeconds: 60
                periodSeconds: 30
              resources:
                limits:
                  nvidia.com/gpu: 1
                requests:
                  cpu: 1.5
                  memory: 1Gi
                  nvidia.com/gpu: 1
              securityContext:
                allowPrivilegeEscalation: false
                capabilities:
                  drop:
                    - ALL
                runAsNonRoot: true
                seccompProfile:
                  type: RuntimeDefault
              volumeMounts:
                - mountPath: /workspace/config_models.py
                  name: config-models
                  subPath: config_models.py
                - mountPath: /workspace/config.py
                  name: config-volume
                  subPath: config.py
                - mountPath: /workspace/supervisord.conf
                  name: supervisord-volume
                  subPath: supervisord.conf
                - mountPath: /workspace/hf_models_cache
                  name: model-volume
              workingDir: /workspace
          imagePullSecrets:
            - name: ecr-public-pull
          initContainers:
            - command:
                - sh
                - -c
                - until nc -z cache.eyelevel.svc.cluster.local 6379; do echo waiting for cache; sleep 2; done
              image: public.ecr.aws/c9r4x6y5/eyelevel/busybox:1.0.0
              imagePullPolicy: Always
              name: wait-for-cache
            - command:
                - /bin/sh
                - -c
                - |
                  download_and_extract_model() {
                    echo "Model downloading started..."

                    touch /workspace/hf_models_cache/downloading

                    echo "00 01 02" | tr ' ' '\n' | xargs -n 1 -P 5 -I {} sh -c \
                      'MAX_RETRIES=3; RETRIES=0; SUCCESS=0; PART={}; URL=https://upload.groundx.ai/ranker/model/current/model.tar.gz.part.$PART; \
                      while [ $RETRIES -lt $MAX_RETRIES ]; do \
                        echo "Download [attempt $RETRIES] ranker.tar.gz.part.$PART"; \
                        wget -q -O /workspace/hf_models_cache/ranker.tar.gz.part.$PART $URL && { echo "Downloaded ranker.tar.gz.part.$PART successfully."; SUCCESS=1; break; }; \
                        echo "Failed to download $URL. Retrying..."; RETRIES=$((RETRIES + 1)); sleep 3; \
                      done; \
                      [ $SUCCESS -eq 0 ] && { echo "Failed to download $URL after $MAX_RETRIES attempts. Exiting."; rm /workspace/hf_models_cache/downloading; exit 1; }; \
                      echo "Unzipping ranker.tar.gz.part.$PART..."; tar -xzf /workspace/hf_models_cache/ranker.tar.gz.part.$PART -C /workspace/hf_models_cache/; echo "Unzipping ranker.tar.gz.part.$PART complete...";'

                    rm /workspace/hf_models_cache/ranker.tar.*
                    rm /workspace/hf_models_cache/downloading
                    touch /workspace/hf_models_cache/complete.model
                  }
                  if [ ! -f /workspace/hf_models_cache/complete.model ]; then
                    if [ ! -f /workspace/hf_models_cache/downloading ]; then
                      download_and_extract_model
                    else
                      echo "Download in progress by another pod. Waiting..."
                      while [ -f /workspace/hf_models_cache/downloading ] || [ ! -f /workspace/hf_models_cache/complete.model ]; do
                        sleep $((3 + RANDOM % 2))
                      done

                      if [ ! -f /workspace/hf_models_cache/complete.model ]; then
                        download_and_extract_model
                      else
                        echo "Model cache ready."
                      fi
                    fi
                  else
                    echo "Model cache already exists. Skipping download."
                  fi

                  echo "Model load done."
              image: public.ecr.aws/c9r4x6y5/eyelevel/busybox:1.0.0
              imagePullPolicy: Always
              name: download-model
              securityContext:
                allowPrivilegeEscalation: false
                capabilities:
                  drop:
                    - ALL
                runAsNonRoot: true
                seccompProfile:
                  type: RuntimeDefault
              volumeMounts:
                - mountPath: /workspace/hf_models_cache
                  name: model-volume
          securityContext:
            runAsNonRoot: true
            seccompProfile:
              type: RuntimeDefault
          tolerations:
            - effect: NoSchedule
              key: node
              value: eyelevel-gpu
            - effect: NoSchedule
              key: eyelevel_node
              value: eyelevel-gpu
          volumes:
            - configMap:
                name: config-models-map
              name: config-models
            - configMap:
                name: ranker-config-py-map
              name: config-volume
            - configMap:
                name: ranker-inference-supervisord-conf-map
              name: supervisord-volume
            - name: model-volume
              persistentVolumeClaim:
                claimName: ranker-model
  3: |
    apiVersion: v1
    kind: PersistentVolumeClaim
    metadata:
      labels:
        app: ranker-inference
      name: ranker-model
      namespace: eyelevel
    spec:
      accessModes:
        - ReadWriteOnce
      resources:
        requests:
          storage: 10Gi
      storageClassName: eyelevel-pv
  4: |
    apiVersion: apps/v1
    kind: Deployment
    metadata:
      labels:
        app: summary-inference
        appVersion: 0.1.0
        chart: groundx-0.1.0
        heritage: Helm
        version: 0.1.0
      name: summary-inference
      namespace: eyelevel
    spec:
      replicas: 24
      selector:
        matchLabels:
          app: summary-inference
      template:
        metadata:
          annotations:
            config-hash: 1b1aead3ca98c3ddee0f7bd5b82db625856ebb4bd9fe5fe1cef654c9499d87fb
            config-models-hash: 529542d6881ddf622683f3bc8516205a5707660e0a921243b32fd51fd3573f4f
            supervisord-hash: a48af0c98c4a6d0aafa9d919d204e9d8b1c51e416a36f766644a6c8d11e48a90
          labels:
            app: summary-inference
        spec:
          affinity:
            nodeAffinity:
              requiredDuringSchedulingIgnoredDuringExecution:
                nodeSelectorTerms:
                  - matchExpressions:
                      - key: node
                        operator: In
                        values:
                          - eyelevel-gpu
                  - matchExpressions:
                      - key: eyelevel_node
                        operator: In
                        values:
                          - eyelevel-gpu
          containers:
            - command:
                - /bin/sh
                - -c
                - |
                  export PYTHONPATH=/workspace:$PYTHONPATH &&  supervisord -c /workspace/supervisord.conf
              env:
                - name: POD_NAME
                  valueFrom:
                    fieldRef:
                      fieldPath: metadata.name
              image: public.ecr.aws/c9r4x6y5/eyelevel/summary-inference:0.1.0
              imagePullPolicy: Always
              livenessProbe:
                failureThreshold: 8
                httpGet:
                  path: /alive
                  port: 8080
                initialDelaySeconds: 30
                periodSeconds: 15
              name: summary-inference
              ports:
                - containerPort: 8080
                  protocol: TCP
              readinessProbe:
                failureThreshold: 30
                httpGet:
                  path: /health
                  port: 8080
                initialDelaySeconds: 30
                periodSeconds: 15
              resources:
                limits:
                  nvidia.com/gpu: 1
                requests:
                  cpu: 500m
                  memory: 1Gi
                  nvidia.com/gpu: 1
              securityContext:
                allowPrivilegeEscalation: false
                capabilities:
                  drop:
                    - ALL
                runAsNonRoot: true
                seccompProfile:
                  type: RuntimeDefault
              volumeMounts:
                - mountPath: /workspace/config_models.py
                  name: config-models
                  subPath: config_models.py
                - mountPath: /workspace/config.py
                  name: config-volume
                  subPath: config.py
                - mountPath: /workspace/supervisord.conf
                  name: supervisord-volume
                  subPath: supervisord.conf
                - mountPath: /workspace/hf_models_cache
                  name: model-volume
              workingDir: /workspace
          imagePullSecrets:
            - name: ecr-public-pull
          initContainers:
            - command:
                - sh
                - -c
                - until nc -z cache.eyelevel.svc.cluster.local 6379; do echo waiting for cache; sleep 2; done
              image: public.ecr.aws/c9r4x6y5/eyelevel/busybox:1.0.0
              imagePullPolicy: Always
              name: wait-for-cache
            - command:
                - /bin/sh
                - -c
                - |
                  download_and_extract_model() {
                    echo "Model downloading started..."

                    touch /workspace/hf_models_cache/downloading

                    echo "00 01 02 03 04" | tr ' ' '\n' | xargs -n 1 -P 5 -I {} sh -c \
                      'MAX_RETRIES=3; RETRIES=0; SUCCESS=0; PART={}; URL=https://upload.groundx.ai/summary/model/current/g34b.tar.gz.part.$PART; \
                      while [ $RETRIES -lt $MAX_RETRIES ]; do \
                        echo "Download [attempt $RETRIES] summary.tar.gz.part.$PART"; \
                        wget -q -O /workspace/hf_models_cache/summary.tar.gz.part.$PART $URL && { echo "Downloaded summary.tar.gz.part.$PART successfully."; SUCCESS=1; break; }; \
                        echo "Failed to download $URL. Retrying..."; RETRIES=$((RETRIES + 1)); sleep 3; \
                      done; \
                      [ $SUCCESS -eq 0 ] && { echo "Failed to download $URL after $MAX_RETRIES attempts. Exiting."; rm /workspace/hf_models_cache/downloading; exit 1; }; \
                      echo "Unzipping summary.tar.gz.part.$PART..."; tar -xzf /workspace/hf_models_cache/summary.tar.gz.part.$PART -C /workspace/hf_models_cache/; echo "Unzipping summary.tar.gz.part.$PART complete...";'

                    rm /workspace/hf_models_cache/summary.tar.*
                    rm /workspace/hf_models_cache/downloading
                    touch /workspace/hf_models_cache/complete.g34b
                  }
                  if [ ! -f /workspace/hf_models_cache/complete.g34b ]; then
                    if [ ! -f /workspace/hf_models_cache/downloading ]; then
                      download_and_extract_model
                    else
                      echo "Download in progress by another pod. Waiting..."
                      while [ -f /workspace/hf_models_cache/downloading ] || [ ! -f /workspace/hf_models_cache/complete.g34b ]; do
                        sleep $((3 + RANDOM % 2))
                      done

                      if [ ! -f /workspace/hf_models_cache/complete.g34b ]; then
                        download_and_extract_model
                      else
                        echo "Model cache ready."
                      fi
                    fi
                  else
                    echo "Model cache already exists. Skipping download."
                  fi

                  echo "Model load done."
              image: public.ecr.aws/c9r4x6y5/eyelevel/busybox:1.0.0
              imagePullPolicy: Always
              name: download-model
              securityContext:
                allowPrivilegeEscalation: false
                capabilities:
                  drop:
                    - ALL
                runAsNonRoot: true
                seccompProfile:
                  type: RuntimeDefault
              volumeMounts:
                - mountPath: /workspace/hf_models_cache
                  name: model-volume
          securityContext:
            runAsNonRoot: true
            seccompProfile:
              type: RuntimeDefault
          tolerations:
            - effect: NoSchedule
              key: node
              value: eyelevel-gpu
            - effect: NoSchedule
              key: eyelevel_node
              value: eyelevel-gpu
          volumes:
            - configMap:
                name: config-models-map
              name: config-models
            - configMap:
                name: summary-config-py-map
              name: config-volume
            - configMap:
                name: summary-inference-supervisord-conf-map
              name: supervisord-volume
            - name: model-volume
              persistentVolumeClaim:
                claimName: summary-model
  5: |
    apiVersion: v1
    kind: PersistentVolumeClaim
    metadata:
      labels:
        app: summary-inference
      name: summary-model
      namespace: eyelevel
    spec:
      accessModes:
        - ReadWriteOnce
      resources:
        requests:
          storage: 20Gi
      storageClassName: eyelevel-pv
